\documentclass[color=usenames,dvipsnames]{beamer}\usepackage[]{graphicx}\usepackage[]{color}
% maxwidth is the original width if it is less than linewidth
% otherwise use linewidth (to make sure the graphics do not exceed the margin)
\makeatletter
\def\maxwidth{ %
  \ifdim\Gin@nat@width>\linewidth
    \linewidth
  \else
    \Gin@nat@width
  \fi
}
\makeatother

\definecolor{fgcolor}{rgb}{0, 0, 0}
\newcommand{\hlnum}[1]{\textcolor[rgb]{0.69,0.494,0}{#1}}%
\newcommand{\hlstr}[1]{\textcolor[rgb]{0.749,0.012,0.012}{#1}}%
\newcommand{\hlcom}[1]{\textcolor[rgb]{0.514,0.506,0.514}{\textit{#1}}}%
\newcommand{\hlopt}[1]{\textcolor[rgb]{0,0,0}{#1}}%
\newcommand{\hlstd}[1]{\textcolor[rgb]{0,0,0}{#1}}%
\newcommand{\hlkwa}[1]{\textcolor[rgb]{0,0,0}{\textbf{#1}}}%
\newcommand{\hlkwb}[1]{\textcolor[rgb]{0,0.341,0.682}{#1}}%
\newcommand{\hlkwc}[1]{\textcolor[rgb]{0,0,0}{\textbf{#1}}}%
\newcommand{\hlkwd}[1]{\textcolor[rgb]{0.004,0.004,0.506}{#1}}%
\let\hlipl\hlkwb

\usepackage{framed}
\makeatletter
\newenvironment{kframe}{%
 \def\at@end@of@kframe{}%
 \ifinner\ifhmode%
  \def\at@end@of@kframe{\end{minipage}}%
  \begin{minipage}{\columnwidth}%
 \fi\fi%
 \def\FrameCommand##1{\hskip\@totalleftmargin \hskip-\fboxsep
 \colorbox{shadecolor}{##1}\hskip-\fboxsep
     % There is no \\@totalrightmargin, so:
     \hskip-\linewidth \hskip-\@totalleftmargin \hskip\columnwidth}%
 \MakeFramed {\advance\hsize-\width
   \@totalleftmargin\z@ \linewidth\hsize
   \@setminipage}}%
 {\par\unskip\endMakeFramed%
 \at@end@of@kframe}
\makeatother

\definecolor{shadecolor}{rgb}{.97, .97, .97}
\definecolor{messagecolor}{rgb}{0, 0, 0}
\definecolor{warningcolor}{rgb}{1, 0, 1}
\definecolor{errorcolor}{rgb}{1, 0, 0}
\newenvironment{knitrout}{}{} % an empty environment to be redefined in TeX

\usepackage{alltt}
%\documentclass[color=usenames,dvipsnames,handout]{beamer}

\usepackage[roman]{../lectures}
%\usepackage[sans]{../lectures}


\hypersetup{pdfpagemode=UseNone,pdfstartview={FitV}}



% Load function to compile and open PDF


% Compile and open PDF






%% New command for inline code that isn't to be evaluated
\definecolor{inlinecolor}{rgb}{0.878, 0.918, 0.933}
\newcommand{\inr}[1]{\colorbox{inlinecolor}{\texttt{#1}}}
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\begin{document}




\begin{frame}[plain]
  \LARGE
%  \maketitle
  \centering
  {\LARGE Lecture 8 -- Multinomial $N$-mixture models: \\ simulation, fitting, and prediction} \\
  {\color{default} \rule{\textwidth}{0.1pt}}
  \vfill
  \large
  WILD(FISH) 8390 \\
  Estimation of Fish and Wildlife Population Parameters \\
  \vfill
  \large
  Richard Chandler \\
  University of Georgia \\
\end{frame}






\section{Overview}



\begin{frame}[plain]
  \frametitle{Outline}
  \Large
  \only<1>{\tableofcontents}%[hideallsubsections]}
  \only<2 | handout:0>{\tableofcontents[currentsection]}%,hideallsubsections]}
\end{frame}



\begin{frame}
  \frametitle{Overview}
  The objectives are the same as with binomial $N$-mixture models. %\\
%  \pause
%  \vfill
  We want to:
  \begin{itemize}
    \item Estimate abundance
    \item Model spatial variation in abundance/density
  \end{itemize}
  \pause
  \vfill
  The difference is that, instead of repeated count data at each site,
  we have data from sampling methods such as:
  \begin{itemize}
    \item<2-> Double observer sampling
    \item<3-> Removal sampling
    \item<4-> Mark-recapture
    \item<5-> Distance sampling
    \item<6-> And many others\dots
  \end{itemize}
\end{frame}




\begin{frame}
  \frametitle{Multinomial $N$-mixture model}
  \small
  State model (with Poisson assumption)
  \begin{gather*}
    \mathrm{log}(\lambda_i) = \beta_0 + \beta_1 {\color{blue} x_{i1}} +
    \beta_2 {\color{blue} x_{i2}} + \cdots \\
    N_i \sim \mathrm{Poisson}(\lambda_i)
  \end{gather*}
  \pause
  \vfill
  Observation model
  \begin{gather*}
    \mathrm{logit}(p_{ij}) = \alpha_0 + \alpha_1 {\color{blue} x_{i1}}
    + \alpha_2 {\color{Purple} w_{ij}} + \cdots \\
    \{y_{i1}, \dots, y_{iK}\}  \sim \mathrm{Multinomial}(N_i,
    \pi(p_{i1}, \dots, p_{iJ}))
  \end{gather*}
  \pause
  \vfill
  \small
  Definitions \\
  $\lambda_i$ -- Expected value of abundance at site $i$ \\
  $N_i$ -- Realized value of abundance at site $i$ \\
  $p_{ij}$ -- Probability of detecting \alert{an individual} at site $i$ on occasion $j$ \\
  $\pi(p)$ -- A function converting $J$ detection probabilities to
  $K$ multinomial cell probabilities \\
  $y_{ik}$ -- Multinomial count data \\
%  \vfill
  $\color{blue} x_1$ and $\color{blue} x_2$ -- site covariates \\
%  \vspace{12pt}
  $\color{Purple} w$ -- observation covariate
\end{frame}




\begin{frame}[fragile]
  \frametitle{The multinomial distribution}
  \small
  This is the first multivariate distribution we've covered. \\
  \[
    \{y_{1}, \dots, y_{K}\}  \sim \mathrm{Multinomial}(N, \{\pi_i, \dots, \pi_K\})
  \]
  \pause
%  \vfill
  The multinomial describes how $N$ objects are distributed among
  $K$ classes (also called bins, categories, etc\dots). \\
  \pause
  \vfill
  Imagine $N=20$ animals could have 3 outcomes with probabilities:
  $\Pr(\mathrm{survived})=0.5$, $\Pr(\mathrm{depredated})=0.3$, $\Pr(\mathrm{starved})=0.2$. \\
  \pause
  \vfill
  Here is one possible outcome:
  \vspace{-6pt}
\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{N} \hlkwb{<-} \hlnum{20}
\hlstd{pi} \hlkwb{<-} \hlkwd{c}\hlstd{(}\hlkwc{survived}\hlstd{=}\hlnum{0.5}\hlstd{,} \hlkwc{depredated}\hlstd{=}\hlnum{0.3}\hlstd{,} \hlkwc{starved}\hlstd{=}\hlnum{0.2}\hlstd{)}
\hlkwd{drop}\hlstd{(}\hlkwd{rmultinom}\hlstd{(}\hlkwc{n}\hlstd{=}\hlnum{1}\hlstd{,} \hlkwc{size}\hlstd{=N,} \hlkwc{prob}\hlstd{=pi))}
\end{alltt}
\begin{verbatim}
##   survived depredated    starved 
##         11          5          4
\end{verbatim}
\end{kframe}
\end{knitrout}
  \pause
  \vfill
  Note that the probabilities must sum to 1. %, $\sum_k \pi_k=1$.
\end{frame}



\begin{frame}
  \frametitle{Sampling methods}
  The beauty of the multinomial $N$-mixture model is that it can
  applied to data from many sampling designs, simply by changing how
  the $\pi$ probabilities are computed. \\
  \pause
  \vfill
  Removal sampling %\\
  \[
    {\bm \pi(p)} = \{p, (1-p)p, (1-p)(1-p)p, \dots, (1-p)^Kp\}
  \]
  \pause \vfill
  Double observer (independent observers, reconciled afterward)
  \[
    {\bm \pi(p)} = \{p_1(1-p_2), p_2(1-p_1), p_1p_2\}
  \]
\end{frame}





\section{Simulation}

\subsection{Removal sampling}

\begin{frame}
  \frametitle{Outline}
  \Large
  \tableofcontents[currentsection,currentsubsection]
\end{frame}




\begin{frame}[fragile]
  \frametitle{Simulation -- No covariates}
  \small
%  \begin{enumerate}[<+->]
%  \item  
  Abundance
\begin{knitrout}\scriptsize
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{nSites} \hlkwb{<-} \hlnum{100}
\hlstd{nVisits} \hlkwb{<-} \hlnum{4}
\hlkwd{set.seed}\hlstd{(}\hlnum{3439}\hlstd{)}  \hlcom{## Make it reproducible}
\hlstd{lambda1} \hlkwb{<-} \hlnum{2.6}  \hlcom{## Expected value of N}
\hlstd{N1} \hlkwb{<-} \hlkwd{rpois}\hlstd{(}\hlkwc{n}\hlstd{=nSites,} \hlkwc{lambda}\hlstd{=lambda1)}
\end{alltt}
\end{kframe}
\end{knitrout}
% \item
  \pause
  \vfill
  Detection probability and data
\begin{knitrout}\scriptsize
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{p1} \hlkwb{<-} \hlnum{0.3}
\hlstd{y1} \hlkwb{<-} \hlkwd{matrix}\hlstd{(}\hlnum{NA}\hlstd{,} \hlkwc{nrow}\hlstd{=nSites,} \hlkwc{ncol}\hlstd{=nVisits)}
\hlkwa{for}\hlstd{(i} \hlkwa{in} \hlnum{1}\hlopt{:}\hlstd{nSites) \{}
    \hlstd{y1[i,]} \hlkwb{<-} \hlkwd{rbinom}\hlstd{(nVisits,} \hlkwc{size}\hlstd{=N1[i],} \hlkwc{prob}\hlstd{=p1)}
\hlstd{\}}
\end{alltt}
\end{kframe}
\end{knitrout}
%\end{enumerate}
  \pause
  \vfill
  Data and latent abundance
\begin{knitrout}\scriptsize
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{cbind}\hlstd{(y1, N1)[}\hlnum{1}\hlopt{:}\hlnum{5}\hlstd{,]}
\end{alltt}
\begin{verbatim}
##              N1
## [1,] 2 2 1 0  3
## [2,] 0 0 0 0  1
## [3,] 2 1 2 2  6
## [4,] 0 0 0 0  1
## [5,] 0 0 0 0  0
\end{verbatim}
\end{kframe}
\end{knitrout}
\end{frame}



\begin{frame}[fragile]
  \frametitle{Simulation -- Covariates}
  \small
%  Two continuous covariates and one categorical covariate with 2 levels
%  \vfill
%  \begin{enumerate}[<+->]
%  \item
  Covariates
  \vspace{-6pt}
\begin{knitrout}\scriptsize
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{forest} \hlkwb{<-} \hlkwd{factor}\hlstd{(}\hlkwd{sample}\hlstd{(}\hlkwd{c}\hlstd{(}\hlstr{"Hardwood"}\hlstd{,} \hlstr{"Mixed"}\hlstd{,} \hlstr{"Pine"}\hlstd{), nSites,} \hlkwc{replace}\hlstd{=}\hlnum{TRUE}\hlstd{))}
\hlstd{forestMixed} \hlkwb{<-} \hlkwd{ifelse}\hlstd{(forest}\hlopt{==}\hlstr{"Mixed"}\hlstd{,} \hlnum{1}\hlstd{,} \hlnum{0}\hlstd{)}        \hlcom{## Dummy}
\hlstd{forestPine} \hlkwb{<-} \hlkwd{ifelse}\hlstd{(forest}\hlopt{==}\hlstr{"Pine"}\hlstd{,} \hlnum{1}\hlstd{,} \hlnum{0}\hlstd{)}          \hlcom{## Dummy}
\hlstd{temp} \hlkwb{<-} \hlkwd{matrix}\hlstd{(}\hlkwd{rnorm}\hlstd{(nSites}\hlopt{*}\hlstd{nVisits),} \hlkwc{nrow}\hlstd{=nSites,} \hlkwc{ncol}\hlstd{=nVisits)}
\end{alltt}
\end{kframe}
\end{knitrout}
% \item
\vfill
  Coefficients, $\lambda$, and $p$
  \vspace{-6pt}
\begin{knitrout}\scriptsize
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{beta0} \hlkwb{<-} \hlnum{0}\hlstd{; beta1} \hlkwb{<-} \hlopt{-}\hlnum{1}\hlstd{; beta2} \hlkwb{<-} \hlnum{1}
\hlstd{lambda2} \hlkwb{<-} \hlkwd{exp}\hlstd{(beta0} \hlopt{+} \hlstd{beta1}\hlopt{*}\hlstd{forestMixed} \hlopt{+} \hlstd{beta2}\hlopt{*}\hlstd{forestPine)}
\hlstd{alpha0} \hlkwb{<-} \hlopt{-}\hlnum{2}\hlstd{; alpha1} \hlkwb{<-} \hlnum{1}
\hlstd{p2} \hlkwb{<-} \hlkwd{plogis}\hlstd{(alpha0} \hlopt{+} \hlstd{alpha1}\hlopt{*}\hlstd{temp)}
\end{alltt}
\end{kframe}
\end{knitrout}
% \item
\vfill
  Simulate occupancy and detection data
  \vspace{-6pt}
\begin{knitrout}\scriptsize
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{N2} \hlkwb{<-} \hlkwd{rpois}\hlstd{(nSites,} \hlkwc{lambda}\hlstd{=lambda2)}         \hlcom{## local abundance }
\hlstd{y2} \hlkwb{<-} \hlkwd{matrix}\hlstd{(}\hlnum{NA}\hlstd{,} \hlkwc{nrow}\hlstd{=nSites,} \hlkwc{ncol}\hlstd{=nVisits)}
\hlkwa{for}\hlstd{(i} \hlkwa{in} \hlnum{1}\hlopt{:}\hlstd{nSites) \{}
    \hlstd{y2[i,]} \hlkwb{<-} \hlkwd{rbinom}\hlstd{(nVisits,} \hlkwc{size}\hlstd{=N2[i],} \hlkwc{prob}\hlstd{=p2[i,])}
\hlstd{\}}
\end{alltt}
\end{kframe}
\end{knitrout}
%\end{enumerate}
\end{frame}




\begin{frame}[fragile]
  \frametitle{Simulated data}
  \begin{columns}
    \begin{column}{0.4\textwidth}
      \small
      Observations
%      \tiny
\begin{knitrout}\scriptsize
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{y2[}\hlnum{1}\hlopt{:}\hlnum{20}\hlstd{,]}
\end{alltt}
\begin{verbatim}
##       [,1] [,2] [,3] [,4]
##  [1,]    1    1    0    0
##  [2,]    0    0    3    2
##  [3,]    0    1    0    0
##  [4,]    0    1    0    0
##  [5,]    0    0    0    0
##  [6,]    0    0    0    1
##  [7,]    0    0    0    0
##  [8,]    0    2    0    0
##  [9,]    0    1    0    1
## [10,]    0    1    0    0
## [11,]    0    0    0    1
## [12,]    0    0    1    0
## [13,]    0    0    0    0
## [14,]    0    0    0    0
## [15,]    0    0    0    0
## [16,]    0    0    0    0
## [17,]    0    0    0    0
## [18,]    0    0    0    0
## [19,]    0    0    1    0
## [20,]    0    0    0    1
\end{verbatim}
\end{kframe}
\end{knitrout}
  \end{column}
  \begin{column}{0.6\textwidth}
    \pause
%    \scriptsize
    {\centering Summary stats \\}
    \vspace{24pt}
  Detections at each site \\
\begin{knitrout}\scriptsize
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlcom{# Max count at each site}
\hlstd{maxCounts} \hlkwb{<-} \hlkwd{apply}\hlstd{(y2,} \hlnum{1}\hlstd{, max)}
\hlkwd{table}\hlstd{(maxCounts)}
\end{alltt}
\begin{verbatim}
## maxCounts
##  0  1  2  3 
## 55 33  9  3
\end{verbatim}
\end{kframe}
\end{knitrout}
\pause
\vfill
\small
Proportion of sites known to be occupied \\
\begin{knitrout}\scriptsize
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{naiveOccupancy} \hlkwb{<-} \hlkwd{sum}\hlstd{(maxCounts}\hlopt{>}\hlnum{0}\hlstd{)}\hlopt{/}\hlstd{nSites}
\hlstd{naiveOccupancy}
\end{alltt}
\begin{verbatim}
## [1] 0.45
\end{verbatim}
\end{kframe}
\end{knitrout}

  \end{column}
  \end{columns}
\end{frame}





\subsection{Double observer sampling}

\begin{frame}
  \frametitle{Outline}
  \Large
  \tableofcontents[currentsection,currentsubsection]
\end{frame}




\section{Prediction}



\begin{frame}
  \frametitle{Outline}
  \Large
  \tableofcontents[currentsection]
\end{frame}



\subsection{Likelihood-based methods}



\begin{frame}[fragile]
  \frametitle{Prepare data in `unmarked'}
  \small
\begin{knitrout}\tiny
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{umf} \hlkwb{<-} \hlkwd{unmarkedFramePCount}\hlstd{(}\hlkwc{y}\hlstd{=y2,} \hlkwc{siteCovs}\hlstd{=}\hlkwd{data.frame}\hlstd{(forest),} \hlkwc{obsCovs}\hlstd{=}\hlkwd{list}\hlstd{(}\hlkwc{temp}\hlstd{=temp))}
\end{alltt}
\end{kframe}
\end{knitrout}
\pause
\begin{knitrout}\tiny
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{summary}\hlstd{(umf)}
\end{alltt}
\begin{verbatim}
## unmarkedFrame Object
## 
## 100 sites
## Maximum number of observations per site: 4 
## Mean number of observations per site: 4 
## Sites with at least one detection: 45 
## 
## Tabulation of y observations:
##   0   1   2   3 
## 332  52  13   3 
## 
## Site-level covariates:
##       forest  
##  Hardwood:31  
##  Mixed   :32  
##  Pine    :37  
## 
## Observation-level covariates:
##       temp          
##  Min.   :-3.229012  
##  1st Qu.:-0.603218  
##  Median :-0.019813  
##  Mean   :-0.001029  
##  3rd Qu.: 0.663820  
##  Max.   : 3.001200
\end{verbatim}
\end{kframe}
\end{knitrout}
\end{frame}




\begin{frame}[fragile]
  \frametitle{Fit the model}
  \footnotesize
  \inr{pcount} is similar to \inr{occu}, but there's a new argument
  (\texttt{K}) that should be an integer much 
  greater than the highest possible value of local abundance. 
\begin{knitrout}\tiny
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{fm} \hlkwb{<-} \hlkwd{pcount}\hlstd{(}\hlopt{~}\hlstd{temp} \hlopt{~}\hlstd{forest, umf,} \hlkwc{K}\hlstd{=}\hlnum{100}\hlstd{)}
\hlstd{fm}
\end{alltt}
\begin{verbatim}
## 
## Call:
## pcount(formula = ~temp ~ forest, data = umf, K = 100)
## 
## Abundance:
##             Estimate    SE      z  P(>|z|)
## (Intercept)   -0.326 0.366 -0.891 0.372706
## forestMixed   -0.326 0.461 -0.706 0.480137
## forestPine     1.207 0.336  3.595 0.000324
## 
## Detection:
##             Estimate    SE     z  P(>|z|)
## (Intercept)    -1.96 0.313 -6.26 3.79e-10
## temp            1.18 0.205  5.73 9.83e-09
## 
## AIC: 373.6761
\end{verbatim}
\end{kframe}
\end{knitrout}
\pause
\vfill
Compare to actual parameter values:
\begin{knitrout}\tiny
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{c}\hlstd{(}\hlkwc{beta0}\hlstd{=beta0,} \hlkwc{beta1}\hlstd{=beta1,} \hlkwc{beta2}\hlstd{=beta2);} \hlkwd{c}\hlstd{(}\hlkwc{alpha0}\hlstd{=alpha0,} \hlkwc{alpha1}\hlstd{=alpha1)}
\end{alltt}
\begin{verbatim}
## beta0 beta1 beta2 
##     0    -1     1
## alpha0 alpha1 
##     -2      1
\end{verbatim}
\end{kframe}
\end{knitrout}
\end{frame}




\begin{frame}[fragile]
  \frametitle{Make sure $K$ is high enough}
%  \begin{columns}
%    \begin{column}{0.95\paperwidth}

  Estimates should not change when you increase $K$.
  \vspace{-6pt}
\begin{knitrout}\tiny
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{round}\hlstd{(}\hlkwd{coef}\hlstd{(fm),} \hlkwc{digits}\hlstd{=}\hlnum{4}\hlstd{)}
\end{alltt}
\begin{verbatim}
##         lam(Int) lam(forestMixed)  lam(forestPine)           p(Int)          p(temp) 
##          -0.3260          -0.3258           1.2073          -1.9615           1.1760
\end{verbatim}
\end{kframe}
\end{knitrout}
\pause
\vfill
  Looks good:
  \vspace{-6pt}
\begin{knitrout}\tiny
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{fm.test} \hlkwb{<-} \hlkwd{pcount}\hlstd{(}\hlopt{~}\hlstd{temp} \hlopt{~}\hlstd{forest, umf,} \hlkwc{K}\hlstd{=}\hlnum{150}\hlstd{)}
\hlkwd{round}\hlstd{(}\hlkwd{coef}\hlstd{(fm.test),} \hlkwc{digits}\hlstd{=}\hlnum{4}\hlstd{)}
\end{alltt}
\begin{verbatim}
##         lam(Int) lam(forestMixed)  lam(forestPine)           p(Int)          p(temp) 
##          -0.3260          -0.3258           1.2073          -1.9615           1.1760
\end{verbatim}
\end{kframe}
\end{knitrout}
\pause
\vfill
If the estimates do change, increase $K$ until they stabilize.
%    \end{column}
%  \end{columns}
\end{frame}



\begin{frame}[fragile]
  \frametitle{\normalsize Empirical Bayes -- Site-level abundance}
\begin{knitrout}\scriptsize
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{re} \hlkwb{<-} \hlkwd{ranef}\hlstd{(fm)}
\hlkwd{plot}\hlstd{(re,} \hlkwc{layout}\hlstd{=}\hlkwd{c}\hlstd{(}\hlnum{4}\hlstd{,}\hlnum{3}\hlstd{),} \hlkwc{subset}\hlstd{=site}\hlopt{%in%}\hlnum{1}\hlopt{:}\hlnum{12}\hlstd{,} \hlkwc{xlim}\hlstd{=}\hlkwd{c}\hlstd{(}\hlopt{-}\hlnum{1}\hlstd{,} \hlnum{11}\hlstd{),} \hlkwc{lwd}\hlstd{=}\hlnum{5}\hlstd{)}
\end{alltt}
\end{kframe}
\end{knitrout}
\end{frame}





\begin{frame}[fragile]
  \frametitle{Total abundance (in surveyed region)}
\begin{knitrout}\scriptsize
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{N.total.post} \hlkwb{<-} \hlkwd{predict}\hlstd{(re,} \hlkwc{func}\hlstd{=sum,} \hlkwc{nsim}\hlstd{=}\hlnum{1000}\hlstd{)}
\hlkwd{hist}\hlstd{(N.total.post,} \hlkwc{freq}\hlstd{=}\hlnum{FALSE}\hlstd{,} \hlkwc{main}\hlstd{=}\hlstr{""}\hlstd{,} \hlkwc{xlab}\hlstd{=}\hlstr{"N total"}\hlstd{,} \hlkwc{ylab}\hlstd{=}\hlstr{"Probability"}\hlstd{)}
\end{alltt}
\end{kframe}
\end{knitrout}
\end{frame}






\begin{frame}[fragile]
  \frametitle{Prediction in `unmarked'}
  \small
  Create \texttt{data.frame} with prediction covariates. 
  \vspace{-6pt}
\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{pred.data} \hlkwb{<-} \hlkwd{data.frame}\hlstd{(}\hlkwc{forest}\hlstd{=}\hlkwd{c}\hlstd{(}\hlstr{"Hardwood"}\hlstd{,} \hlstr{"Mixed"}\hlstd{,} \hlstr{"Pine"}\hlstd{),}
                        \hlkwc{temp}\hlstd{=}\hlnum{0}\hlstd{)}
\end{alltt}
\end{kframe}
\end{knitrout}
\pause
\vfill
Get predictions of $\lambda$ for each row of prediction data.
  \vspace{-6pt}
\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{lambda.pred} \hlkwb{<-} \hlkwd{predict}\hlstd{(fm,} \hlkwc{newdata}\hlstd{=pred.data,}
                       \hlkwc{type}\hlstd{=}\hlstr{'state'}\hlstd{,} \hlkwc{append}\hlstd{=}\hlnum{TRUE}\hlstd{)}
\end{alltt}
\end{kframe}
\end{knitrout}
\pause
\vfill
  View $\lambda$ predictions
  \vspace{-6pt}
\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{print}\hlstd{(}\hlkwd{head}\hlstd{(lambda.pred),} \hlkwc{digits}\hlstd{=}\hlnum{2}\hlstd{)}
\end{alltt}
\begin{verbatim}
##   Predicted   SE lower upper   forest temp
## 1      0.72 0.26  0.35   1.5 Hardwood    0
## 2      0.52 0.22  0.23   1.2    Mixed    0
## 3      2.41 0.64  1.44   4.0     Pine    0
\end{verbatim}
\end{kframe}
\end{knitrout}
\end{frame}



% \begin{frame}[fragile]
%   \frametitle{Prediction in `unmarked'}
%   \small
%   View $\lambda$ predictions
% <<psi-head,size='footnotesize'>>=
% print(head(lambda.pred), digits=2)
% @
% \end{frame}






% \begin{frame}[fragile]
%   \frametitle{Prediction in `unmarked'}
% <<pred-psi1,fig.width=7,fig.height=5.5,size='tiny',out.width='80%',fig.align='center',eval=FALSE>>=
% bpx <- barplot(lambda.pred$Predicted, ylab="Expected value of abundance", #col="blue",
%                ylim=c(0,3.5), names=lambda.pred$forest, xlab="Forest type"); box()
% arrows(bpx, lambda.pred$Predicted, bpx, lambda.pred$Predicted+lambda.pred$SE,
%        angle=90, length=0.1)
% @   
% \end{frame}







\begin{frame}
  \frametitle{In-class exercise}
  % \small
  % \begin{enumerate}
  %   \item Predict
  %   \end{enumerate}
  \centering
  Graph $p$ as a function of temperature. Include 95\% confidence intervals. \\
\end{frame}




\subsection{Bayesian methods: posterior prediction}



\begin{frame}[plain]
  \frametitle{Outline}
  \Large
  \tableofcontents[currentsection,currentsubsection]
\end{frame}




% \begin{frame}[fragile]
%   \frametitle{The BUGS model}
% <<bugs,size='scriptsize',echo=FALSE>>=
% writeLines(readLines("Nmix-model-covs.jag"))
% @
% <<jagsUI,include=FALSE>>=
% library(jagsUI)
% @ 
% \end{frame}





% \begin{frame}[fragile]
%   \frametitle{Data, inits, and parameters}
%   Put data in a named list
%   \vspace{-12pt}
% <<bugs-data,size='small'>>=
% jags.data <- list(y=y2, temp=temp,
%                   forestMixed=forestMixed,
%                   forestPine=forestPine,
%                   nSites=nSites, nOccasions=nVisits)
% @
% \pause
% \vfill
%   Initial values
%   \vspace{-12pt}
% <<bugs-inits,size='small'>>=
% jags.inits <- function() {
%     list(beta0=rnorm(1), alpha0=rnorm(1), N=maxCounts)
% }
% @ 
% \pause
% \vfill
%   Parameters to monitor
%   \vspace{-12pt}
% <<bugs-pars,size='small'>>=
% jags.pars <- c("beta0", "beta1", "beta2",
%                "alpha0", "alpha1", "totalAbundance")
% @ 
% \end{frame}





% \begin{frame}[fragile]
%   \frametitle{MCMC}
%   \small
% <<bugs-mcmc,size='scriptsize',message=FALSE,cache=TRUE>>=
% library(jagsUI)
% jags.post.samples <- jags.basic(data=jags.data, inits=jags.inits,
%                                 parameters.to.save=c(jags.pars, "N"), ## NOTE "N"!
%                                 model.file="Nmix-model-covs.jag",
%                                 n.chains=3, n.adapt=100, n.burnin=0,
%                                 n.iter=2000, parallel=TRUE)
% @ 
% \end{frame}



% \begin{frame}[fragile]
%   \frametitle{Summarize output}
% <<bugs-sum,size='tiny'>>=
% summary(jags.post.samples[,jags.pars])
% @ 
% \end{frame}


% \begin{frame}[fragile]
%   \frametitle{Local abundance}
% <<localN,out.width='70%',fig.align='center',size='scriptsize'>>=
% plot(jags.post.samples[,paste0("N[", 1:4, "]")])
% @   
% \end{frame}



% \begin{frame}[fragile]
%   \frametitle{Traceplots and density plots}
% <<bugs-plot1,size='footnotesize',out.width="0.7\\textwidth",fig.align='center'>>=
% plot(jags.post.samples[,jags.pars[1:3]])
% @ 
% \end{frame}



% \begin{frame}[fragile]
%   \frametitle{Traceplots and density plots}
% <<bugs-plot2,size='footnotesize',out.width="0.7\\textwidth",fig.align='center'>>=
% plot(jags.post.samples[,jags.pars[4:5]])
% @ 
% \end{frame}




% \begin{frame}[fragile]
%   \frametitle{Bayesian prediction}
%   \small
%   First, extract the $p$ coefficients
%   \vspace{-6pt}
% <<psi-coefs,size='scriptsize'>>=
% p.coef.post <- as.matrix(jags.post.samples[,c("alpha0","alpha1")])
% head(p.coef.post, n=4)
% @
%   \pause
%   \vfill
%   Create prediction matrix, one row for each MCMC iteration.
%   \vspace{-6pt}
% %  Columns represent covariate values. 
% <<p-predmat,size='scriptsize'>>=
% n.iter <- nrow(p.coef.post)
% temp.pred <- seq(-3, 3, length=50)
% p.post.pred <- matrix(NA, nrow=n.iter, ncol=length(temp.pred))
% @   
%   \pause
%   \vfill
%   Predict $p$ for each MCMC iteration.
%   \vspace{-6pt}
% %  using covariate values from \inr{pred.data}. 
% <<psi-pred-bayes,size='scriptsize'>>=
% for(i in 1:n.iter) {
%     p.post.pred[i,] <- plogis(p.coef.post[i,"alpha0"] +
%                               p.coef.post[i,"alpha1"]*temp.pred)
% }
% @ 
% \end{frame}





% \begin{frame}[fragile]
%   \frametitle{Bayesian prediction}
% %  Now with posterior mean and 95\% CI
% <<psi-pred-post-meanCI,size='tiny',fig.align='center',out.width='70%',fig.height=5,echo=-(1),dev='png',cache=TRUE,dpi=200>>=
% par(mai=c(0.9,0.9,0.1,0.1))  
% plot(temp.pred, p.post.pred[1,], type="l", xlab="Temperature (standardized)",
%      ylab="Detection probability", ylim=c(0, 1), col=gray(0.8))
% for(i in seq(1, n.iter, by=10)) {  ## Thin by 10
%     lines(temp.pred, p.post.pred[i,], col=gray(0.8))  }
% pred.post.mean <- colMeans(p.post.pred)
% pred.post.lower <- apply(p.post.pred, 2, quantile, prob=0.025)
% pred.post.upper <- apply(p.post.pred, 2, quantile, prob=0.975)
% lines(temp.pred, pred.post.mean, col="blue")
% lines(temp.pred, pred.post.lower, col="blue", lty=2)
% lines(temp.pred, pred.post.upper, col="blue", lty=2)
% @ 
% \end{frame}





\subsection{Bayesian methods: prior prediction}



\begin{frame}[plain]
  \frametitle{Outline}
  \Large
  \tableofcontents[currentsection,currentsubsection]
\end{frame}






\begin{frame}
  \frametitle{Prior sensitivity}
  Questions
  \begin{itemize}
    \item What are the implied priors on $\lambda$ and $p$?
    \item What would be the consequence of changing the priors?
  \end{itemize}
  \pause
  \vfill
  \alert{Prior predictive checks} can help us answer these questions. \\
  \pause
  \vfill
  Prior prediction can be acheived by replacing the data with missing values \\
\end{frame}






% \begin{frame}[fragile]
%   \frametitle{Prior sampling}
%   Replace data with missing values
%   \vspace{-12pt}
% <<bugs-data2,size='small'>>=
% jags.data2 <- jags.data
% jags.data2$y[] <- NA      ## Replace data with missing values
% @
%   \pause
%   \vfill
%   Fit model (Really, we're just sampling from the prior)
% <<bugs-mcmc-prior,size='scriptsize',message=FALSE,cache=TRUE>>=
% jags.prior.samples <- jags.basic(data=jags.data2, inits=jags.inits,
%                                  parameters.to.save=jags.pars,
%                                  model.file="Nmix-model-covs.jag",
%                                  n.chains=3, n.adapt=100, n.burnin=0,
%                                  n.iter=2000, parallel=TRUE)
% @ 
% \end{frame}




\begin{frame}[fragile]
  \frametitle{Prior summary}
\begin{knitrout}\tiny
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{summary}\hlstd{(jags.prior.samples)}
\end{alltt}


{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error in h(simpleError(msg, call)): error in evaluating the argument 'object' in selecting a method for function 'summary': object 'jags.prior.samples' not found}}\end{kframe}
\end{knitrout}
\end{frame}






% \begin{frame}[fragile]
%   \frametitle{Prior prediction}
%   \small
%   Push the prior samples through the model to predict $p$
% <<psi-coefs-prior,size='scriptsize'>>=
% p.coef.prior <- as.matrix(jags.prior.samples[,c("alpha0","alpha1")])
% p.prior.pred <- matrix(NA, nrow=n.iter, ncol=length(temp.pred))
% for(i in 1:n.iter) {
%     p.prior.pred[i,] <- plogis(p.coef.prior[i,"alpha0"] +
%                                p.coef.prior[i,"alpha1"]*temp.pred)
% }
% @ 
% \end{frame}





% \begin{frame}[fragile]
%   \frametitle{Bayesian prediction}
%   Compute prior mean and 95\% CI for $p$ predictions
% <<prior-post-pred-1,size='scriptsize'>>=
% pred.prior.mean <- colMeans(p.prior.pred)
% pred.prior.lower <- apply(p.prior.pred, 2, quantile, prob=0.025)
% pred.prior.upper <- apply(p.prior.pred, 2, quantile, prob=0.975)
% @
%   \pause
%   \vfill
%   Show credible regions using shaded polygons. Include a few prior prediction lines.
% <<prior-post-pred-2,size='scriptsize',fig.height=6,dev='png',dpi=200,fig.show='hide'>>=
% plot(temp.pred, p.post.pred[1,], type="n", xlab="Temperature (standardized)",
%      ylab="Detection probability", ylim=c(0, 1.3), col=gray(0.8))
% polygon(x=c(temp.pred, rev(temp.pred)),
%         y=c(pred.post.lower, rev(pred.post.upper)),
%         col=rgb(0,0,1,0.5), border=NA)                   # Post CI
% polygon(x=c(temp.pred, rev(temp.pred)),
%         y=c(pred.prior.lower, rev(pred.prior.upper)),
%         col=rgb(0,1,0,0.5), border=NA)                   # Prior CI
% for(i in seq(1, n.iter, by=100)) {  ## Thin by 100
%     lines(temp.pred, p.prior.pred[i,], col=gray(0.8))  } # Prior preds
% lines(temp.pred, pred.post.mean, col="blue", lwd=2)
% lines(temp.pred, pred.prior.mean, col="darkgreen", lwd=2)
% legend(-3, 1.3, c("Prior mean", "Prior samples", "Posterior mean"),
%        col=c("darkgreen", "grey", "blue"), lwd=2)
% @ 
% \end{frame}



% \begin{frame}
%   \frametitle{Prior and posterior prediction}
%   \vspace{-3pt}
%   \centering
%   \includegraphics[width=0.9\textwidth]{figure/prior-post-pred-2-1}  \\
% \end{frame}



% \begin{frame}
%   \frametitle{Prior predictive recap}
%   There are two common strategies for specifying priors:
%   \begin{enumerate}
%     \item Use uniform/flat priors to obtain results that will often be
%       similar to likelihood-based methods.
%     \item Use priors that reflect available information.
%   \end{enumerate}
%   \pause
%   \vfill
%   The second approach can be used even if there isn't much prior
%   information available. Priors can allow for the
%   possibility of being ``surprised'' by the data, but without
%   putting most of the prior weight on extreme values. \\
%   \pause
%   \vfill
%   Often, highly diffuse priors on the link scales result in most of the
%   prior weight being on extreme values on the natural scales. \\
%   \pause
%   \vfill
%   Prior predictive checks can be used to assess this possibility, and
%   should be a standard component of Bayesian analysis. \\
% \end{frame}



\section{Assignment}




\begin{frame}[fragile]
  \frametitle{Assignment}
  % \small
  \footnotesize
  Create a self-contained R script or Rmarkdown file
  to do the following:
  \vfill
  \begin{enumerate}
%    \small
    \footnotesize
    \item Using the simulated data, compare the prior and posterior
      predictive distributions of $\lambda$ for each of the 3 forest
      types. 
    \item Change the priors for $\alpha_0$ and $\alpha_1$ from
      \inr{dnorm(0,0.5)} to \inr{dnorm(0, 0.001)} and then compare the
      prior and posterior predictions of $p$ as a function of
      temperature. Make the same graph as we made above. How
      sensitive is the posterior to the prior?
    \item Fit a binomial $N$-mixture model to the Canada warbler data
      using `unmarked'. The data include: 
      \begin{itemize}
        \footnotesize
        \item Response: \texttt{cawa1, cawa2, cawa3, cawa4}
        \item Site covs: \texttt{Elevation, Wind, Noise}
      \end{itemize}
    \item Graph the predictions of $\lambda$ over the 
      elevation range, along with 95\% CIs.
  \end{enumerate}
  \vfill
  Upload your {\tt .R} or {\tt .Rmd} file to ELC before Monday. 
\end{frame}





\end{document}

