\documentclass[color=usenames,dvipsnames]{beamer}\usepackage[]{graphicx}\usepackage[]{color}
% maxwidth is the original width if it is less than linewidth
% otherwise use linewidth (to make sure the graphics do not exceed the margin)
\makeatletter
\def\maxwidth{ %
  \ifdim\Gin@nat@width>\linewidth
    \linewidth
  \else
    \Gin@nat@width
  \fi
}
\makeatother

\definecolor{fgcolor}{rgb}{0, 0, 0}
\newcommand{\hlnum}[1]{\textcolor[rgb]{0.69,0.494,0}{#1}}%
\newcommand{\hlstr}[1]{\textcolor[rgb]{0.749,0.012,0.012}{#1}}%
\newcommand{\hlcom}[1]{\textcolor[rgb]{0.514,0.506,0.514}{\textit{#1}}}%
\newcommand{\hlopt}[1]{\textcolor[rgb]{0,0,0}{#1}}%
\newcommand{\hlstd}[1]{\textcolor[rgb]{0,0,0}{#1}}%
\newcommand{\hlkwa}[1]{\textcolor[rgb]{0,0,0}{\textbf{#1}}}%
\newcommand{\hlkwb}[1]{\textcolor[rgb]{0,0.341,0.682}{#1}}%
\newcommand{\hlkwc}[1]{\textcolor[rgb]{0,0,0}{\textbf{#1}}}%
\newcommand{\hlkwd}[1]{\textcolor[rgb]{0.004,0.004,0.506}{#1}}%
\let\hlipl\hlkwb

\usepackage{framed}
\makeatletter
\newenvironment{kframe}{%
 \def\at@end@of@kframe{}%
 \ifinner\ifhmode%
  \def\at@end@of@kframe{\end{minipage}}%
  \begin{minipage}{\columnwidth}%
 \fi\fi%
 \def\FrameCommand##1{\hskip\@totalleftmargin \hskip-\fboxsep
 \colorbox{shadecolor}{##1}\hskip-\fboxsep
     % There is no \\@totalrightmargin, so:
     \hskip-\linewidth \hskip-\@totalleftmargin \hskip\columnwidth}%
 \MakeFramed {\advance\hsize-\width
   \@totalleftmargin\z@ \linewidth\hsize
   \@setminipage}}%
 {\par\unskip\endMakeFramed%
 \at@end@of@kframe}
\makeatother

\definecolor{shadecolor}{rgb}{.97, .97, .97}
\definecolor{messagecolor}{rgb}{0, 0, 0}
\definecolor{warningcolor}{rgb}{1, 0, 1}
\definecolor{errorcolor}{rgb}{1, 0, 0}
\newenvironment{knitrout}{}{} % an empty environment to be redefined in TeX

\usepackage{alltt}
%\documentclass[color=usenames,dvipsnames,handout]{beamer}

\usepackage[roman]{../lectures}
%\usepackage[sans]{../lectures}


\hypersetup{pdfpagemode=UseNone,pdfstartview={FitV}}




% Load function to compile and open PDF


% Compile and open PDF





% New command for inline code that isn't to be evaluated
\definecolor{inlinecolor}{rgb}{0.878, 0.918, 0.933}
\newcommand{\inr}[1]{\colorbox{inlinecolor}{\texttt{#1}}}
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\begin{document}




\begin{frame}[plain]
  \LARGE
  \centering
  {
    \LARGE Lecture 12 -- Spatial capture-recapture \\
    for closed populations: \\
    \Large simulation, fitting, and prediction \\
  }
  {\color{default} \rule{\textwidth}{0.1pt} }
  \vfill
  \large
  WILD(FISH) 8390 \\
  Estimation of Fish and Wildlife Population Parameters \\
  \vfill
  \large
  Richard Chandler \\
  University of Georgia \\
\end{frame}






\section{Overview}



\begin{frame}[plain]
  \frametitle{Outline}
  \Large
  \only<1>{\tableofcontents}%[hideallsubsections]}
  \only<2 | handout:0>{\tableofcontents[currentsection]}%,hideallsubsections]}
\end{frame}



\begin{frame}
  \frametitle{SCR overview}
  {\centering There are two motivations for SCR \\}
  \vfill
  \begin{enumerate}
    \item Improved inference
    \begin{itemize}
      \item<1-> Non-spatial models can't properly account for sources
        of variation in $p$ that can induce bias in $N$ estimators.
        \begin{itemize}
          \item<1-> Distance to traps
          \item<1-> Trap-specific covariates
        \end{itemize}
      \item<2-> Ability to estimate \alert{density}, not just $N$ in an
        unknown region. 
    \end{itemize}
    \pause
    \vfill
  \item<3-> Improved science
  \begin{itemize}
    \item<3-> We can ask new questions
      \begin{itemize}
        \item<3-> What influences spatial variation in density?
        \item<4-> How do survival and recruitment vary in space and time?
        \item<5-> How does movement influence density and detectability?
      \end{itemize}
    \end{itemize}
  \end{enumerate}
\end{frame}



\begin{frame}
  \frametitle{Mark-recapture overview}
  The simplest estimator of abundance is 
  \[
    \hat{N} = \frac{n}{\hat{p}}
  \]
  where $n$ is the number of individuals detected, $p$ is detection
  probability, and $E(n)=Np$. \\
  \pause
  \vfill
  In distance sampling, we modeled detection probability as a
  function of distance, and we replaced $p$ with average detection
  probability. \\ 
  \pause
  \vfill
  Spatial capture recapture can be thought of in a similar way, but we 
  average detection probability over the spatial distribution of
  individuals, not just over distance. 
\end{frame}





\begin{frame}
  \frametitle{SCR data}
  \small
  % SCR capture histories histories have 3 dimensions instead of two. \\
  % \pause
  % \vfill
  SCR capture histories can be organized as a 3D array where $y_{ijk}$
  indicates if individual $i=1,\dots,n$, was captured in trap
  $j=1,\dots,J$ on occasion $k=1,\dots,K$. \\
  \pause \vfill
  Here an example of a ``flatted array'' with $n=4$ animals captured
  at $J=3$ traps on $K=2$ occasions. \\
  \centering
  \vfill  
  \begin{tabular}{lccccccc}
    \hline
    & \multicolumn{7}{c}{Occasion} \\
    \cline{2-8}
    & \multicolumn{3}{c}{1} & & \multicolumn{3}{c}{2} \\
    \cline{2-4} \cline{6-8}
    & \multicolumn{3}{c}{Trap} & & \multicolumn{3}{c}{Trap} \\
    \cline{2-4} \cline{6-8}
    Individual & 1 & 2 & 3 & & 1 & 2 & 3 \\
    \hline
    1 & 0 & 0 & 0 & & 1 & 0 & 1 \\
    2 & 1 & 1 & 1 & & 0 & 1 & 1 \\
    3 & 0 & 1 & 0 & & 0 & 0 & 0 \\
    4 & 0 & 1 & 1 & & 1 & 0 & 0 \\
    \hline
  \end{tabular}
  \pause
  \vfill
  \flushleft
  Because we know the coordinates of the traps, we also know when and
  where each individual was detected. \\
  \pause
  \vfill
  This spatial information has been available all along, but it wasn't
  utilized to estimate density until Efford (2004, Oikos). \\
\end{frame}




% \begin{frame}
%   \frametitle{In-class exercise}
%   Building off the previous example\dots
%   \begin{enumerate}
%     \item Compute $\bar{p}$ for line-transect sampling when
%       $\sigma=50, 100, \mathrm{and}\, 200$, instead of $\sigma=25$.  
%     \item Repeat, but for point-transect sampling. 
%   \end{enumerate}
% \end{frame}





\begin{frame}
  \frametitle{\large Closed population model ($N$ known hypothetically) }
  \small
  State model (a spatial point process model) \\
  \begin{gather*}
    \lambda(s) = \beta_0 + \beta_1 w_1(s) \dots \\
    \Lambda = \int_{\mathcal{S}} \lambda(s) \; \mathrm{d}s \\
    N \sim \mathrm{Pois}(\Lambda) \\
    s_i \sim \lambda(s)/\Lambda \;\; \mathrm{for}\, i=1,\dots,N 
  \end{gather*}
  \pause
  \vfill
  Observation model (supposing $N$ was known)
  \begin{gather*}
    p_{ij} = g_0\exp(\|s_i - x_j\|/(2\sigma^2))  \;\; \mathrm{for}\, j=1,\dots,J  \\
    y_{ijk} \sim \mathrm{Bernoulli}(p_{ij})
  \end{gather*}
  \pause
%  \vfill
  \small
  Definitions \\
  $N$ -- Population size \\
  \hangindent=0.8cm $y_{ij}$ -- encounter histories, indicating if
  individual $i$ was captured on occasion $j$ \\  
  $p$ -- Capture probability
  \pause
  \vfill
  The problem with this formulation is that we don't observe the ``all
  zero'' encounter histories (and thus we don't know $N$). 
\end{frame}





\begin{frame}
  \frametitle{Closed population estimation options}
  Conditional likelihood \\
  \begin{itemize}
    \item Estimate $\tilde{p}$\footnote{$\tilde{p}$ depends on $\lambda(s), g_0,
        \sigma, \mathcal{S}, x$}, and then compute $\hat{N}=n/\hat{\tilde{p}}$
  \end{itemize}
  \pause
  \vfill
  Joint likelihood \\
  \begin{itemize}
    \item Estimate $N$ and $\tilde{p}$ jointly
    \item Joint likelihood can be written as
      \begin{itemize}
      \item $L(N,g_0,\sigma;y,n) = p(y|n,p)p(n|N,p)$ or
      \item $L(N,g_0,\sigma;y,n) = p(y,n|N,p)$
      \end{itemize}
  \end{itemize}
  \pause \vfill
  Data augmentation \\
  \begin{itemize}
    \item Tack on many ``all zero'' encounter histories and estimate
      how many of them actually occurred
    \item Usually, but not necessarily, used in Bayesian inference
  \end{itemize}
\end{frame}









\begin{frame}
  \frametitle{Joint likelihood}
  % \footnotesize
  \small
  The joint likelihood looks similar to the nonspatial likelihood,
  except that we have a third dimension for $y$ and we have to
  integrate out the latent activity center $s_i$. 
  \pause
  \vfill
  \flushleft
  \begin{equation*}
%  \begin{multline*}
%    L(N,p; y,n) =                                          \\
    L(N,p; y,n) = \left\{\prod_{i=1}^n \prod_{j=1}^J \prod_{k=1}^K p_{ij}^{y_{ijj}}(1-p_{ij})^{1-y_{ijk}}\right\}
%    \left\{\frac{N!}{(N-n)!}  \left(\prod_{j=1}^J(1-p)\right)^{N-n} \right\}
    \frac{N!}{(N-n)!}  \left(q^*\right)^{N-n}
%  \end{multline*}
  \end{equation*}
\end{frame}



\begin{frame}
  \frametitle{Model variations}
  Aside from the approach to estimation, the key consideration
  concerns the sources of variation in capture probability ($p$). \\
  \pause
  \vfill
  Otis et al. (1978, Wildlife Monographs) identified several model variations
  \begin{itemize}
    \small
    \item $M_0$ -- $p$ is constant
    \item $M_t$ -- unique $p$ for each capture occasion
    \item \hangindent=0.8cm $M_b$ -- behavioral response with $p$ different than
      recapture probability $c$
    \item $M_h$ -- individual heterogeneity in $p$
  \end{itemize}
  \pause \vfill
  These can be combined, but beware of identifiability issues. See
  Otis et al. (1978) for details.  \\
  \pause \vfill
  Later we'll talk about another important class of models, the
  ``individual covariate'' models.  
\end{frame}




\begin{frame}
  \frametitle{Software options}
  \small
  Program DENSITY
  \begin{itemize}
  \footnotesize
    \item Has the most model types
    \item Written for Windows, but can be executed on other platforms  
  \end{itemize}
  R package `oSCR'
  \begin{itemize}
  \footnotesize
    \item Function \inr{mark} runs MARK from R.
  \end{itemize}
  R package `marked'
  \begin{itemize}
  \footnotesize
    \item Includes CJS and JS models
  \end{itemize}
  R package `mra'
  \begin{itemize}
  \footnotesize
    \item Includes closed-population, CJS, and JS models
  \end{itemize}
  R package `Rcapture'
  \begin{itemize}
  \footnotesize
    \item Includes closed-population
  \end{itemize}
  R package `unmarked'
  \begin{itemize}
  \footnotesize
    \item Likelihood-based data augmentation with \inr{occu}
  \end{itemize}
  R package `secr'
  \begin{itemize}
  \footnotesize
    \item Designed for spatially explicit models, but see \inr{closedN}
  \end{itemize}
\end{frame}




\section{Simulation}

%\section{Model $M_0$}


%\subsection{Simulation}


\subsection{Model $M_0$}




\begin{frame}
  \frametitle{Outline}
  \Large
%  \tableofcontents[currentsection,currentsubsection]
  \tableofcontents[currentsection]
\end{frame}









\begin{frame}[fragile]
  \frametitle{Model $M_0$}
  \small
  Parameters
  \vspace{-6pt}
\begin{knitrout}\scriptsize
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{N} \hlkwb{<-} \hlnum{100}
\hlstd{p} \hlkwb{<-} \hlnum{0.2}
\end{alltt}
\end{kframe}
\end{knitrout}
  \pause
  \vfill
  All capture histories (for captured and uncaptured individuals)
  \vspace{-6pt}
\begin{knitrout}\scriptsize
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{J} \hlkwb{<-} \hlnum{4}  \hlcom{## Occasions}
\hlstd{y.all} \hlkwb{<-} \hlkwd{matrix}\hlstd{(}\hlnum{NA}\hlstd{, N, J)}
\hlkwa{for}\hlstd{(i} \hlkwa{in} \hlnum{1}\hlopt{:}\hlstd{N) \{}
    \hlstd{y.all[i,]} \hlkwb{<-} \hlkwd{rbinom}\hlstd{(J,} \hlnum{1}\hlstd{, p)}
\hlstd{\}}
\end{alltt}
\end{kframe}
\end{knitrout}
  \pause
  \vfill
  Observed capture histories (data)
  \vspace{-6pt}
\begin{knitrout}\scriptsize
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{captured} \hlkwb{<-} \hlkwd{rowSums}\hlstd{(y.all)}\hlopt{>}\hlnum{0}
\hlstd{(n} \hlkwb{<-} \hlkwd{sum}\hlstd{(captured))}
\end{alltt}
\begin{verbatim}
## [1] 54
\end{verbatim}
\begin{alltt}
\hlstd{y} \hlkwb{<-} \hlstd{y.all[captured,]}
\hlstd{y[}\hlnum{1}\hlopt{:}\hlnum{3}\hlstd{,]}
\end{alltt}
\begin{verbatim}
##      [,1] [,2] [,3] [,4]
## [1,]    0    1    0    0
## [2,]    1    0    0    0
## [3,]    0    0    1    0
\end{verbatim}
\end{kframe}
\end{knitrout}
\end{frame}



\begin{frame}[fragile]
  \frametitle{Summary stats}
  Capture history frequencies
\begin{knitrout}\scriptsize
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{histories} \hlkwb{<-} \hlkwd{apply}\hlstd{(y,} \hlnum{1}\hlstd{, paste,} \hlkwc{collapse}\hlstd{=}\hlstr{""}\hlstd{)}
\hlkwd{sort}\hlstd{(}\hlkwd{table}\hlstd{(histories))}
\end{alltt}
\begin{verbatim}
## histories
## 0011 0101 1100 1010 1101 0110 1001 0001 0010 0100 1000 
##    1    1    1    2    2    4    4    7   10   10   12
\end{verbatim}
\end{kframe}
\end{knitrout}
\pause
\vfill
  Detection frequencies
\begin{knitrout}\scriptsize
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{y.tilde} \hlkwb{<-} \hlkwd{rowSums}\hlstd{(y)}
\hlkwd{sort}\hlstd{(}\hlkwd{table}\hlstd{(y.tilde))}
\end{alltt}
\begin{verbatim}
## y.tilde
##  3  2  1 
##  2 13 39
\end{verbatim}
\end{kframe}
\end{knitrout}
\end{frame}



\subsection{Model $M_t$}


\begin{frame}[fragile]
  \frametitle{Model $M_t$ -- Temporal variation}
  Capture probability for each occasion
\begin{knitrout}\scriptsize
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{p.t} \hlkwb{<-} \hlkwd{c}\hlstd{(}\hlnum{0.3}\hlstd{,} \hlnum{0.5}\hlstd{,} \hlnum{0.2}\hlstd{,} \hlnum{0.4}\hlstd{)}
\end{alltt}
\end{kframe}
\end{knitrout}
  \pause
  \vfill
  All capture histories (for captured and uncaptured individuals)
  \vspace{-6pt}
\begin{knitrout}\scriptsize
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{y.all.Mt} \hlkwb{<-} \hlkwd{matrix}\hlstd{(}\hlnum{NA}\hlstd{, N, J)}
\hlkwa{for}\hlstd{(i} \hlkwa{in} \hlnum{1}\hlopt{:}\hlstd{N) \{}
    \hlstd{y.all.Mt[i,]} \hlkwb{<-} \hlkwd{rbinom}\hlstd{(J,} \hlnum{1}\hlstd{, p.t) \}}
\end{alltt}
\end{kframe}
\end{knitrout}
  \pause
  \vfill
  Observed capture histories (data)
  \vspace{-6pt}
\begin{knitrout}\scriptsize
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{captured.Mt} \hlkwb{<-} \hlkwd{rowSums}\hlstd{(y.all.Mt)}\hlopt{>}\hlnum{0}
\hlstd{n.Mt} \hlkwb{<-} \hlkwd{sum}\hlstd{(captured.Mt)}
\hlstd{y.Mt} \hlkwb{<-} \hlstd{y.all.Mt[captured.Mt,]}
\hlstd{y.Mt[}\hlnum{1}\hlopt{:}\hlnum{3}\hlstd{,]}
\end{alltt}
\begin{verbatim}
##      [,1] [,2] [,3] [,4]
## [1,]    1    0    1    0
## [2,]    1    1    1    0
## [3,]    1    0    0    0
\end{verbatim}
\begin{alltt}
\hlkwd{colSums}\hlstd{(y.Mt)}
\end{alltt}
\begin{verbatim}
## [1] 28 53 22 38
\end{verbatim}
\end{kframe}
\end{knitrout}
\end{frame}



\subsection{Model $M_b$}

\begin{frame}[fragile]
  \frametitle{Model $M_b$ -- Behavioral response}
  Capture probability for each occasion
\begin{knitrout}\scriptsize
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{p.b} \hlkwb{<-} \hlnum{0.3}
\hlstd{c} \hlkwb{<-} \hlnum{0.5}  \hlcom{## Trap happy}
\end{alltt}
\end{kframe}
\end{knitrout}
  \pause
  \vfill
  All capture histories (for captured and uncaptured individuals)
  \vspace{-6pt}
\begin{knitrout}\scriptsize
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{y.all.Mb} \hlkwb{<-} \hlkwd{matrix}\hlstd{(}\hlnum{NA}\hlstd{, N, J)}
\hlstd{prevcap} \hlkwb{<-} \hlkwd{matrix}\hlstd{(}\hlnum{FALSE}\hlstd{, N, J)}
\hlkwa{for}\hlstd{(i} \hlkwa{in} \hlnum{1}\hlopt{:}\hlstd{N) \{}
    \hlstd{y.all.Mb[i,}\hlnum{1}\hlstd{]} \hlkwb{<-} \hlkwd{rbinom}\hlstd{(}\hlnum{1}\hlstd{,} \hlnum{1}\hlstd{, p.b)}
    \hlkwa{for}\hlstd{(j} \hlkwa{in} \hlnum{2}\hlopt{:}\hlstd{J) \{}
        \hlstd{prevcap[i,j]} \hlkwb{<-} \hlkwd{any}\hlstd{(y.all.Mb[i,}\hlnum{1}\hlopt{:}\hlstd{(j}\hlopt{-}\hlnum{1}\hlstd{)]}\hlopt{>}\hlnum{0}\hlstd{)}
        \hlstd{prob} \hlkwb{<-} \hlkwd{ifelse}\hlstd{(prevcap[i,j], c, p.b)}
        \hlstd{y.all.Mb[i,j]} \hlkwb{<-} \hlkwd{rbinom}\hlstd{(}\hlnum{1}\hlstd{,} \hlnum{1}\hlstd{, prob)}
    \hlstd{\}}
\hlstd{\}}
\end{alltt}
\end{kframe}
\end{knitrout}
  \pause
  \vfill
  Observed capture histories (data)
  \vspace{-6pt}
\begin{knitrout}\scriptsize
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{captured.Mb} \hlkwb{<-} \hlkwd{rowSums}\hlstd{(y.all.Mb)}\hlopt{>}\hlnum{0}
\hlstd{n.Mb} \hlkwb{<-} \hlkwd{sum}\hlstd{(captured.Mb)}
\hlstd{y.Mb} \hlkwb{<-} \hlstd{y.all.Mb[captured.Mb,]}
\hlcom{## prevcap[1:3,]}
\end{alltt}
\end{kframe}
\end{knitrout}
\end{frame}



\subsection{Model $M_h$}


\begin{frame}[fragile]
  \frametitle{Model $M_h$ -- Individual heterogeneity}
  There are many flavors of $M_h$. Some use finite mixture
  models. Here we have logit-normal distribution for $p$. 
\begin{knitrout}\scriptsize
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{logit.p.bar} \hlkwb{<-} \hlopt{-}\hlnum{1}  \hlcom{## Mean p on logit scale}
\hlstd{logit.p.var} \hlkwb{<-} \hlnum{1}   \hlcom{## SD of p on logit scale}
\hlstd{p.h} \hlkwb{<-} \hlkwd{plogis}\hlstd{(}\hlkwd{rnorm}\hlstd{(N, logit.p.bar, logit.p.var))}
\end{alltt}
\end{kframe}
\end{knitrout}
  \pause
  \vfill
  All capture histories (for captured and uncaptured individuals)
  \vspace{-6pt}
\begin{knitrout}\scriptsize
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{y.all.Mh} \hlkwb{<-} \hlkwd{matrix}\hlstd{(}\hlnum{NA}\hlstd{, N, J)}
\hlkwa{for}\hlstd{(i} \hlkwa{in} \hlnum{1}\hlopt{:}\hlstd{N) \{}
    \hlstd{y.all.Mh[i,]} \hlkwb{<-} \hlkwd{rbinom}\hlstd{(J,} \hlnum{1}\hlstd{, p.h[i])}
\hlstd{\}}
\end{alltt}
\end{kframe}
\end{knitrout}
  \pause
  \vfill
  Observed capture histories (data)
  \vspace{-6pt}
\begin{knitrout}\scriptsize
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{captured.Mh} \hlkwb{<-} \hlkwd{rowSums}\hlstd{(y.all.Mh)}\hlopt{>}\hlnum{0}
\hlstd{n.Mh} \hlkwb{<-} \hlkwd{sum}\hlstd{(captured.Mh)}
\hlstd{y.Mh} \hlkwb{<-} \hlstd{y.all.Mh[captured.Mh,]}
\hlcom{#y.Mh[1:3,]}
\end{alltt}
\end{kframe}
\end{knitrout}
\end{frame}





\section{Joint likelihood}



\begin{frame}
  \frametitle{Outline}
  \Large
  \tableofcontents[currentsection]
\end{frame}


%% p(y,n|N,p)
\begin{frame}[fragile]
  \frametitle{Joint likelihood for $M_0$}
  The joint likelihood has a multinomial form:
  \begin{multline*}
    L(N,p; y,n) = \\
    \left\{\prod_{i=1}^n \prod_{j=1}^J p^{y_{ij}}(1-p)^{1-y_{ij}}\right\}
    \left\{\frac{N!}{(N-n)!}  \left(\prod_{j=1}^J(1-p)\right)^{N-n} \right\}
  \end{multline*}
  \pause
  \vfill
\begin{knitrout}\scriptsize
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{nll.M0} \hlkwb{<-} \hlkwa{function}\hlstd{(}\hlkwc{pars}\hlstd{,} \hlkwc{y}\hlstd{) \{}           \hlcom{## Negative log-likelihood}
    \hlstd{n} \hlkwb{<-} \hlkwd{nrow}\hlstd{(y);       J} \hlkwb{<-} \hlkwd{ncol}\hlstd{(y)}
    \hlstd{N} \hlkwb{<-} \hlkwd{exp}\hlstd{(pars[}\hlnum{1}\hlstd{])}
    \hlstd{n0} \hlkwb{<-} \hlstd{N}\hlopt{-}\hlstd{n}
    \hlkwa{if}\hlstd{(n0}\hlopt{<}\hlnum{0}\hlstd{)} \hlkwd{return}\hlstd{(}\hlnum{NA}\hlstd{)}
    \hlstd{p} \hlkwb{<-} \hlkwd{plogis}\hlstd{(pars[}\hlnum{2}\hlstd{])}
    \hlstd{ld.y1} \hlkwb{<-} \hlkwd{sum}\hlstd{(}\hlkwd{dbinom}\hlstd{(y,} \hlnum{1}\hlstd{, p,} \hlkwc{log}\hlstd{=}\hlnum{TRUE}\hlstd{))}
    \hlstd{p0} \hlkwb{<-} \hlstd{(}\hlnum{1}\hlopt{-}\hlstd{p)}\hlopt{^}\hlstd{J}
    \hlstd{ld.n0} \hlkwb{<-} \hlkwd{lgamma}\hlstd{(N}\hlopt{+}\hlnum{1}\hlstd{)}\hlopt{-}\hlkwd{lgamma}\hlstd{(n0}\hlopt{+}\hlnum{1}\hlstd{)}\hlopt{+}\hlstd{n0}\hlopt{*}\hlkwd{log}\hlstd{(p0)}
    \hlstd{nll} \hlkwb{<-} \hlopt{-}\hlstd{(ld.y1}\hlopt{+}\hlstd{ld.n0)}
    \hlkwd{return}\hlstd{(nll)}
\hlstd{\}}
\end{alltt}
\end{kframe}
\end{knitrout}
\end{frame}



\begin{frame}[fragile]
  \frametitle{Maximize joint likelihood for $M_0$}
Minimized the negative log-likelihood
\begin{knitrout}\scriptsize
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{fm.M0} \hlkwb{<-} \hlkwd{optim}\hlstd{(}\hlkwd{c}\hlstd{(}\hlkwc{log.N}\hlstd{=}\hlnum{4}\hlstd{,}\hlkwc{logit.p}\hlstd{=}\hlnum{0}\hlstd{), nll.M0,} \hlkwc{y}\hlstd{=y,} \hlkwc{hessian}\hlstd{=}\hlnum{TRUE}\hlstd{)}
\hlstd{fm.M0.est} \hlkwb{<-} \hlkwd{data.frame}\hlstd{(}\hlkwc{Estimate}\hlstd{=}\hlkwd{c}\hlstd{(fm.M0}\hlopt{$}\hlstd{par[}\hlnum{1}\hlstd{], fm.M0}\hlopt{$}\hlstd{par[}\hlnum{2}\hlstd{]),}
                        \hlkwc{SE}\hlstd{=}\hlkwd{sqrt}\hlstd{(}\hlkwd{diag}\hlstd{(}\hlkwd{solve}\hlstd{(fm.M0}\hlopt{$}\hlstd{hessian))))}
\hlstd{fm.M0.est}
\end{alltt}
\begin{verbatim}
##          Estimate        SE
## log.N    4.570652 0.1730285
## logit.p -1.491271 0.2493760
\end{verbatim}
\end{kframe}
\end{knitrout}
\pause
\vfill
Back-transform the estimates
\begin{knitrout}\scriptsize
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{c}\hlstd{(}\hlkwc{N.hat}\hlstd{=}\hlkwd{exp}\hlstd{(fm.M0}\hlopt{$}\hlstd{par[}\hlnum{1}\hlstd{]),} \hlkwc{p.hat}\hlstd{=}\hlkwd{plogis}\hlstd{(fm.M0}\hlopt{$}\hlstd{par[}\hlnum{2}\hlstd{]))}
\end{alltt}
\begin{verbatim}
##   N.hat.log.N p.hat.logit.p 
##     96.607092      0.183731
\end{verbatim}
\end{kframe}
\end{knitrout}
\pause
\vfill
Compare to data-generating values
\begin{knitrout}\scriptsize
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{c}\hlstd{(}\hlkwc{N}\hlstd{=N,} \hlkwc{p}\hlstd{=p)}
\end{alltt}
\begin{verbatim}
##     N     p 
## 100.0   0.2
\end{verbatim}
\end{kframe}
\end{knitrout}
\end{frame}





\section{Data augmentation}


%\section{Prediction}
%\subsection{Likelihood-based inference}


\begin{frame}
  \frametitle{Outline}
  \Large
  \tableofcontents[currentsection]
\end{frame}



\begin{frame}
  \frametitle{Data augmentation}
  Data augmentation is strange. \\
  \pause
  \vfill
  We add ``all zero'' capture histories to our data, then we try to
  estimate how many of them are real. \\ 
  \pause
  \vfill
  The total number of observed and agumented encounter histories is
  $M$. \\
  \pause
  \vfill
  We define the model in terms of a binary indicator variable $z_i$,
  such that $N=\sum_{i=1}^M z_i$. \\
  \pause
  \vfill
  We know $z_i=1$ for the $n$ captured individuals. \\
\end{frame}






\begin{frame}
  \frametitle{Data augmentation model}
  The model is:
  \begin{gather*}
    z_i \sim \mathrm{Bern}(\psi) \\
    y_{ij} \sim \mathrm{Bern}(z_i p_{ij}) \\
    N=\sum_{i=1}^M z_i
  \end{gather*}
  \pause \vfill
  % A uniform prior on $\psi$ results in a discrete uniform prior on
  % $N$. We can change the prior for $N$ by changing the prior on
  % $\psi$, recognizing that $E(N)=M\psi$.
  Note that this looks exactly like an occupancy model. \\
  \pause \vfill
  But why bother with augmentation?
  \begin{itemize}
    \item DA works for \alert{all} varieties of mark-recapture models
    \item Make it easy to incorporate
      individual-covariates\dots\pause including distance and
      location!   
  \end{itemize}
\end{frame}






\begin{frame}
  \frametitle{Bayesian data augmentation}
  The model is the same, but we need priors on $\psi$ and $p$. 
  \begin{gather*}
    z_i \sim \mathrm{Bern}(\psi) \\
    y_{ij} \sim \mathrm{Bern}(z_ip) \\
    N = \sum_{i=1}^M z_i
  \end{gather*}
  \vfill
  A uniform prior on $\psi$ results in a discrete uniform prior on
  $N$. We can change the prior for $N$ by changing the prior on  
  $\psi$, recognizing:
  \[
    E(N)=M\psi
  \]
\end{frame}



% \begin{frame}[fragile]
%   \frametitle{Model $M_0$ -- data augmentation}
% \vspace{-3pt}
% <<bugs-M0-aug,size='small'>>=
% writeLines(readLines("M0-aug.jag"))
% @
% \end{frame}



% \begin{frame}[fragile]
%   \frametitle{Model $M_0$ -- data augmentation}
%   Data
% <<jd-M0-aug,size='scriptsize'>>=
% y.aug <- matrix(0, M, J)
% y.aug[1:n,] <- y
% jags.data.M0 <- list(y=y.aug, M=M, J=J)
% @
% \pause
% \vfill
%   Inits and parameters
% <<ji-M0-aug,size='scriptsize'>>=
% ji.M0 <- function() list(z=rep(1,M), psi=runif(1), p=runif(1))
% jp.M0 <- c("p", "psi", "N")
% @
% \pause
% \vfill
% MCMC
% <<mcmc-M0-aug,size='scriptsize',results='hide'>>=
% library(jagsUI)
% jags.post.M0 <- jags.basic(data=jags.data.M0, inits=ji.M0,
%                            parameters.to.save=jp.M0,
%                            model.file="M0-aug.jag",
%                            n.chains=3, n.adapt=100, n.burnin=0,
%                            n.iter=2000, parallel=TRUE)
% @ 
% \end{frame}




% \begin{frame}[fragile]
%   \frametitle{Traceplots and density plots}
% <<plot-mcmc-M0,size='footnotesize',out.width="0.7\\textwidth",fig.align='center',cache=TRUE>>=
% plot(jags.post.M0[,jp.M0])
% @ 
% \end{frame}




% \begin{frame}[fragile]
%   \frametitle{Model $M_0$ -- without data augmentation}
%   Here's why practitioners like data augmentation 
% \vspace{-3pt}
% <<bugs-M0,size='footnotesize'>>=
% writeLines(readLines("M0.jag"))
% @
% \end{frame}





% \begin{frame}[fragile]
%   \frametitle{Model $M_0$ -- without data augmentation}
%   Data
% <<jd-M0-noaug,size='scriptsize'>>=
% n0max <- 1000  ## Upper limit of prior on n0
% jags.data.M0.noaug <- list(y=y.aug, n=n, J=J,
%                            ## Prior probs for n0
%                            n0probs=rep(1/n0max, n0max), zero=0)
% @
% \pause
% \vfill
%   Inits and parameters
% <<ji-M0-noaug,size='scriptsize'>>=
% ji.M0.noaug <- function() list(n0=rpois(1, 5), p=runif(1, 0, 0.1))
% jp.M0.noaug <- c("p", "N")
% @
% \pause
% \vfill
% MCMC
% <<mcmc-M0-noaug,size='scriptsize',results='hide'>>=
% jags.post.M0.noaug <- jags.basic(data=jags.data.M0.noaug,
%                                  inits=ji.M0.noaug,
%                                  parameters.to.save=jp.M0.noaug,
%                                  model.file="M0.jag",
%                                  n.chains=3, n.adapt=100, n.burnin=0,
%                                  n.iter=2000, parallel=TRUE)
% @ 
% \end{frame}




% \begin{frame}[fragile]
%   \frametitle{Traceplots and density plots}
% <<plot-mcmc-M0-noaug,size='footnotesize',out.width="0.7\\textwidth",fig.align='center',cache=TRUE>>=
% plot(jags.post.M0.noaug[,jp.M0.noaug])
% @ 
% \end{frame}








% \begin{frame}[fragile]
%   \frametitle{Model $M_t$ -- data augmentation}
% \vspace{-3pt}
% <<bugs-Mt-aug,size='small'>>=
% writeLines(readLines("Mt-aug.jag"))
% @
% \end{frame}






% \begin{frame}[fragile]
%   \frametitle{Model $M_t$ -- data augmentation}
%   Data, inits, parameters to monitor
% <<ji-Mt-aug,size='scriptsize'>>=
% jags.data.Mt <- jags.data.M0
% ji.Mt <- function() list(z=rep(1,M), psi=runif(1), p=runif(4))
% jp.Mt <- c("p", "psi", "N")
% @
% \pause
% \vfill
% MCMC
% <<mcmc-Mt-aug,size='scriptsize',results='hide'>>=
% jags.post.Mt <- jags.basic(data=jags.data.Mt, inits=ji.Mt,
%                            parameters.to.save=jp.Mt,
%                            model.file="Mt-aug.jag",
%                            n.chains=3, n.adapt=100, n.burnin=0,
%                            n.iter=2000, parallel=TRUE)
% @ 
% \end{frame}






% \begin{frame}[fragile]
%   \frametitle{Traceplots and density plots}
% <<plot-mcmc-Mt1,size='footnotesize',out.width="0.7\\textwidth",fig.align='center',cache=TRUE>>=
% plot(jags.post.Mt[,paste0("p[", 1:4, "]")])
% @ 
% \end{frame}









%\section{Summary}


\begin{frame}
  \frametitle{SCR summary}
  We assume that variation in $p$ arises from changes over time,
  behavioral effects, or random individual heterogeneity. \\
  \pause \vfill
  Individual heterogeneity models pose estimation problems. \\
  \pause \vfill
  A solution is to use individual covariates to explain the variation,
  rather than random effects. \pause But what covariates are
  important? \\
  \pause \vfill
  With spatial capture-recapture (SCR) models we will use
  \alert{distance between animals and traps} as a covariate, and we'll
  put use a spatial point process model for animal locations. 
\end{frame}




\section{Assignment}




\begin{frame}[fragile]
  \frametitle{Assignment}
  % \small
  % \footnotesize
  Create a self-contained R script or Rmarkdown file to do the
  following: 
  \vfill
  \begin{enumerate}
%    \small
%    \footnotesize
    \item Fit model $M_h$ in JAGS to the data simulated above
      \begin{itemize}
%        \footnotesize
        \item Use the flavor of $M_h$ that assumes $\mathrm{logit}(p_i)$ follows a
          normal distribution: $\mathrm{logit}(p_i) \sim
          \mathrm{Normal}(\bar{p}, \sigma^2_p)$.  
      \end{itemize}
    \item Use prior predictive checks to find reasonable priors for
      {\tt logit.p.mean} and {\tt logit.p.var}
    \item Present summary stats for prior and posterior distributions
      of {\tt logit.p.mean} and {\tt logit.p.var}, as well as for
      $N$. 
  \end{enumerate}
  \vfill
  Upload your {\tt .R} or {\tt .Rmd} file to ELC before Tuesday. 
\end{frame}





\end{document}

