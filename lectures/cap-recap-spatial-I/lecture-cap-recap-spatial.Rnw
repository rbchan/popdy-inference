\documentclass[color=usenames,dvipsnames]{beamer}
%\documentclass[color=usenames,dvipsnames,handout]{beamer}

\usepackage[roman]{../lectures}
%\usepackage[sans]{../lectures}


\hypersetup{pdfpagemode=UseNone,pdfstartview={FitV}}



% Load function to compile and open PDF
<<build-fun,include=FALSE,purl=FALSE>>=
source("../rnw2pdf.R")
@

% Compile and open PDF
<<buildit,include=FALSE,eval=FALSE>>=
rnw2pdf("lecture-cap-recap-spatial")
rnw2pdf("lecture-cap-recap-spatial", tangle=TRUE)
@ 


<<knitr-theme,include=FALSE,purl=FALSE>>=
knit_theme$set("edit-kwrite")
@

% New command for inline code that isn't to be evaluated
\definecolor{inlinecolor}{rgb}{0.878, 0.918, 0.933}
\newcommand{\inr}[1]{\colorbox{inlinecolor}{\texttt{#1}}}




\begin{document}
    



\begin{frame}[plain]
  \LARGE
  \centering
  {
    \LARGE Spatial capture-recapture %\\
    for \\ closed populations \\
%    \Large simulation, fitting, and prediction \\
  }
  {\color{default} \rule{\textwidth}{0.1pt} }
  \vfill
  \large
  WILD(FISH) 8390 \\
  Estimation of Fish and Wildlife Population Parameters \\
  \vfill
  \large
  Richard Chandler \\
  University of Georgia \\
\end{frame}






\section{Overview}



\begin{frame}[plain]
  \frametitle{Outline}
  \Large
  \only<1>{\tableofcontents}%[hideallsubsections]}
  \only<2 | handout:0>{\tableofcontents[currentsection]}%,hideallsubsections]}
\end{frame}



\begin{frame}
  \frametitle{SCR overview}
  {\centering \large Two motivations for SCR \\}
  \vfill
  \begin{enumerate}
    \item Improved inference
    \begin{itemize}
      \item<1-> Non-spatial models don't account for important sources
        of variation in $p$. %that can cause bias.
        \begin{itemize}
          \item<1-> Distance between animals and traps
          \item<1-> Trap-specific covariates
        \end{itemize}
      \item<2-> SCR makes it possible to estimate \alert{density}, not
        just $N$ in an unknown region. 
    \end{itemize}
    \pause
    \vfill
  \item<3-> Improved science
  \begin{itemize}
    \item<3-> We can ask new questions, such as:
      \begin{itemize}
        \item<3-> What influences spatial variation in density?
        \item<4-> How do survival and recruitment vary in space and time?
        \item<5-> How does movement influence density and detectability?
      \end{itemize}
    \item<6-> Rather than think of SCR as a new estimation tool, you
      can think of it as an individual-based framework for inference on
      spatial population dynamics.
    \end{itemize}
  \end{enumerate}
  % \vfill
  % \centering
  % \footnotesize
  % \uncover<6->{
  % Rather than think of SCR as a new estimation tool, you can think of
  % it as an individual-based framework for inference on spatial
  % population dynamics. \\}
\end{frame}



% \begin{frame}
%   \frametitle{Comparison to mark-recapture}
%   The simplest estimator of abundance is 
%   \[
%     \hat{N} = \frac{n}{\hat{p}}
%   \]
%   where $n$ is the number of individuals detected, $p$ is detection
%   probability, and $E(n)=Np$. \\
%   \pause
%   \vfill
%   In distance sampling, we modeled detection probability as a
%   function of distance, and we replaced $p$ with average detection
%   probability. \\ 
%   \pause
%   \vfill
%   Spatial capture recapture can be thought of in a similar way, but we 
%   average detection probability over the spatial distribution of
%   individuals, not just over distance. 
% \end{frame}





\begin{frame}
  \frametitle{SCR data}
  \small
  % SCR capture histories histories have 3 dimensions instead of two. \\
  % \pause
  % \vfill
  SCR capture histories can be organized as a 3D array where $y_{ijk}$
  indicates if individual $i=1,\dots,n$, was captured in trap
  $j=1,\dots,J$ on occasion $k=1,\dots,K$. \\
  \pause \vfill
  Here's an example of a ``flattened array'' with $n=4$ animals captured  
  at $J=3$ traps on $K=2$ occasions. \\
  \centering
  \vfill  
  \begin{tabular}{lccccccc}
    \hline
    & \multicolumn{7}{c}{Occasion} \\
    \cline{2-8}
    & \multicolumn{3}{c}{1} & & \multicolumn{3}{c}{2} \\
    \cline{2-4} \cline{6-8}
    & \multicolumn{3}{c}{Trap} & & \multicolumn{3}{c}{Trap} \\
    \cline{2-4} \cline{6-8}
    Individual & 1 & 2 & 3 & & 1 & 2 & 3 \\
    \hline
    1 & 0 & 0 & 0 & & 1 & 0 & 1 \\
    2 & 1 & 1 & 1 & & 0 & 1 & 1 \\
    3 & 0 & 1 & 0 & & 0 & 0 & 0 \\
    4 & 0 & 1 & 1 & & 1 & 0 & 0 \\
    \hline
  \end{tabular}
  \pause
  \vfill
  \flushleft
  Because we know the coordinates of the traps, we also know when and
  where each individual was detected. \\
  \pause
  \vfill
  This spatial information has been available all along, but it wasn't
  utilized to estimate density until Efford (2004, Oikos). \\
\end{frame}




% \begin{frame}
%   \frametitle{In-class exercise}
%   Building off the previous example\dots
%   \begin{enumerate}
%     \item Compute $\bar{p}$ for line-transect sampling when
%       $\sigma=50, 100, \mathrm{and}\, 200$, instead of $\sigma=25$.  
%     \item Repeat, but for point-transect sampling. 
%   \end{enumerate}
% \end{frame}





\begin{frame}
  \frametitle{\large Closed population model ($N$ known hypothetically) }
  \footnotesize
  State model (a spatial point process model) %\\
  \begin{gather*}
    \lambda(\bs) = \exp(\beta_0 + \beta_1 w_1(\bs) + \beta_2 w_2(\bs) + \cdots) \\
    \Lambda = \int_{\mathcal{S}} \lambda(\bs) \; \mathrm{d}\bs \\
    N \sim \mathrm{Pois}(\Lambda) \\
    \bsi \propto \lambda(\bs) \;\; \mathrm{for}\; i=1,\dots,N 
  \end{gather*}
  \pause
%  \vfill
  Observation model (supposing $N$ was known)
  \begin{gather*}
    p_{ij} = g_0\exp(-\|\bsi - \bxj\|^2/(2\sigma^2))  \;\; \mathrm{for}\, j=1,\dots,J  \\
    y_{ijk} \sim \mathrm{Bernoulli}(p_{ij})
  \end{gather*}
  \pause
%  \vfill
%  \footnotesize
  \scriptsize
  Definitions \\
  \hangindent=0.9cm $\lambda(\bs)$ -- ``Intensity function'' %or ``density surface''
  describing expected density of individuals at location $\bs$ \\ 
  $\Lambda$ -- Expected number of individuals in the spatial region $\mathcal{S}$ \\
  $N$ -- Realized number of individuals (ie, population size) \\
  $\bsi$ -- Location of the $i$th activity center \\
  $\bxj$ -- Location of trap $j$ \\
  $\dsixj$ -- Euclidean distance between $\bsi$ and $\bxj$ \\
  $g_0$ -- Capture probability when distance between activity centers
  and traps is 0 \\
  $\sigma$ -- Scale parameter of encounter function \\
  $p_{ij}$ -- Capture probability \\
  $y_{ijk}$ -- Spatial capture histories \\
  % \pause
  % \vfill
  % The problem with this formulation is that we don't observe the ``all
  % zero'' encounter histories (and thus we don't know $N$). 
\end{frame}





\begin{frame}
  \frametitle{Spatial point processes}
  {\centering \large
    The state model of SCR is a spatial (or spatio-temporal) point process \\}
  \vfill
  \pause
  There are many varieties of spatial point processes, including \\
  \begin{itemize}
    \item (In)homogeneous binomial point process
    \item (In)homogeneous Poisson point process
    \item Cox process
    \item Gibbs process
    \item Markov point process
%    \item Among others
  \end{itemize}
\end{frame}





\begin{frame}
  \frametitle{Spatial point processes}
%  \large
  All share a few properties \\
  \begin{itemize}%[<+->]
    \item<1-> The data are a collection of points called a ``point pattern''
    \item<2-> Points are in an area called the state-space
      ($\mathcal{S}$), or observation window, which is usually two
      dimensional  
    \item<3-> An intensity function ($\lambda(\bs)$) describes spatial
      variation in the density of points
    \item<4-> The area under this function is the expected number of
      points (a.k.a, $N$) in the region:
  \end{itemize}
  \vfill
%  \Large
  \uncover<5->{
\[
  E(N) = \Lambda = \int_{\mathcal{S}} \lambda(\bs) \;\mathrm{d}\bs
\]
}
\end{frame}



\begin{frame}
  \frametitle{Poisson point process}
  Properties
  \begin{itemize}
    \item If density is constant throughout the state-space:
      $\lambda(\bs) = \lambda$, the process is said to be
      ``homogeneous''
    \item Otherwise, the process is ``inhomogeneous''
    \item The number of points in any region of the state-space is
      Poisson distributed
    \item Points are independent of one another (no attraction or
      repulsion) 
  \end{itemize}
  \pause
  \vfill
%   \centering {\bf Note:} For more complicated models, it's easier to
%   work in discrete space than continuous space. Plus, spatial
%   covariates always come to us in the form of raster. \\
  An inhomogeneous point process allows for spatial variation
  in density, which can be modeled using \alert{spatial covariates},
  such as raster layers. \\
\end{frame}






\begin{frame}
  \frametitle{Shiny app}
  \LARGE
  \centering
  % \href{
  %   https://richard-chandler.shinyapps.io/scr-cap-prob/
  % }{
  %   Shiny App 
  % } \\
  Shiny App \\
  \vfill
  \normalsize
  \color{blue}
  \url{
    https://richard-chandler.shinyapps.io/scr-cap-prob/
  } \\
\end{frame}




\begin{frame}
  \frametitle{Observation models}
  The SCR model assumes that capture probability decreases with
  distance between activity centers and traps. \\
  \pause
  \vfill
  We can use encounter rate functions similar to those from distance 
  sampling for this purpose. \\
  \pause
  \vfill
  The most common encounter rate function that we'll consider is based
  on the Gaussian distribution:
  \begin{gather*}
    p_{ij} = g_0\exp(-\dsixj/(2\sigma^2)) \\
    y_{ijk} \sim \mathrm{Bernoulli}(p_{ij}) 
  \end{gather*}
  \pause
%  \vfill
  However, there are many options and we aren't restricted to the
  Bernoulli observation model. 
\end{frame}







\begin{frame}
  \frametitle{Observation models}
%  \begin{itemize}
%  \item
  Observation models are not the same as encounter rate functions. \\
  \pause \vfill
  % \item
  Observation models are chosen with respect to the sampling
      method (mist-net, camera trap, hair snare, etc\dots) \\
%  \end{itemize}
  \pause \vfill
  % \begin{center}
  \centering
    \begin{tabular}{lll}
      \hline
      Model       & Detector/Trap     & Examples           \\
      \hline
      Bernoulli   & Proximity    & Hair-snares        \\
      Poisson     & Count        & Camera trap        \\
      Multinomial/Categorical & Multi-catch  & Mist net, crab pot \\
      ---          & Single-catch & Sherman trap       \\
      \hline
    \end{tabular}
    % \end{center}
  \pause \vfill
  There are other observation models for data from area searches,
  transects, or acoustic recording units.
\end{frame}








\section{Simulation}


\begin{frame}
  \frametitle{Outline}
  \Large
%  \tableofcontents[currentsection,currentsubsection]
  \tableofcontents[currentsection]
\end{frame}




% \begin{frame}[fragile]
%   \frametitle{Homogeneous binomial point process}
% <<bpp1,size='footnotesize',out.width="50%",fig.align="center">>=
% N <- 25
% s <- cbind(runif(N, 0, 1), runif(N, 0, 1))
% plot(s, pch=16, col="blue", xlab="Easting", ylab="Northing",
%      xlim=c(0,1), ylim=c(0,1), cex.lab=1.5, asp=1)
% @
% \end{frame}






\begin{frame}[fragile]
  \frametitle{Homogeneous Poisson point process}
<<ppp1,size='footnotesize',out.width="50%",fig.align="center",echo=-1>>=
set.seed(439)
lambda1 <- 25; A <- 1     ## lambda1=density, A=area
N <- rpois(1, lambda1*A)  
s <- cbind(runif(N, 0, 1), runif(N, 0, 1))
plot(s, pch=16, col="blue", xlab="Easting", ylab="Northing",
     xlim=c(0,1), ylim=c(0,1), cex.lab=1.5, asp=1)
@
\end{frame}



<<include=FALSE,eval=FALSE,purl=FALSE>>=
## Simulate covariate from normal distribution with exponential covariance
delta <- 0.01
grid0 <- seq(0+delta/2, 1-delta/2, delta)
grid <- cbind(rep(grid0, each=length(grid0)),
              rep(grid0, times=length(grid0)))
dist.grid <- as.matrix(dist(grid))
V <- exp(-dist.grid*10)
set.seed(4984)
w <- t(chol(V)) %*% rnorm(nrow(V))

elevation <- 1000 + w*100

library(raster)
elevation.r <- rasterFromXYZ(cbind(grid[,1], grid[,2], elevation))
plot(elevation.r)
writeRaster(elevation.r, filename="elevation.tif", overwrite=TRUE)



## library(lattice)

## levelplot(w ~ grid[,1]+grid[,2], aspect="iso", at=seq(min(w), max(w), len=100))

## lambda <- exp(-7 + 1.5*w)
## (Lambda <- sum(lambda*delta^2*1e4))
## (N <- rpois(1, Lambda))

## levelplot(lambda ~ grid[,1]+grid[,2], aspect="iso",
##           at=seq(min(lambda), max(lambda), len=100),
##           col.regions=topo.colors(100))

## pi <- lambda/sum(lambda)

## s <- grid[sample(nrow(grid), size=N, replace=TRUE, prob=pi),]

## levelplot(lambda ~ grid[,1]+grid[,2], aspect="iso",
##           panel=function(...) {
##               panel.levelplot(...)
##               lpoints(s, pch=16, col="blue")
##           }, 
##           at=seq(min(lambda), max(lambda), len=100),
##           col.regions=terrain.colors(100))


@ 








% \begin{frame}[fragile]
%   \frametitle{Inhomogeneous Poisson point process}
%   First, let's import a raster layer
% <<ippp1,size='footnotesize',fig.width=7.2,out.width="60%",fig.align="center",results="hide">>=
% library(raster)
% elevation <- raster("elevation.tif")
% plot(elevation, col=topo.colors(100), main="Elevation")
% @
% \end{frame}




% \begin{frame}
%   \frametitle{Closed population estimation options}
%   Conditional likelihood \\
%   \begin{itemize}
%     \item Estimate $\tilde{p}$\footnote{$\tilde{p}$ depends on $\lambda(s), g_0,
%         \sigma, \mathcal{S}, x$}, and then compute $\hat{N}=n/\hat{\tilde{p}}$
%   \end{itemize}
%   \pause
%   \vfill
%   Joint likelihood \\
%   \begin{itemize}
%     \item Estimate $N$ and $\tilde{p}$ jointly
%     \item Joint likelihood can be written as
%       \begin{itemize}
%       \item $L(N,g_0,\sigma;y,n) = p(y|n,p)p(n|N,p)$ or
%       \item $L(N,g_0,\sigma;y,n) = p(y,n|N,p)$
%       \end{itemize}
%   \end{itemize}
%   \pause \vfill
%   Data augmentation \\
%   \begin{itemize}
%     \item Tack on many ``all zero'' encounter histories and estimate
%       how many of them actually occurred
%     \item Usually, but not necessarily, used in Bayesian inference
%   \end{itemize}
% \end{frame}






% \begin{frame}[fragile]
%   \frametitle{Inhomogeneous Poisson point process}
%   \small
%   Second, let's pick some coefficients and create a density surface
% <<ippp2,size='footnotesize',fig.width=7.2,out.width="60%",fig.align="center">>=
% beta0 <- -15
% beta1 <- 0.01 #0.005
% lambda <- exp(beta0 + beta1*elevation)  # Intensity function
% plot(lambda, col=terrain.colors(100), main="Density surface")
% @
% \end{frame}




% \begin{frame}[fragile]
%   \frametitle{Inhomogeneous Poisson point process}
%   \small
%   Third, simulate $N$
%   \vspace{-6pt}
% <<ippp3,size='footnotesize'>>=
% set.seed(538)  
% ds <- 1                            ## Pixel area is 1 ha
% lambda.values <- values(lambda)    ## Convert raster to vector
% Lambda <- sum(lambda.values*ds)    ## E(N)
% (N <- rpois(1, Lambda))            ## Realized N
% @
% \pause
% \vfill
% Fourth, simulate and $\bs_1, \dots, \bs_N$. To do this, we'll pick
% pixels proportional to density. Then we'll jitter each point
% inside its pixel. 
%   \vspace{-6pt}
% <<ipp4,size='footnotesize'>>=
% n.pixels <- length(lambda)
% jitter <- 0.005                    ## Half width of pixel 
% s.pixels <- sample(n.pixels, size=N, replace=TRUE,
%                    prob=lambda.values/Lambda)
% elevation.xyz <- as.data.frame(elevation, xy=TRUE)
% s <- elevation.xyz[s.pixels,c("x","y")] +
%     cbind(runif(N, -jitter, jitter),runif(N, -jitter, jitter))
% @
% \end{frame}







% \begin{frame}[fragile]
%   \frametitle{Inhomogeneous Poisson point process}
% <<ippp5,size='scriptsize',fig.width=7.2,out.width="70%",fig.align="center">>=
% plot(lambda, col=terrain.colors(100),
%      main="Density surface with activity centers")
% points(s, pch=16, cex=1, col="blue")
% @
% \end{frame}






\begin{frame}[fragile]
  \frametitle{Traps}
<<traps1,size='scriptsize',fig.width=7.2,out.width="60%",fig.align="center",echo=-(2:4)>>=
x <- cbind(rep(seq(0.15, 0.85, by=0.1), each=8),
           rep(seq(0.15, 0.85, by=0.1), times=8))  ## Trap locations
##plot(lambda, col=terrain.colors(100),
##     main="Density surface with activity centers and traps")
##points(s, pch=16, col="blue") ## Activity center locations
plot(s, pch=16, col="blue", xlab="Easting", ylab="Northing", asp=1,
     main="Activity centers and traps")
points(x, pch=3)              ## Trap locations
@
\end{frame}





\begin{frame}[fragile]
  \frametitle{Distance between traps and activity centers}
  Compute distances between activity centers ($\bs_1, \dots, \bs_N$)
  and traps ($\bx_1, \dots, \bx_J$).
<<dist1,size='footnotesize'>>=
J <- nrow(x)                 ## nTraps
dist.sx <- matrix(NA, N, J)  
for(i in 1:N) {
    dist.sx[i,] <- sqrt((s[i,1]-x[,1])^2 + (s[i,2]-x[,2])^2)
}
@
\pause
\vfill
  Look at distances between first 4 individuals and first 5 traps.
<<dist2,size='footnotesize'>>=
round(dist.sx[1:4,1:5], digits=2)
@

\end{frame}






\begin{frame}[fragile]
  \frametitle{Capture probability}
  Compute capture probability
<<p1,size='footnotesize'>>=
g0 <- 0.2
sigma <- 0.05
p <- g0*exp(-dist.sx^2/(2*sigma^2))
@
\pause
\vfill
  Look at capture probs for first 4 individuals and first 5 traps.
<<p2,size='footnotesize'>>=
round(p[1:4,1:5], digits=3)
@

\end{frame}





\begin{frame}[fragile]
  \frametitle{Capture histories}
  Simulate capture histories for all $N$ individuals
<<y1,size='footnotesize'>>=
K <- 5                          # nOccasions
y.all <- array(NA, c(N, J, K))
for(i in 1:N) {
    for(j in 1:J) {
        y.all[i,j,] <- rbinom(K, 1, prob=p[i,j])
    }
}
@
\pause
\vfill
  Discard individuals not captured
<<y2,size='footnotesize'>>=
captured <- rowSums(y.all)>0
y <- y.all[captured,,]
@
\pause
\vfill
  Capture histories for first 2 individuals and first 5 traps
  on first occasion.
<<y3,size='footnotesize'>>=
y[1:2,1:5,1]
@

\end{frame}







\begin{frame}[fragile]
  \frametitle{Summary stats}
  \small
  Individuals captured
<<n,size='footnotesize'>>=
(n <- nrow(y))
@
\pause \vfill
  Capture frequencies
  \vspace{-6pt}  
<<cap-freq,size='footnotesize'>>=
y.tilde <- rowSums(y)
table(y.tilde)
@
\pause
\vfill
Spatial recaptures
  \vspace{-6pt}  
<<sp-cap-freq,size='footnotesize'>>=
y.nok <- apply(y, c(1, 2), sum)
y.nojk <- apply(y.nok>0, 1, sum)
table(y.nojk)
@ 
\end{frame}




\begin{frame}[fragile]
  \frametitle{Spider plot}
<<spider,size='scriptsize',fig.width=7.15,fig.show='hide',echo=-(1:2)>>=
## plot(lambda, col=terrain.colors(100),
##      main="Density surface, activity centers, traps, and capture locs")
plot(0, xlim=c(0,1), ylim=c(0,1), asp=1, xlab="", ylab="",
     main="Activity centers, traps, and capture locs")
s.cap <- s[captured,]
for(i in 1:n) {
    traps.i <- which(rowSums(y[i,,])>0)
    for(j in 1:length(traps.i)) {
        segments(s.cap[i,1], s.cap[i,2],
                 x[traps.i[j],1], x[traps.i[j],2], col=gray(0.3))
    }
}
points(s[captured,], pch=16, col="blue") ## Activity center locations
points(s[!captured,], pch=1, col="blue") ## Activity center locations
points(x, pch=3)                         ## Trap locations
@   
\end{frame}


\begin{frame}
  \frametitle{Spider plot}
  \centering
  \includegraphics[width=0.85\textwidth]{figure/spider-1} \\
\end{frame}






% \begin{frame}
%   \frametitle{Joint likelihood}
%   % \footnotesize
%   \small
%   The joint likelihood looks similar to the nonspatial likelihood,
%   except that we have a third dimension for $y$ and we have to
%   integrate out the latent activity center $s_i$. 
%   \pause
%   \vfill
%   \flushleft
%   \begin{equation*}
% %  \begin{multline*}
% %    L(N,p; y,n) =                                          \\
%     L(N,p; y,n) = \left\{\prod_{i=1}^n \prod_{j=1}^J \prod_{k=1}^K p_{ij}^{y_{ijj}}(1-p_{ij})^{1-y_{ijk}}\right\}
% %    \left\{\frac{N!}{(N-n)!}  \left(\prod_{j=1}^J(1-p)\right)^{N-n} \right\}
%     \frac{N!}{(N-n)!}  \left(q^*\right)^{N-n}
% %  \end{multline*}
%   \end{equation*}
% \end{frame}



% \begin{frame}
%   \frametitle{Model variations}
%   Aside from the approach to estimation, the key consideration
%   concerns the sources of variation in capture probability ($p$). \\
%   \pause
%   \vfill
%   Otis et al. (1978, Wildlife Monographs) identified several model variations
%   \begin{itemize}
%     \small
%     \item $M_0$ -- $p$ is constant
%     \item $M_t$ -- unique $p$ for each capture occasion
%     \item \hangindent=0.8cm $M_b$ -- behavioral response with $p$ different than
%       recapture probability $c$
%     \item $M_h$ -- individual heterogeneity in $p$
%   \end{itemize}
%   \pause \vfill
%   These can be combined, but beware of identifiability issues. See
%   Otis et al. (1978) for details.  \\
%   \pause \vfill
%   Later we'll talk about another important class of models, the
%   ``individual covariate'' models.  
% \end{frame}






%\section{Model $M_0$}


%\subsection{Simulation}


%\subsection{Model $M_0$}






% \begin{frame}[fragile]
%   \frametitle{Summary stats}
%   Capture history frequencies
% <<M0-hist,size='scriptsize'>>=
% histories <- apply(y, 1, paste, collapse="")
% sort(table(histories))
% @
% \pause
% \vfill
%   Detection frequencies
% <<M0-freq,size='scriptsize'>>=
% y.tilde <- rowSums(y)
% sort(table(y.tilde))
% @   
% \end{frame}



%\subsection{Model $M_t$}


% \begin{frame}[fragile]
%   \frametitle{Model $M_t$ -- Temporal variation}
%   Capture probability for each occasion
% <<sim-Mt-pars,size='scriptsize'>>=
% p.t <- c(0.3, 0.5, 0.2, 0.4)
% @
%   \pause
%   \vfill
%   All capture histories (for captured and uncaptured individuals)
%   \vspace{-6pt}
% <<sim-Mt-ch,size='scriptsize'>>=
% y.all.Mt <- matrix(NA, N, J)
% for(i in 1:N) {
%     y.all.Mt[i,] <- rbinom(J, 1, p.t) }
% @
%   \pause
%   \vfill
%   Observed capture histories (data)
%   \vspace{-6pt}
% <<sim-Mt-y1,size='scriptsize'>>=
% captured.Mt <- rowSums(y.all.Mt)>0
% n.Mt <- sum(captured.Mt)
% y.Mt <- y.all.Mt[captured.Mt,]
% y.Mt[1:3,]
% colSums(y.Mt)
% @ 
% \end{frame}









\section{Likelihood}



\begin{frame}
  \frametitle{Outline}
  \Large
  \tableofcontents[currentsection]
\end{frame}




\begin{frame}
  \frametitle{Software options}
%  \small
  Program DENSITY
  \begin{itemize}
%  \footnotesize
    \item Windows program with GUI
  \end{itemize}
  \vfill
  R package `secr'
  \begin{itemize}
%  \footnotesize
    \item The oldest R package with the most options
  \end{itemize}
  \vfill
  R package `oSCR'
  \begin{itemize}
%  \footnotesize
    \item A newer R package with similar functionality
  \end{itemize}
\end{frame}



% %% p(y,n|N,p)
% \begin{frame}[fragile]
%   \frametitle{Joint likelihood for $M_0$}
%   The joint likelihood has a multinomial form:
%   \begin{multline*}
%     L(N,p; y,n) = \\
%     \left\{\prod_{i=1}^n \prod_{j=1}^J p^{y_{ij}}(1-p)^{1-y_{ij}}\right\}
%     \left\{\frac{N!}{(N-n)!}  \left(\prod_{j=1}^J(1-p)\right)^{N-n} \right\}
%   \end{multline*}
%   \pause
%   \vfill
% <<nll-M0,echo=TRUE,size='scriptsize'>>=
% nll.M0 <- function(pars, y) {           ## Negative log-likelihood
%     n <- nrow(y);       J <- ncol(y)
%     N <- exp(pars[1])
%     n0 <- N-n
%     if(n0<0) return(NA)
%     p <- plogis(pars[2])
%     ld.y1 <- sum(dbinom(y, 1, p, log=TRUE))
%     p0 <- (1-p)^J
%     ld.n0 <- lgamma(N+1)-lgamma(n0+1)+n0*log(p0)
%     nll <- -(ld.y1+ld.n0)
%     return(nll)
% }
% @
% \end{frame}



% \begin{frame}[fragile]
%   \frametitle{Maximize joint likelihood for $M_0$}
% Minimized the negative log-likelihood
% <<opt-nll-M0, size='scriptsize'>>=
% fm.M0 <- optim(c(log.N=4,logit.p=0), nll.M0, y=y, hessian=TRUE)
% fm.M0.est <- data.frame(Estimate=c(fm.M0$par[1], fm.M0$par[2]),
%                         SE=sqrt(diag(solve(fm.M0$hessian))))
% fm.M0.est
% @
% \pause
% \vfill
% Back-transform the estimates
% <<opt-nll-M0-back, size='scriptsize'>>=
% c(N.hat=exp(fm.M0$par[1]), p.hat=plogis(fm.M0$par[2]))
% @
% \pause
% \vfill
% Compare to data-generating values
% <<dg,size='scriptsize'>>=
% c(N=N, p=p)
% @ 
% \end{frame}


<<write,include=FALSE,results="hide",purl=FALSE>>=
ch.out <- data.frame(session=1,
                     individual=rep(slice.index(y, 1), y),
                     occasion=rep(slice.index(y, 3), y),
                     trap=rep(slice.index(y, 2), y))
write.table(ch.out, file="encounter_data_file.csv",
            row.names=FALSE, col.names=FALSE, sep=",")
traps.out <- data.frame(trap=1:nrow(x), x*1000)
write.table(traps.out, file="trap_data_file.csv",
            row.names=FALSE, col.names=FALSE, sep=",")
library(secr)
@ 


\begin{frame}[fragile]
  \frametitle{R package `secr'}
  Import data from two text files
<<secr-in,warning=FALSE,size='tiny'>>=
library(secr)  
sch <- read.capthist(captfile="encounter_data_file.csv",
                     trapfile="trap_data_file.csv",
                     detector="proximity", fmt="trapID")
summary(sch)
@   
\end{frame}



\begin{frame}[fragile]
  \frametitle{R package `secr'}
<<secr-plot,out.width="70%",fig.align="center">>=
plot(sch)
@ 
\end{frame}




\begin{frame}[fragile]
  \frametitle{R package `secr'}
  Fit the SCR equivalent of Model $M_0$
<<secr-M0,size='scriptsize',cache=FALSE,warning=FALSE>>=
fm.M0 <- secr.fit(sch, model=list(D=~1, g0=~1, sigma=~1),
                  buffer=150, trace=FALSE, ncores=3)
coef(fm.M0)
@
\pause
\vfill
Estimates on original scale
<<secr-M0-real,size='scriptsize'>>=
predict(fm.M0)
@
\inr{D} is density (animals/ha), \inr{g0} is $g_0$, and \inr{sigma} is 
$\sigma$.   
\end{frame}



\begin{frame}[fragile]
  \frametitle{R package `secr'}
  Fit the SCR equivalent of Model $M_t$
<<secr-Mt,size='scriptsize',cache=FALSE,warning=FALSE>>=
fm.Mt <- secr.fit(sch, model=list(D=~1, g0=~t, sigma=~1),
                  buffer=150, trace=FALSE, ncores=3)
coef(fm.Mt)
@   
\pause
\vfill
Estimates on original scale
<<secr-Mt-real,size='scriptsize'>>=
predict(fm.Mt)
@ 
\end{frame}



\begin{frame}[fragile]
  \frametitle{R package `secr'}
  Fit the SCR equivalent of Model $M_b$
<<secr-Mb,size='scriptsize',cache=FALSE,warning=FALSE>>=
fm.Mb <- secr.fit(sch, model=list(D=~1, g0=~b, sigma=~1),
                  buffer=150, trace=FALSE, ncores=3)
coef(fm.Mb)
@   
\pause
\vfill
Estimates on original scale
<<secr-Mb-real,size='scriptsize'>>=
predict(fm.Mb)
@ 
\end{frame}


\begin{frame}[fragile]
  \frametitle{R package `secr'}
  What about $N$? \pause \inr{E.N} is the expected value of
  $N$. \inr{R.N} is the realized value of $N$. 
  \vfill
<<regionN-M0,size='footnotesize'>>=
region.N(fm.M0)
@
  \pause
<<regionN-Mt,size='footnotesize'>>=
region.N(fm.Mt)
@
  \pause
<<regionN-Mb,size='footnotesize'>>=
region.N(fm.Mb)
@
%\pause
%\vfill
\end{frame}


\begin{frame}[fragile]
  \frametitle{R package `secr'}
  \small
  Was \inr{buffer} big enough?
<<buffer1,size='scriptsize',warning=FALSE,cache=FALSE>>=
predict(update(fm.M0, buffer=100))[1,]
@
\pause
\vspace{-12pt}
<<buffer2,size='scriptsize',warning=FALSE,cache=FALSE>>=
predict(update(fm.M0, buffer=150))[1,]
@   
\pause
\vspace{-12pt}
<<buffer3,size='scriptsize',warning=FALSE,cache=FALSE>>=
predict(update(fm.M0, buffer=200))[1,]
@   
\pause
\vspace{-12pt}
<<buffer4,size='scriptsize',warning=FALSE,cache=FALSE>>=
predict(update(fm.M0, buffer=250))[1,]
@   
\pause
\vspace{-12pt}
<<buffer5,size='scriptsize',warning=FALSE,cache=FALSE>>=
predict(update(fm.M0, buffer=300))[1,]
@   
\end{frame}



\begin{frame}[fragile]
  \frametitle{R package `secr'}
  AIC
<<aic,size='tiny'>>=
AIC(fm.M0, fm.Mt, fm.Mb)
@   
\end{frame}


\section{Data augmentation}


%\section{Prediction}
%\subsection{Likelihood-based inference}


\begin{frame}
  \frametitle{Outline}
  \Large
  \tableofcontents[currentsection]
\end{frame}





\begin{frame}
  \frametitle{Data augmentation model}
  The DA version of a basic SCR model is:
  \begin{gather*}
    \bsi \sim \mathrm{Unif}(\mathcal{S}) \\
    z_i \sim \mathrm{Bern}(\psi) \\
    p_{ij} = g_0\exp(-\|\bsi-\bxj\|^2/(2\sigma^2)) \\
    y_{ijk} \sim \mathrm{Bern}(z_i \times p_{ij}) \\
    N=\sum_{i=1}^M z_i
  \end{gather*}
  % A uniform prior on $\psi$ results in a discrete uniform prior on
  % $N$. We can change the prior for $N$ by changing the prior on
  % $\psi$, recognizing that $E(N)=M\psi$.
  % But why bother with augmentation?
  % \begin{itemize}
  %   \item DA works for \alert{all} varieties of mark-recapture models
  %   \item Make it easy to incorporate
  %     individual-covariates\dots\pause including distance and
  %     location!   
  % \end{itemize}
\end{frame}






\begin{frame}[fragile]
  \frametitle{Model SCR$_0$ -- data augmentation}
\vspace{-3pt}
<<bugs-SC0-R,size='scriptsize',eval=FALSE>>=
writeLines(readLines("SCR0.jag"))
@
<<bugs-SC0,size='scriptsize',comment='',background='lightblue',echo=FALSE>>=
writeLines(readLines("SCR0.jag"))
@
\end{frame}


<<rjags,include=FALSE,results="hide">>=
library(rjags)
@ 


\begin{frame}[fragile]
  \frametitle{Model SCR$_0$ -- data augmentation}
  Data
  \vspace{-6pt}
<<jd-SCR0-aug,size='scriptsize'>>=
M <- 150
y.aug <- array(0, c(M, J, K))
y.aug[1:nrow(y),,] <- y
jags.data.SCR0 <- list(y=y.aug, M=M, J=J, K=K,
                       x=x, xlim=c(0,1), ylim=c(0,1))
@
\pause
\vfill
  Inits and parameters
  \vspace{-6pt}
<<ji-M0-aug,size='scriptsize'>>=
ji.SCR0 <- function() {
    list(z=rep(1,M), psi=runif(1),
         s=cbind(runif(M), runif(M)),
         g0=runif(1), sigma=runif(1, 0.05, 0.1)) }
jp.SCR0 <- c("g0", "sigma", "EN", "N")
library(jagsUI)
@
\pause
\vfill
MCMC
  \vspace{-6pt}
<<mcmc-M0-aug,size='scriptsize',results='hide',cache=FALSE>>=
jags.post.SCR0 <- jags.basic(data=jags.data.SCR0, inits=ji.SCR0,
                             parameters.to.save=jp.SCR0,
                             model.file="SCR0.jag",
                             n.chains=3, n.adapt=100, n.burnin=0,
                             n.iter=2000, parallel=TRUE)
@ 
\end{frame}




\begin{frame}[fragile]
  \frametitle{Posterior summaries}
<<summary-mcmc-SCR0,size='tiny'>>=
summary(jags.post.SCR0)
@ 
\end{frame}



\begin{frame}[fragile]
  \frametitle{Traceplots and density plots}
<<plot-mcmc-SCR0,size='footnotesize',out.width="0.7\\textwidth",fig.align='center'>>=
plot(jags.post.SCR0[,jp.SCR0])
@ 
\end{frame}


\begin{frame}
  \frametitle{Easy tricks to speed up Bayesian inference}
  \begin{itemize}
    % \item Use joint likelihood $p(y|n)p(0|n,N)p(N)$ approach as shown in
    %   non-spatial lecture.
    %   \begin{itemize}
    %     \item This can work well, but not when there are other
    %       individual-level covariates.
    %   \end{itemize}
    \item Treat $z_i=1$ as data for first $n$ individuals.
    \item If there are no occasion-specific covariates, collapse data
      and use binomial instead of Bernoulli distribution.
    \item Use a single zero for each augmented individual, instead of
      an array of zeros. Then compute probability of detecting an
      individual at least once.
  \end{itemize}
\end{frame}




\begin{frame}[fragile]
  \frametitle{Model SCR$_0$ -- data augmentation}
\vspace{-3pt}
<<bugs-SC0-faster-R,size='tiny',eval=FALSE>>=
writeLines(readLines("SCR0-faster.jag"))
@
<<bugs-SC0-faster,size='tiny',comment='',background='lightblue',echo=FALSE>>=
writeLines(readLines("SCR0-faster.jag"))
@
\end{frame}




\begin{frame}[fragile]
  \frametitle{Model SCR$_0$ -- faster}
  Data
  \vspace{-6pt}
<<jd-SCR0-aug-faster,size='scriptsize'>>=
y.tilde <- apply(y, c(1,2), sum)
n <- nrow(y)
jags.data.SCR0.faster <- list(y.tilde=y.tilde, n=n, M=M, J=J,
                              z=c(rep(1, n), rep(NA, M-n)),
                              K=K, zero=rep(0, M), x=x,
                              xlim=c(0,1), ylim=c(0,1))
@
\pause
\vfill
  Inits and parameters (same as before)
\pause
\vfill
<<ji-M0-aug-faster,size='scriptsize'>>=
ji.SCR0.faster <- function() {
    list(z=c(rep(NA, n), rep(0,M-n)), psi=runif(1),
         s=cbind(runif(M), runif(M)),
         g0=runif(1), sigma=runif(1, 0.05, 0.1)) }
@
MCMC
  \vspace{-6pt}
<<mcmc-M0-aug-faster,size='scriptsize',results='hide',cache=FALSE>>=
jags.post.SCR0.faster <- jags.basic(data=jags.data.SCR0.faster,
                                    inits=ji.SCR0.faster,
                                    parameters.to.save=jp.SCR0,
                                    model.file="SCR0-faster.jag",
                                    n.chains=3, n.adapt=100, n.burnin=0,
                                    n.iter=2000, parallel=TRUE)
@ 
\end{frame}




\begin{frame}[fragile]
  \frametitle{Posterior summaries}
<<summary-mcmc-SCR0-faster,size='tiny'>>=
summary(jags.post.SCR0.faster)
@ 
\end{frame}



\begin{frame}[fragile]
  \frametitle{Traceplots and density plots}
<<plot-mcmc-SCR0-faster,size='footnotesize',out.width="0.7\\textwidth",fig.align='center'>>=
plot(jags.post.SCR0.faster[,jp.SCR0])
@ 
\end{frame}




\begin{frame}
  \frametitle{SCR study design}
  SCR uses model-based, rather than design-based,
  inference (see Ch. 10). \\ 
  \pause
  \vfill
  Random placement of traps is not required, but it's a good idea to
  randomly sample locations along the environmental gradients you're
  interested in. \\
  \pause \vfill
  The other two key design considerations are:
  \begin{enumerate}
    \item<3-> Capture as many individuals as you can (i.e., maximize $n$)
    \item<4-> Obtain as many {\it spatial} recaptures as possible
  \end{enumerate}
  \vfill
  \uncover<5->{
    There is a tradeoff between these two objectives. Simulation is
    often the best option for finding the right balance.
  }
\end{frame}

%\section{Summary}


\begin{frame}
  \frametitle{SCR summary}
  We assume that variation in $p$ arises from distance between animals
  and traps. \\
  \pause \vfill
  We can estimate abundance and model distribution (i.e., spatial
  variation in density) \\
  \pause \vfill
  Next time, we'll see how to do that using secr and JAGS, and we'll
  make a bunch of maps. \\
\end{frame}




\section{Assignment}




\begin{frame}[fragile]
  \frametitle{Assignment}
  Create a self-contained R script or Rmarkdown file to do the
  following: 
  \vfill
  \begin{enumerate}
%    \item Fit a ``local behavioral response'' model,
%      rather than a ``global behavioral response'' model in secr.
    \item Import the bear data formatted for `secr' and fit a model
      where $g_0$ varies among the 8 occasions. Use `secr' to
      determine what an appropriate buffer should be.
    \item Import the bear data formatted for JAGS and tabulate the
      capture frequencies and the number of spatial recapture. Fit the
      same model in JAGS that you fit in secr. Compare estimates and 95\% CIs
      for $g_{0,t}$, $\sigma$, $E(N)$ and $N$.  
  \end{enumerate}
  \vfill
  Upload your {\tt .R} or {\tt .Rmd} file to ELC before 5:00 PM on Monday. 
\end{frame}





\end{document}

