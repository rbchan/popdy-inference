\documentclass[color=usenames,dvipsnames]{beamer}
%\documentclass[color=usenames,dvipsnames,handout]{beamer}

\usepackage[roman]{../lectures}
%\usepackage[sans]{../lectures}


\hypersetup{pdfpagemode=UseNone,pdfstartview={FitV}}



% Load function to compile and open PDF
<<build-fun,include=FALSE,purl=FALSE>>=
source("../rnw2pdf.R")
@

% Compile and open PDF
<<buildit,include=FALSE,eval=FALSE>>=
rnw2pdf("lecture-cap-recap-spatial-II")
rnw2pdf("lecture-cap-recap-spatial-II", tangle=TRUE)
@ 

<<knitr-theme,include=FALSE,purl=FALSE>>=
knit_theme$set("edit-kwrite")
@

% New command for inline code that isn't to be evaluated
\definecolor{inlinecolor}{rgb}{0.878, 0.918, 0.933}
\newcommand{\inr}[1]{\colorbox{inlinecolor}{\texttt{#1}}}




\newcommand{\bxt}{${\bm x}_j$}
\newcommand{\bx}{{\bm x}}
\newcommand{\bxj}{{\bm x}_j}
\newcommand{\bst}{${\bm s}_i$}
\newcommand{\bs}{{\bm s}}
\newcommand{\bsi}{{\bm s}_i}
\newcommand{\ed}{\|\bx - \bs\|}
\newcommand{\cs}{\mathcal{S} }
\newcommand{\dsixj}{\|\bsi - \bxj\|}


\begin{document}




\begin{frame}[plain]
  \LARGE
  \centering
  {
    \LARGE Lecture 12 -- Spatial capture-recapture \\
    for closed populations: \\
    \Large Part II: mapping density surfaces and other posteriors \\
  }
  {\color{default} \rule{\textwidth}{0.1pt} }
  \vfill
  \large
  WILD(FISH) 8390 \\
  Estimation of Fish and Wildlife Population Parameters \\
  \vfill
  \large
  Richard Chandler \\
  University of Georgia \\
\end{frame}






\section{Overview}



\begin{frame}[plain]
  \frametitle{Outline}
  \Large
  \only<1>{\tableofcontents}%[hideallsubsections]}
  \only<2 | handout:0>{\tableofcontents[currentsection]}%,hideallsubsections]}
\end{frame}



\begin{frame}
  \frametitle{SCR overview}
  {\centering Two motivations for SCR \\}
  \vfill
  \begin{enumerate}
    \item Improved inference
    \begin{itemize}
      \item<1-> Non-spatial models can't properly account for sources
        of variation in $p$ that can cause bias.
        \begin{itemize}
          \item<1-> Distance to traps
          \item<1-> Trap-specific covariates
        \end{itemize}
      \item<2-> SCR makes it possible to estimate \alert{density}, not
        just $N$ in an unknown region. 
    \end{itemize}
    \pause
    \vfill
  \item<3-> Improved science
  \begin{itemize}
    \item<3-> We can ask new questions, such as:
      \begin{itemize}
        \item<3-> What influences spatial variation in density?
        \item<4-> How do survival and recruitment vary in space and time?
        \item<5-> How does movement influence density and detectability?
      \end{itemize}
    \item<6-> Rather than think of SCR as a new estimation tool, you
      can think of it as an individual-based framework for inference on
      spatial population dynamics.
    \end{itemize}
  \end{enumerate}
\end{frame}





% \begin{frame}
%   \frametitle{In-class exercise}
%   Building off the previous example\dots
%   \begin{enumerate}
%     \item Compute $\bar{p}$ for line-transect sampling when
%       $\sigma=50, 100, \mathrm{and}\, 200$, instead of $\sigma=25$.  
%     \item Repeat, but for point-transect sampling. 
%   \end{enumerate}
% \end{frame}





\begin{frame}
  \frametitle{\large Closed population model ($N$ known hypothetically) }
  \footnotesize
  State model (a spatial point process model) %\\
  \begin{gather*}
    \lambda(\bs) = \beta_0 + \beta_1 w_1(\bs) + \beta_2 w_2(\bs) \dots \\
    \Lambda = \int_{\mathcal{S}} \lambda(\bs) \; \mathrm{d}\bs \\
    N \sim \mathrm{Pois}(\Lambda) \\
    \bsi \propto p(\lambda(\bs)) \;\; \mathrm{for}\; i=1,\dots,N 
  \end{gather*}
  \pause
%  \vfill
  Observation model (supposing $N$ was known)
  \begin{gather*}
    p_{ij} = g_0\exp(-\|\bsi - \bxj\|^2/(2\sigma^2))  \;\; \mathrm{for}\, j=1,\dots,J  \\
    y_{ijk} \sim \mathrm{Bernoulli}(p_{ij})
  \end{gather*}
  \pause
%  \vfill
%  \footnotesize
  \scriptsize
  Definitions \\
  \hangindent=0.9cm $\lambda(\bs)$ -- The ``intensity function'' %or ``density surface''
  describing the density of individuals at location $\bs$ \\ 
  $\Lambda$ -- Expected number of individuals \\
  $N$ -- Realized number of individuals (ie, population size) \\
  $\bsi$ -- Location of the $i$th activity center \\
  $\bxj$ -- Location of trap $j$ \\
  $\dsixj$ -- Euclidean distance between $\bsi$ and $\bxj$ \\
  $g_0$ -- Capture probability when distance between activity centers
  and traps is 0 \\
  $\sigma$ -- Scale parameter of encounter function \\
  $p_{ij}$ -- Capture probability \\
  $y_{ijk}$ -- Spatial capture histories \\
\end{frame}







\section{Simulation}


\begin{frame}
  \frametitle{Outline}
  \Large
%  \tableofcontents[currentsection,currentsubsection]
  \tableofcontents[currentsection]
\end{frame}






\begin{frame}[fragile]
  \frametitle{Inhomogeneous Poisson point process}
  First, let's import a raster layer
<<ippp1,size='footnotesize',fig.width=7.2,out.width="60%",fig.align="center",results="hide">>=
library(raster)
elevation <- raster("elevation.tif")
plot(elevation, col=topo.colors(100), main="Elevation")
@
\end{frame}




\begin{frame}[fragile]
  \frametitle{Inhomogeneous Poisson point process}
  \small
  Second, let's pick some coefficients and create a density surface
<<ippp2,size='footnotesize',fig.width=7.2,out.width="60%",fig.align="center">>=
beta0 <- -15
beta1 <- 0.01 #0.005
lambda <- exp(beta0 + beta1*elevation) # Intensity function
plot(lambda, col=terrain.colors(100), main="Density surface")
@
\end{frame}




\begin{frame}[fragile]
  \frametitle{Inhomogeneous Poisson point process}
  \small
  Third, simulate $N$
  \vspace{-6pt}
<<ippp3,size='footnotesize'>>=
set.seed(538)  
ds <- 1                            ## Pixel area is 1 ha
lambda.values <- values(lambda)    ## Convert raster to vector
Lambda <- sum(lambda.values*ds)    ## E(N)
(N <- rpois(1, Lambda))            ## Realized N
@
\pause
\vfill
Fourth, simulate and $\bs_1, \dots, \bs_N$. To do this, we'll pick
pixels proportional to density. Then we'll jitter each point
inside its pixel. 
  \vspace{-6pt}
<<ipp4,size='footnotesize'>>=
n.pixels <- length(lambda)
jitter <- 0.005                    ## Half width of pixel 
s.pixels <- sample(n.pixels, size=N, replace=TRUE,
                   prob=lambda.values/Lambda)
elevation.xyz <- as.data.frame(elevation, xy=TRUE)
s <- elevation.xyz[s.pixels,c("x","y")] +
    cbind(runif(N, -jitter, jitter),runif(N, -jitter, jitter))
@
\end{frame}







\begin{frame}[fragile]
  \frametitle{Inhomogeneous Poisson point process}
<<ippp5,size='scriptsize',fig.width=7.2,out.width="70%",fig.align="center">>=
plot(lambda, col=terrain.colors(100),
     main="Density surface with activity centers")
points(s, pch=16, cex=1, col="blue")
@
\end{frame}






\begin{frame}[fragile]
  \frametitle{Traps}
<<traps1,size='scriptsize',fig.width=7.2,out.width="60%",fig.align="center">>=
x <- cbind(rep(seq(0.15, 0.85, by=0.1), each=8),
           rep(seq(0.15, 0.85, by=0.1), times=8))  ## Trap locations
plot(lambda, col=terrain.colors(100),
     main="Density surface with activity centers and traps")
points(s, pch=16, col="blue") ## Activity center locations
points(x, pch=3)              ## Trap locations
@
\end{frame}





\begin{frame}[fragile]
  \frametitle{Distance between traps and activity centers}
  Compute distances between activity centers ($\bs_1, \dots, \bs_N$)
  and traps ($\bx_1, \dots, \bx_J$).
<<dist1,size='footnotesize'>>=
J <- nrow(x)                 ## nTraps
dist.sx <- matrix(NA, N, J)  
for(i in 1:N) {
    dist.sx[i,] <- sqrt((s[i,1]-x[,1])^2 + (s[i,2]-x[,2])^2)
}
@
\pause
\vfill
  Look at distances between first 4 individuals and first 5 traps.
<<dist2,size='footnotesize'>>=
dist.sx[1:4,1:5]
@

\end{frame}






\begin{frame}[fragile]
  \frametitle{Capture probability}
  Compute capture probability
<<p1,size='footnotesize'>>=
g0 <- 0.2
sigma <- 0.05
p <- g0*exp(-dist.sx^2/(2*sigma^2))
@
\pause
\vfill
  Look at capture probs for first 4 individuals and first 5 traps.
<<p2,size='footnotesize'>>=
print(p[1:4,1:5], digits=3)
@

\end{frame}





\begin{frame}[fragile]
  \frametitle{Capture histories}
  Simulate capture histories for all $N$ individuals
<<y1,size='footnotesize'>>=
K <- 5                          # nOccasions
y.all <- array(NA, c(N, J, K))
for(i in 1:N) {
    for(j in 1:J) {
        y.all[i,j,] <- rbinom(K, 1, prob=p[i,j])
    }
}
@
\pause
\vfill
  Discard individuals not captured
<<y2,size='footnotesize'>>=
captured <- rowSums(y.all)>0
y <- y.all[captured,,]
@
\pause
\vfill
  Capture histories for first 2 individuals and first 5 traps
  on first occasion.
<<y3,size='footnotesize'>>=
y[1:2,1:5,1]
@
\end{frame}

















\section{Likelihood}



\begin{frame}
  \frametitle{Outline}
  \Large
  \tableofcontents[currentsection]
\end{frame}




\begin{frame}
  \frametitle{Software options}
%  \small
  Program DENSITY
  \begin{itemize}
%  \footnotesize
    \item Windows program with GUI
  \end{itemize}
  \vfill
  R package `secr'
  \begin{itemize}
%  \footnotesize
    \item The oldest R package with the most options
  \end{itemize}
  \vfill
  R package `oSCR'
  \begin{itemize}
%  \footnotesize
    \item A newer R package with similar functionality
  \end{itemize}
\end{frame}





<<write,include=FALSE,results="hide">>=
ch.out <- data.frame(session=1,
                     individual=rep(slice.index(y, 1), y),
                     occasion=rep(slice.index(y, 3), y),
                     trap=rep(slice.index(y, 2), y))
write.table(ch.out, file="encounter_data_file.csv",
            row.names=FALSE, col.names=FALSE, sep=",")
traps.out <- data.frame(trap=1:nrow(x), x*1000)
write.table(traps.out, file="trap_data_file.csv",
            row.names=FALSE, col.names=FALSE, sep=",")
library(secr)
@ 


\begin{frame}[fragile]
  \frametitle{R package `secr'}
  Import data from two text files
<<secr-in,warning=FALSE,size='tiny'>>=
library(secr)  
sch <- read.capthist(captfile="encounter_data_file.csv",
                     trapfile="trap_data_file.csv",
                     detector="proximity", fmt="trapID")
library(sp)
elevation.xyz <- as.data.frame(elevation, xy=TRUE)
elevation.xyz.m <- elevation.xyz
elevation.xyz.m$x <- elevation.xyz$x*1000
elevation.xyz.m$y <- elevation.xyz$y*1000
elevation.xyz.m$elevation <- scale(elevation.xyz$elevation)
elevation.m <- rasterFromXYZ(elevation.xyz.m)
elev.sp <- as(elevation.m, "SpatialGridDataFrame")
trp <- traps(sch)
mask <- make.mask(trp, buffer=150)
mask <- addCovariates(mask, spatialdata=elev.sp)
@   
\end{frame}



\begin{frame}[fragile]
  \frametitle{R package `secr'}
<<secr-plot,out.width="70%",fig.align="center">>=
plot(sch)
@ 
\end{frame}




\begin{frame}[fragile]
  \frametitle{R package `secr'}
  Fit the SCR equivalent of Model $M_0$
<<secr-M0,size='scriptsize',cache=TRUE>>=
fm.elev <- secr.fit(sch, model=list(D=~elevation, g0=~1, sigma=~1),
                    mask=mask, trace=FALSE)
coef(fm.elev)
@
\pause
\vfill
Estimates on original scale
<<secr-M0-real,size='scriptsize'>>=
predict(fm.elev)
dsurf <- predictDsurface(fm.elev)
dsurf.r <- raster(dsurf, covariate="D.0")
@
\inr{D} is density (animals/ha), \inr{g0} is $g_0$, and \inr{sigma} is 
$\sigma$.   
\end{frame}



\begin{frame}[fragile]
  \frametitle{R package `secr'}
  What about $N$? \pause \inr{E.N} is the expected value of
  $N$. \inr{R.N} is the realized value of $N$. 
  \vfill
<<regionN-M0,size='footnotesize'>>=
region.N(fm.elev)
@
\end{frame}




\section{Data augmentation}


%\section{Prediction}
%\subsection{Likelihood-based inference}


\begin{frame}
  \frametitle{Outline}
  \Large
  \tableofcontents[currentsection]
\end{frame}





\begin{frame}
  \frametitle{Data augmentation model}
  The DA version of a basic SCR model is:
  \begin{gather*}
    \bsi \sim \mathrm{Unif}(\mathcal{S}) \\
    z_i \sim \mathrm{Bern}(\psi) \\
    p_{ij} = g_0\exp(-\|\bsi-\bxj\|^2/(2\sigma^2)) \\
    y_{ijk} \sim \mathrm{Bern}(z_i p_{ij}) \\
    N=\sum_{i=1}^M z_i
  \end{gather*}
  % A uniform prior on $\psi$ results in a discrete uniform prior on
  % $N$. We can change the prior for $N$ by changing the prior on
  % $\psi$, recognizing that $E(N)=M\psi$.
  % But why bother with augmentation?
  % \begin{itemize}
  %   \item DA works for \alert{all} varieties of mark-recapture models
  %   \item Make it easy to incorporate
  %     individual-covariates\dots\pause including distance and
  %     location!   
  % \end{itemize}
\end{frame}






\begin{frame}[fragile]
  \frametitle{Model SCR$_0$ -- data augmentation}
\vspace{-3pt}
<<bugs-SC0,size='scriptsize'>>=
writeLines(readLines("SCR0.jag"))
@
\end{frame}


<<rjags,include=FALSE,results="hide">>=
library(rjags)
@ 


\begin{frame}[fragile]
  \frametitle{Model SCR$_0$ -- data augmentation}
  Data
  \vspace{-6pt}
<<jd-SCR0-aug,size='scriptsize'>>=
M <- 150
y.aug <- array(0, c(M, J, K))
y.aug[1:nrow(y),,] <- y
jags.data.SCR0 <- list(y=y.aug, M=M, J=J, K=K,
                       x=x, xlim=c(0,1), ylim=c(0,1))
@
\pause
\vfill
  Inits and parameters
  \vspace{-6pt}
<<ji-M0-aug,size='scriptsize'>>=
ji.SCR0 <- function() {
    list(z=rep(1,M), psi=runif(1),
         s=cbind(runif(M), runif(M)),
         g0=runif(1), sigma=runif(1, 0.05, 0.1)) }
jp.SCR0 <- c("g0", "sigma", "EN", "N")
library(jagsUI)
@
\pause
\vfill
MCMC
  \vspace{-6pt}
<<mcmc-M0-aug,size='scriptsize',results='hide',cache=TRUE>>=
jags.post.SCR0 <- jags.basic(data=jags.data.SCR0, inits=ji.SCR0,
                             parameters.to.save=jp.SCR0,
                             model.file="SCR0.jag",
                             n.chains=3, n.adapt=100, n.burnin=0,
                             n.iter=2000, parallel=TRUE)
@ 
\end{frame}




\begin{frame}[fragile]
  \frametitle{Posterior summaries}
<<summary-mcmc-SCR0,size='tiny'>>=
summary(jags.post.SCR0)
@ 
\end{frame}



\begin{frame}[fragile]
  \frametitle{Traceplots and density plots}
<<plot-mcmc-SCR0,size='footnotesize',out.width="0.7\\textwidth",fig.align='center'>>=
plot(jags.post.SCR0[,jp.SCR0])
@ 
\end{frame}


\begin{frame}
  \frametitle{How do we speed up Bayesian inference?}
  \begin{itemize}
    \item Use joint likelihood $p(y|n)p(0|n,N)p(N)$ approach as shown in
      non-spatial lecture.
      \begin{itemize}
        \item This can work well, but not when there are other
          individual-level covariates.
      \end{itemize}
    \item Treat $z_i=1$ as data for first $n$ individuals.
    \item If there are no occasion-specific covariates, collapse data
      and use binomial instead of Bernoulli distribution.
    \item Use a single zero for each augmented individual, instead of
      an array of zeros. Then compute probability of detecting an
      individual at least once.
  \end{itemize}
\end{frame}




\begin{frame}[fragile]
  \frametitle{Model SCR$_0$ -- data augmentation}
\vspace{-3pt}
<<bugs-SC0-faster,size='tiny'>>=
writeLines(readLines("SCR0-faster.jag"))
@
\end{frame}




\begin{frame}[fragile]
  \frametitle{Model SCR$_0$ -- faster}
  Data
  \vspace{-6pt}
<<jd-SCR0-aug-faster,size='scriptsize'>>=
y.tilde <- apply(y, c(1,2), sum)
n <- nrow(y)
jags.data.SCR0.faster <- list(y.tilde=y.tilde, n=n, M=M, J=J,
                              z=c(rep(1, n), rep(NA, M-n)),
                              K=K, zero=rep(0, M), x=x,
                              xlim=c(0,1), ylim=c(0,1))
@
\pause
\vfill
  Inits and parameters (same as before)
\pause
\vfill
<<ji-M0-aug-faster,size='scriptsize'>>=
ji.SCR0.faster <- function() {
    list(z=c(rep(NA, n), rep(0,M-n)), psi=runif(1),
         s=cbind(runif(M), runif(M)),
         g0=runif(1), sigma=runif(1, 0.05, 0.1)) }
@
MCMC
  \vspace{-6pt}
<<mcmc-M0-aug-faster,size='scriptsize',results='hide',cache=TRUE>>=
jags.post.SCR0.faster <- jags.basic(data=jags.data.SCR0.faster,
                                    inits=ji.SCR0.faster,
                                    parameters.to.save=jp.SCR0,
                                    model.file="SCR0-faster.jag",
                                    n.chains=3, n.adapt=100, n.burnin=0,
                                    n.iter=2000, parallel=TRUE)
@ 
\end{frame}




\begin{frame}[fragile]
  \frametitle{Posterior summaries}
<<summary-mcmc-SCR0-faster,size='tiny'>>=
summary(jags.post.SCR0.faster)
@ 
\end{frame}



\begin{frame}[fragile]
  \frametitle{Traceplots and density plots}
<<plot-mcmc-SCR0-faster,size='footnotesize',out.width="0.7\\textwidth",fig.align='center'>>=
plot(jags.post.SCR0.faster[,jp.SCR0])
@ 
\end{frame}




\begin{frame}
  \frametitle{SCR study design}
  SCR uses model-based, rather than design-based,
  inference (see Ch. 10). \\ 
  \pause
  \vfill
  Random placement of traps is not required, but it's a good idea
  randomly sample locations along the environmental gradients you're
  interested in. \\
  \pause \vfill
  The other two key design considerations are:
  \begin{enumerate}
    \item<3-> Capture as many individuals as you can (i.e., maximize $n$)
    \item<4-> Obtain as many {\it spatial} recaptures as possible
  \end{enumerate}
  \vfill
  \uncover<5->{
    There is a tradeoff between these two objectives. Simulation is
    often the best option for finding the right balance.
  }
\end{frame}

%\section{Summary}


\begin{frame}
  \frametitle{SCR summary}
  We assume that variation in $p$ arises from distance between animals
  and traps. \\
  \pause \vfill
  We can estimate abundance and model distribution (i.e., spatial
  variation in density) \\
  \pause \vfill
  Next time, we'll see how to do that using secr and JAGS, and we'll
  make a bunch of maps. \\
\end{frame}




\section{Assignment}




\begin{frame}[fragile]
  \frametitle{Assignment}
  Create a self-contained R script or Rmarkdown file to do the
  following: 
  \vfill
  \begin{enumerate}
    \item Fit a ``local behavioral response'' model,
      rather than a ``global behavioral response'' model in secr.
    \item Fit a model in JAGS where $g_0$ varies among
      occasions. Compare estimates of $E(N)$ and $N$ to the estimates
      from secr for the same model (which we fit earlier).
  \end{enumerate}
  \vfill
  Upload your {\tt .R} or {\tt .Rmd} file to ELC before Tuesday. 
\end{frame}





\end{document}

