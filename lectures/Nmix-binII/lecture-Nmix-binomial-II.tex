\documentclass[color=usenames,dvipsnames]{beamer}\usepackage[]{graphicx}\usepackage[]{xcolor}
% maxwidth is the original width if it is less than linewidth
% otherwise use linewidth (to make sure the graphics do not exceed the margin)
\makeatletter
\def\maxwidth{ %
  \ifdim\Gin@nat@width>\linewidth
    \linewidth
  \else
    \Gin@nat@width
  \fi
}
\makeatother

\definecolor{fgcolor}{rgb}{0, 0, 0}
\newcommand{\hlnum}[1]{\textcolor[rgb]{0.69,0.494,0}{#1}}%
\newcommand{\hlsng}[1]{\textcolor[rgb]{0.749,0.012,0.012}{#1}}%
\newcommand{\hlcom}[1]{\textcolor[rgb]{0.514,0.506,0.514}{\textit{#1}}}%
\newcommand{\hlopt}[1]{\textcolor[rgb]{0,0,0}{#1}}%
\newcommand{\hldef}[1]{\textcolor[rgb]{0,0,0}{#1}}%
\newcommand{\hlkwa}[1]{\textcolor[rgb]{0,0,0}{\textbf{#1}}}%
\newcommand{\hlkwb}[1]{\textcolor[rgb]{0,0.341,0.682}{#1}}%
\newcommand{\hlkwc}[1]{\textcolor[rgb]{0,0,0}{\textbf{#1}}}%
\newcommand{\hlkwd}[1]{\textcolor[rgb]{0.004,0.004,0.506}{#1}}%
\let\hlipl\hlkwb

\usepackage{framed}
\makeatletter
\newenvironment{kframe}{%
 \def\at@end@of@kframe{}%
 \ifinner\ifhmode%
  \def\at@end@of@kframe{\end{minipage}}%
  \begin{minipage}{\columnwidth}%
 \fi\fi%
 \def\FrameCommand##1{\hskip\@totalleftmargin \hskip-\fboxsep
 \colorbox{shadecolor}{##1}\hskip-\fboxsep
     % There is no \\@totalrightmargin, so:
     \hskip-\linewidth \hskip-\@totalleftmargin \hskip\columnwidth}%
 \MakeFramed {\advance\hsize-\width
   \@totalleftmargin\z@ \linewidth\hsize
   \@setminipage}}%
 {\par\unskip\endMakeFramed%
 \at@end@of@kframe}
\makeatother

\definecolor{shadecolor}{rgb}{.97, .97, .97}
\definecolor{messagecolor}{rgb}{0, 0, 0}
\definecolor{warningcolor}{rgb}{1, 0, 1}
\definecolor{errorcolor}{rgb}{1, 0, 0}
\newenvironment{knitrout}{}{} % an empty environment to be redefined in TeX

\usepackage{alltt}
%\documentclass[color=usenames,dvipsnames,handout]{beamer}

\usepackage[roman]{../lectures}
%\usepackage[sans]{../lectures}

\usepackage{booktabs}

\hypersetup{pdfpagemode=UseNone,pdfstartview={FitV}}


\mode<handout>{
  \usetheme{default}
%  \setbeamercolor{background canvas}{bg=black!5}
% \pgfpagesuselayout{4 on 1}[letterpaper,landscape,border shrink=2.5mm]
%  \pgfpagesuselayout{2 on 1}[letterpaper,border shrink=10mm]
}


% Load function to compile and open PDF


% Compile and open PDF






%% New command for inline code that isn't to be evaluated
\definecolor{inlinecolor}{rgb}{0.878, 0.918, 0.933}
\newcommand{\inr}[1]{\colorbox{inlinecolor}{\texttt{#1}}}


% \newcommand\blfootnote[1]{%
%   \begingroup
%   \renewcommand\thefootnote{}\footnote{#1}%
%   \addtocounter{footnote}{-1}%
%   \endgroup
% }
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\begin{document}




\begin{frame}[plain]
  \LARGE
%  \maketitle
  \centering
  {\LARGE Lecture 6 -- Binomial $N$-mixture models: \\
    model selection % , spatial prediction,
    and goodness-of-fit} \\  
  {\color{default} \rule{\textwidth}{0.1pt}}
  \vfill
  \large
  WILD(FISH) 8390 \\
%   Estimation of Fish and Wildlife Population Parameters \\
  Inference for Models of Fish and Wildlife Population Dynamics \\
  \vfill
  \large
  Richard Chandler \\
  University of Georgia \\
\end{frame}





\section{Model selection}



\begin{frame}[plain]
  \frametitle{Outline}
  \Large
  \only<1>{\tableofcontents}%[hideallsubsections]}
%  \only<2 | handout:0>{\tableofcontents[currentsection,currentsubsection]}
\end{frame}





\begin{frame}
  \frametitle{Model selection}
  In scientific contexts, we want models that describe natural
  processes and allow us to evaluate hypotheses. \\
  \pause
  \vfill
  Models should be predictive, but they shouldn't be crafted with the
  sole goal of prediction in mind. \\
  \pause
  \vfill
  Scientists typically don't care about prediction if the model
  doesn't help us learn about the processes that gave rise to the
  data. \\  
  \pause
  \vfill
  Nonetheless, predictive performance is often the best way
  to compare models and avoid underfitting and overfitting. \\
  \pause
  \vfill
  Make sure the models being compared were motivated by clear
  hypotheses.
\end{frame}




\begin{frame}
  \frametitle{Model selection}
  Prediction accuracy increases with model complexity up to a point,
  until overfitting kicks in. \\
  \pause
  \vfill
  The best way to determine if a model is too simplistic or too
  complex is to compare predictions to new observations. \\
  \pause
  \vfill
  However, we rarely have the resources to
  collect additional data for the sake of evaluating predictive
  performance. \\ 
  % \pause
  % \vfill
  % Trouble is, people rarely collect new observations. \\
  \pause
  \vfill
  A cheaper (albeit less desirable) alternative is to use
  cross-validation: 
  \begin{itemize}
    \item Split data into K partitions
    \item Fit model to the data in K-1 partitions
    \item Predict the holdout partition
  \end{itemize}
  \pause
  \vfill
  Information criteria like AIC and WAIC yield similar predictive
  rankings as cross-validation, but with less computation.    
\end{frame}


\begin{frame}[fragile]
  \frametitle{Overfitting}
  7 regression models with 5 covariates. \\
  
  Only \inr{x2} is in the data generating model.  
\begin{knitrout}\scriptsize
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hldef{n} \hlkwb{<-} \hlnum{50}
\hldef{dat} \hlkwb{<-} \hlkwd{data.frame}\hldef{(}\hlkwc{x1}\hldef{=}\hlkwd{rnorm}\hldef{(n),} \hlkwc{x2}\hldef{=}\hlkwd{rnorm}\hldef{(n),} \hlkwc{x3}\hldef{=}\hlkwd{rnorm}\hldef{(n),}
                  \hlkwc{x4}\hldef{=}\hlkwd{rnorm}\hldef{(n),} \hlkwc{x5}\hldef{=}\hlkwd{rnorm}\hldef{(n))}
\hldef{dat}\hlopt{$}\hldef{y} \hlkwb{<-} \hlkwd{rnorm}\hldef{(n,} \hlkwc{mean} \hldef{=} \hlopt{-}\hlnum{1} \hlopt{+} \hlnum{2}\hlopt{*}\hldef{dat}\hlopt{$}\hldef{x2,} \hlkwc{sd} \hldef{=} \hlnum{2}\hldef{)} \hlcom{# Data generating model}
\hldef{fm1} \hlkwb{<-} \hlkwd{glm}\hldef{(y}\hlopt{~}\hlnum{1}\hldef{, gaussian, dat)}
\hldef{fm2} \hlkwb{<-} \hlkwd{glm}\hldef{(y}\hlopt{~}\hldef{x1, gaussian, dat)}
\hldef{fm3} \hlkwb{<-} \hlkwd{glm}\hldef{(y}\hlopt{~}\hldef{x2, gaussian, dat)}                 \hlcom{# Data generating model}
\hldef{fm4} \hlkwb{<-} \hlkwd{glm}\hldef{(y}\hlopt{~}\hldef{x1}\hlopt{+}\hldef{x2, gaussian, dat)}
\hldef{fm5} \hlkwb{<-} \hlkwd{glm}\hldef{(y}\hlopt{~}\hldef{x1}\hlopt{+}\hldef{x2}\hlopt{+}\hldef{x3, gaussian, dat)}
\hldef{fm6} \hlkwb{<-} \hlkwd{glm}\hldef{(y}\hlopt{~}\hldef{x1}\hlopt{+}\hldef{x2}\hlopt{+}\hldef{x3}\hlopt{+}\hldef{x4, gaussian, dat)}
\hldef{fm7} \hlkwb{<-} \hlkwd{glm}\hldef{(y}\hlopt{~}\hldef{x1}\hlopt{+}\hldef{x2}\hlopt{+}\hldef{x3}\hlopt{+}\hldef{x4}\hlopt{+}\hldef{x5, gaussian, dat)}

\hlkwd{library}\hldef{(boot)}  \hlcom{## For 'cv.glm'}
\hldef{prediction_error} \hlkwb{<-} \hlkwd{c}\hldef{(}\hlkwc{fm1}\hldef{=}\hlkwd{cv.glm}\hldef{(dat, fm1)}\hlopt{$}\hldef{delta[}\hlnum{1}\hldef{],}
  \hlkwc{fm2}\hldef{=}\hlkwd{cv.glm}\hldef{(dat, fm2)}\hlopt{$}\hldef{delta[}\hlnum{1}\hldef{],} \hlkwc{fm3}\hldef{=}\hlkwd{cv.glm}\hldef{(dat, fm3)}\hlopt{$}\hldef{delta[}\hlnum{1}\hldef{],}
  \hlkwc{fm4}\hldef{=}\hlkwd{cv.glm}\hldef{(dat, fm4)}\hlopt{$}\hldef{delta[}\hlnum{1}\hldef{],} \hlkwc{fm5}\hldef{=}\hlkwd{cv.glm}\hldef{(dat, fm5)}\hlopt{$}\hldef{delta[}\hlnum{1}\hldef{],}
  \hlkwc{fm6}\hldef{=}\hlkwd{cv.glm}\hldef{(dat, fm6)}\hlopt{$}\hldef{delta[}\hlnum{1}\hldef{],} \hlkwc{fm7}\hldef{=}\hlkwd{cv.glm}\hldef{(dat, fm7)}\hlopt{$}\hldef{delta[}\hlnum{1}\hldef{])}
\end{alltt}
\end{kframe}
\end{knitrout}
\end{frame}


\begin{frame}[fragile]
  \frametitle{Overfitting}
  \centering
  \includegraphics[width=0.9\textwidth]{figure/overfit-1} \\
\end{frame}

\subsection{Likelihood-based methods}



\begin{frame}
  \frametitle{Outline}
  \Large
  \tableofcontents[currentsection,currentsubsection]
\end{frame}





\begin{frame}
  \frametitle{Model selection with AIC}
  \small
  Most information criteria (IC) take on a form like this:
  \[
     \mathrm{IC} = \mathrm{fit} + \mathrm{penalty}
  \]
  where `fit' describes the \alert{in-sample} predictive accuracy and 
  `penalty' describes model complexity. \\
  \pause
  \vfill
  In the case of Akaike's `An Information Criterion', which
  approximates leave-one-out cross validation, `fit' is described by
  the likelihood and the `penalty' is determined by the number of parameters:
  \[
%     \mathrm{AIC} = -2\times \mathrm{logLikelihood} + 2\times \mathrm{nParameters}
     \mathrm{AIC} = -2 \log(L) + 2P 
   \]
   where $L$ is the likelihood evaluated at the MLE and $P$ is
   the number of parameters. \\
   \pause
   \vfill
   The lower the AIC, the better the \alert{out-of-sample} predictive
   performance.
\end{frame}




% \bgroup
% \let\oldfootnoterule\footnoterule
% \def\footnoterule{\only<1->\oldfootnoterule}
% \begin{frame}
%   \frametitle{Model selection with AIC}
% %  \small
%   For an $N$-mixture model, the `integrated likelihood' is computed by
%   marginalizing (summing over all possible values of) $N_i$:
%   \[
%      L = \prod_{i=1}^M \sum_{N^*_i=\max(y_i)}^{K\approx \infty}
%      \left\{\prod_{j=1}^J p(y_{ij}|N^*_i,p)\right\}p(N^*_i|\lambda)
%   \]
% %  \pause
%   where $p(y_{ij}|N_i,p)$ is the binomial probability
%   density\footnote<1->{\scriptsize For discrete random variables, 
%     ``mass'' is often used instead of ``density''.} function 
%   (pdf), and $p(N_i|\lambda)$ is the Poisson (or similar) pdf for
%   local abundance. 
% \end{frame}
% \egroup



% \bgroup
% \let\oldfootnoterule\footnoterule
% \def\footnoterule{\only<2->\oldfootnoterule}
\begin{frame}[fragile]
  \frametitle{Model selection in `unmarked'}
  \small
  Import the grouse data
  \vspace{-6pt}
\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{library}\hldef{(unmarked)}
\hldef{grouse.data} \hlkwb{<-} \hlkwd{read.csv}\hldef{(}\hlsng{"grouse_data_Nmix.csv"}\hldef{,} \hlkwc{row.names}\hldef{=}\hlnum{1}\hldef{)}
\hldef{grouse.umf} \hlkwb{<-} \hlkwd{unmarkedFramePCount}\hldef{(}
    \hlkwc{y}\hldef{=grouse.data[,}\hlkwd{paste0}\hldef{(}\hlsng{"grouse"}\hldef{,}\hlnum{1}\hlopt{:}\hlnum{3}\hldef{)],}
    \hlkwc{siteCovs}\hldef{=grouse.data[,}\hlkwd{c}\hldef{(}\hlsng{"utmE"}\hldef{,}\hlsng{"utmN"}\hldef{,}\hlsng{"elevation"}\hldef{)],}
    \hlkwc{obsCovs}\hldef{=}\hlkwd{list}\hldef{(}\hlkwc{temp}\hldef{=grouse.data[,}\hlkwd{paste0}\hldef{(}\hlsng{"Temperature."}\hldef{,}\hlnum{1}\hlopt{:}\hlnum{3}\hldef{)]))}
\end{alltt}
\end{kframe}
\end{knitrout}
\pause
\vfill
Standardize the covariates
% \footnote<2->{\inr{scale} will only work if all the covariates are continuous}:
  \vspace{-6pt}
\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlcom{## scale() only works if all the covariates are continuous  }
\hldef{site.covs.s} \hlkwb{<-} \hlkwd{scale}\hldef{(}\hlkwd{siteCovs}\hldef{(grouse.umf))}
\hlkwd{colnames}\hldef{(site.covs.s)} \hlkwb{<-} \hlkwd{paste0}\hldef{(}\hlkwd{colnames}\hldef{(site.covs.s),} \hlsng{".s"}\hldef{)}
\hlkwd{siteCovs}\hldef{(grouse.umf)} \hlkwb{<-} \hlkwd{cbind}\hldef{(}\hlkwd{siteCovs}\hldef{(grouse.umf), site.covs.s)}
\hlkwd{obsCovs}\hldef{(grouse.umf)} \hlkwb{<-} \hlkwd{scale}\hldef{(}\hlkwd{obsCovs}\hldef{(grouse.umf))}
\end{alltt}
\end{kframe}
\end{knitrout}
\end{frame}
%\egroup




\begin{frame}[fragile]
  \frametitle{Model selection in `unmarked'}
  \small
  Fit some models
  \vspace{-6pt}
\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hldef{fm1} \hlkwb{<-} \hlkwd{pcount}\hldef{(}\hlopt{~}\hldef{temp} \hlopt{~} \hldef{elevation.s}\hlopt{+}\hldef{utmE.s}\hlopt{+}\hldef{utmN.s, grouse.umf,} \hlkwc{K}\hldef{=}\hlnum{50}\hldef{)}
\hldef{fm2} \hlkwb{<-} \hlkwd{pcount}\hldef{(}\hlopt{~}\hldef{temp} \hlopt{~} \hldef{elevation.s}\hlopt{+}\hldef{utmN.s, grouse.umf,} \hlkwc{K}\hldef{=}\hlnum{50}\hldef{)}
\hldef{fm3} \hlkwb{<-} \hlkwd{pcount}\hldef{(}\hlopt{~}\hldef{temp} \hlopt{~} \hldef{elevation.s, grouse.umf,} \hlkwc{K}\hldef{=}\hlnum{50}\hldef{)}
\hldef{fm4} \hlkwb{<-} \hlkwd{pcount}\hldef{(}\hlopt{~}\hlnum{1} \hlopt{~} \hldef{elevation.s}\hlopt{+}\hldef{utmN.s, grouse.umf,} \hlkwc{K}\hldef{=}\hlnum{50}\hldef{)}
\hldef{fm5} \hlkwb{<-} \hlkwd{pcount}\hldef{(}\hlopt{~}\hlnum{1} \hlopt{~} \hldef{elevation.s, grouse.umf,} \hlkwc{K}\hldef{=}\hlnum{50}\hldef{)}
\hldef{fm6} \hlkwb{<-} \hlkwd{pcount}\hldef{(}\hlopt{~}\hlnum{1} \hlopt{~} \hlnum{1}\hldef{, grouse.umf,} \hlkwc{K}\hldef{=}\hlnum{50}\hldef{)}
\end{alltt}
\end{kframe}
\end{knitrout}
\pause
\vfill
Put models in a special type of list
  \vspace{-6pt}
\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hldef{grouse.models} \hlkwb{<-} \hlkwd{fitList}\hldef{(}\hlsng{'lam(elev+utmE+utmN)p(temp)'}\hldef{=fm1,}
                         \hlsng{'lam(elev+utmN)p(temp)'}\hldef{=fm2,}
                         \hlsng{'lam(elev)p(ptemp)'}\hldef{=fm3,}
                         \hlsng{'lam(elev+utmN)p(.)'}\hldef{=fm4,}
                         \hlsng{'lam(elev)p(.)'}\hldef{=fm5,}
                         \hlsng{'lam(.)p(.)'}\hldef{=fm6)}
\end{alltt}


{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error in validityMethod(object): Data are not the same among models due to missing covariate values. Consider removing NAs before analysis.}}\end{kframe}
\end{knitrout}
%\pause
Uh oh, missing values differ among models.
\end{frame}



\begin{frame}[fragile]
  \frametitle{Model selection in `unmarked'}
  \small
  Replace count data with \inr{NA} where associated covariates are missing:
  \vspace{-6pt}
\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hldef{na.sites} \hlkwb{<-} \hlkwd{apply}\hldef{(}\hlkwd{is.na}\hldef{(site.covs.s),} \hlnum{1}\hldef{, any)}
\hldef{grouse.counts} \hlkwb{<-} \hlkwd{getY}\hldef{(grouse.umf)}
\hldef{grouse.counts[na.sites,]} \hlkwb{<-} \hlnum{NA}
\hldef{grouse.umf}\hlopt{@}\hlkwc{y} \hlkwb{<-} \hldef{grouse.counts}
\end{alltt}
\end{kframe}
\end{knitrout}
  \pause
  \vfill
  Fit the models again
  \vspace{-6pt}
\begin{knitrout}\scriptsize
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hldef{fm1} \hlkwb{<-} \hlkwd{pcount}\hldef{(}\hlopt{~}\hldef{temp} \hlopt{~} \hldef{elevation.s}\hlopt{+}\hldef{utmE.s}\hlopt{+}\hldef{utmN.s, grouse.umf,} \hlkwc{K}\hldef{=}\hlnum{50}\hldef{)}
\hldef{fm2} \hlkwb{<-} \hlkwd{pcount}\hldef{(}\hlopt{~}\hldef{temp} \hlopt{~} \hldef{elevation.s}\hlopt{+}\hldef{utmN.s, grouse.umf,} \hlkwc{K}\hldef{=}\hlnum{50}\hldef{)}
\hldef{fm3} \hlkwb{<-} \hlkwd{pcount}\hldef{(}\hlopt{~}\hldef{temp} \hlopt{~} \hldef{elevation.s, grouse.umf,} \hlkwc{K}\hldef{=}\hlnum{50}\hldef{)}
\hldef{fm4} \hlkwb{<-} \hlkwd{pcount}\hldef{(}\hlopt{~}\hlnum{1} \hlopt{~} \hldef{elevation.s}\hlopt{+}\hldef{utmN.s, grouse.umf,} \hlkwc{K}\hldef{=}\hlnum{50}\hldef{)}
\hldef{fm5} \hlkwb{<-} \hlkwd{pcount}\hldef{(}\hlopt{~}\hlnum{1} \hlopt{~} \hldef{elevation.s, grouse.umf,} \hlkwc{K}\hldef{=}\hlnum{50}\hldef{)}
\hldef{fm6} \hlkwb{<-} \hlkwd{pcount}\hldef{(}\hlopt{~}\hlnum{1} \hlopt{~} \hlnum{1}\hldef{, grouse.umf,} \hlkwc{K}\hldef{=}\hlnum{50}\hldef{)}
\end{alltt}
\end{kframe}
\end{knitrout}
\pause
\vfill
Put models in a \inr{fitList}
  \vspace{-6pt}
\begin{knitrout}\scriptsize
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hldef{grouse.models} \hlkwb{<-} \hlkwd{fitList}\hldef{(}\hlsng{'lam(elev+utmE+utmN)p(temp)'}\hldef{=fm1,}
                         \hlsng{'lam(elev+utmN)p(temp)'}\hldef{=fm2,}
                         \hlsng{'lam(elev)p(ptemp)'}\hldef{=fm3,}
                         \hlsng{'lam(elev+utmN)p(.)'}\hldef{=fm4,}
                         \hlsng{'lam(elev)p(.)'}\hldef{=fm5,}
                         \hlsng{'lam(.)p(.)'}\hldef{=fm6)}
\end{alltt}
\end{kframe}
\end{knitrout}
\end{frame}




\begin{frame}[fragile]
  \frametitle{Model selection in `unmarked'}
  \small
  Create AIC table
\begin{knitrout}\scriptsize
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{modSel}\hldef{(grouse.models)}
\end{alltt}
\begin{verbatim}
##                            nPars    AIC delta   AICwt cumltvWt
## lam(elev+utmN)p(temp)          5 202.89  0.00 5.1e-01     0.51
## lam(elev+utmE+utmN)p(temp)     6 203.76  0.87 3.3e-01     0.84
## lam(elev)p(ptemp)              4 206.09  3.20 1.0e-01     0.95
## lam(elev+utmN)p(.)             4 208.25  5.36 3.5e-02     0.98
## lam(elev)p(.)                  3 209.72  6.83 1.7e-02     1.00
## lam(.)p(.)                     2 222.52 19.63 2.8e-05     1.00
\end{verbatim}
\end{kframe}
\end{knitrout}
  \pause
  \vfill
  We could use the model with the lowest AIC for inference and
  prediction. \\ 
  \pause
  \vfill
  Or, we could model-average the predictions. \\
  % \pause
  % \vfill
  % For now, let's use the top model to predict grouse abundance across
  % N Georgia.
\end{frame}


% \subsubsection{Spatial prediction}


% \begin{frame}
%   \frametitle{Spatial prediction}
%   When our covariates are available as raster layers, we can paint our
%   predictions across the landscape. \\
%   \pause
%   \vfill
%   This doesn't account for spatial autocorrelation, except through the
%   covariates, but it can be very useful nonetheless for modeling
%   species distributions. \\
%   \pause
%   \vfill
%   We will cover spatial autocorrelation later. 
% \end{frame}



% \begin{frame}[fragile]
%   \frametitle{Spatial prediction}
% <<elev-sp,fig.width=9.7,out.width='80%',fig.align='center',size='scriptsize',results='hide',message=FALSE,warning=FALSE>>=
% library(raster); library(sf)
% load("state_boundaries.gzip")
% elev <- raster("elev_utm16.tif")
% plot(elev, main="Elevation")
% plot(ga.nc.sc.tn.utm, add=TRUE)
% @ 
% \end{frame}




% \begin{frame}[fragile]
%   \frametitle{Spatial prediction}
% %  Extract UTM northing:
% <<utmN-sp,fig.width=9.7,out.width='80%',fig.align='center',size='scriptsize'>>=
% utmN <- elev
% utmN[] <- yFromCell(elev, cell=1:length(elev))
% plot(utmN, main="UTM northing")
% plot(ga.nc.sc.tn.utm, add=TRUE)
% @ 
% \end{frame}



% \begin{frame}[fragile]
%   \frametitle{Spatial prediction}
%   We have to standardize our rasters \alert{using the same mean and SD
%     as used before}.  
% \vspace{-6pt}
% <<means-sds,size='scriptsize'>>=
% attributes(site.covs.s)[3] ## Means
% attributes(site.covs.s)[4] ## SDs
% @
% \pause
% \vfill
% <<std-rast,size='scriptsize'>>=
% elev.s <- (elev-666.1)/186.6        
% utmN.s <- (utmN-3852681.2)/18030.2  
% @
% \pause
% \vfill
% Put them together in a `raster stack'
% \vspace{-6pt}
% <<stack,size='scriptsize'>>=
% elev.utm <- stack(elev.s,utmN.s)
% names(elev.utm) <- c("elevation.s", "utmN.s")
% @ 
% \end{frame}


% \begin{frame}[fragile]
%   \frametitle{Spatial prediction}
% <<lam-pred-map,size='scriptsize',results='hide',fig.width=10.5,out.width='85%',fig.align='center',cache=TRUE>>=
% grouse.pred.map <- predict(fm2, newdata=elev.utm, type="state")
% plot(grouse.pred.map)
% @
% \end{frame}




% \begin{frame}[fragile]
%   \frametitle{Spatial prediction}
% <<Elam-pred-map,size='scriptsize',results='hide',fig.width=9.7,out.width='90%',fig.align='center'>>=
% plot(grouse.pred.map$Predicted, main="Grouse distribution")
% plot(ga.nc.sc.tn.utm, add=TRUE)
% @
% \end{frame}




% \begin{frame}[fragile]
%   \frametitle{Spatial prediction}
% <<Elam-pred-map2,size='scriptsize',results='hide',fig.width=9.7,out.width='50%',fig.align='center',echo=FALSE>>=
% plot(grouse.pred.map$Predicted, main="Grouse distribution")
% plot(ga.nc.sc.tn.utm, add=TRUE)
% @
% \footnotesize
% This map depicts the expected number of grouse that would occur at a
% survey plot centered on each pixel. \\
% \pause
% \vfill
% To estimate grouse abundance in the entire region, we would need to:
% \begin{enumerate}
%   \footnotesize
%   \item Estimate density by including an \alert{offset} in the model
%     like this:
% %    \colorbox{inlinecolor}{\verb=pcount(~1~elevation.s+utmN.s+offset(log(area)))=}
%     \verb_pcount(~1~elevation.s+utmN.s+offset(log(area)))_
%   \item Predict abundance at each pixel, while accounting for pixel area
%   \item Sum pixel-specific abundance
% \end{enumerate}
% \end{frame}





\subsection{Bayesian methods}



\begin{frame}
  \frametitle{Outline}
  \Large
  \tableofcontents[currentsection,currentsubsection]
\end{frame}



\begin{frame}
  \frametitle{WAIC}
  Watanabe's widely applicable information criterion (WAIC) is a
  generalization of AIC suitable for Bayesian models. %\\
  \pause
%  \vfill
  As before, we have 
  \[
%    \mathrm{WAIC} = \sum_{i=1}^M \log(\frac{1}{S} \sum_s p(y_i|\theta_s)) +
%    \sum_{i=1}^M \mathrm{var}(\log(p(y_i|\theta_s)))
%    \mathrm{WAIC} = \sum_{i=1}^M \log\left(E_s( p(y_i|\theta_s))\right) +
%    \sum_{i=1}^M V_s(\log(p(y_i|\theta_s)))
    \mathrm{WAIC} = \mathrm{fit} + \mathrm{penalty}
  \]
  \pause
  \vfill
  The measure of `fit' in this case is the
  log-pointwise-predictive-density:
  \[
     \mathrm{lppd} = \sum_{i=1}^M \log\left(\frac{1}{S} \sum_s p(y_i|\theta_s)\right)
  \]
  \pause
  \vfill
  The penalty is proportional to the posterior variance:
  \[
     \mathrm{penalty} = \sum_{i=1}^M \mathrm{Var}(\log p(y_i|\theta_s)))
%     \mathrm{penalty} = \sum_{i=1}^M \frac{\left(\sum_s
%       \log(p(y_i|\theta_s)) - \sum_s \log(p(y_i|\theta_s))/S)\right)^2}{S-1}
  \]
\end{frame}



\begin{frame}[fragile]
  \frametitle{Data, inits, and parameters}
  Put data in a named list
  \vspace{-6pt}
\begin{knitrout}\scriptsize
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hldef{jags.data} \hlkwb{<-} \hlkwd{list}\hldef{(}
    \hlkwc{y}\hldef{=grouse.counts,}
    \hlkwc{elevation}\hldef{=site.covs.s[,}\hlsng{"elevation.s"}\hldef{],}
    \hlkwc{utmE}\hldef{=site.covs.s[,}\hlsng{"utmE.s"}\hldef{],}
    \hlkwc{utmN}\hldef{=site.covs.s[,}\hlsng{"utmN.s"}\hldef{],}
    \hlkwc{temp}\hldef{=}\hlkwd{as.matrix}\hldef{(grouse.data[,}\hlkwd{paste0}\hldef{(}\hlsng{"Temperature."}\hldef{,}\hlnum{1}\hlopt{:}\hlnum{3}\hldef{)]),}
    \hlkwc{nSites}\hldef{=}\hlkwd{nrow}\hldef{(grouse.counts),}
    \hlkwc{nOccasions}\hldef{=}\hlkwd{ncol}\hldef{(grouse.counts))}
\hldef{jags.data}\hlopt{$}\hldef{temp} \hlkwb{<-} \hldef{(jags.data}\hlopt{$}\hldef{temp}\hlopt{-}\hlkwd{mean}\hldef{(jags.data}\hlopt{$}\hldef{temp,} \hlkwc{na.rm}\hldef{=}\hlnum{TRUE}\hldef{))}\hlopt{/}
    \hlkwd{sd}\hldef{(jags.data}\hlopt{$}\hldef{temp,} \hlkwc{na.rm}\hldef{=}\hlnum{TRUE}\hldef{)} \hlcom{# standardize temperature}
\end{alltt}
\end{kframe}
\end{knitrout}
\pause
\vfill
  Initial values
  \vspace{-6pt}
\begin{knitrout}\scriptsize
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hldef{jags.inits} \hlkwb{<-} \hlkwa{function}\hldef{() \{}
    \hlkwd{list}\hldef{(}\hlkwc{lambda.intercept}\hldef{=}\hlkwd{runif}\hldef{(}\hlnum{1}\hldef{),} \hlkwc{alpha0}\hldef{=}\hlkwd{rnorm}\hldef{(}\hlnum{1}\hldef{),}
         \hlkwc{N}\hldef{=}\hlkwd{rep}\hldef{(}\hlnum{2}\hldef{, jags.data}\hlopt{$}\hldef{nSites))}
\hldef{\}}
\end{alltt}
\end{kframe}
\end{knitrout}
\pause
\vfill
  Parameters to monitor
  \vspace{-6pt}
\begin{knitrout}\scriptsize
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hldef{jags.pars} \hlkwb{<-} \hlkwd{c}\hldef{(}\hlsng{"beta0"}\hldef{,} \hlsng{"beta1"}\hldef{,} \hlsng{"beta2"}\hldef{,} \hlsng{"beta3"}\hldef{,}
               \hlsng{"alpha0"}\hldef{,} \hlsng{"alpha1"}\hldef{,} \hlsng{"totalAbundance"}\hldef{,}
               \hlsng{"ld.y.dot"}\hldef{,} \hlsng{"ld.ydot.N"}\hldef{)}
\end{alltt}
\end{kframe}
\end{knitrout}
\end{frame}





\begin{frame}[fragile]
  \frametitle{The BUGS model}
  \small
  Notice \alert{\tt modswitch}, which we can use to include/exclude
  predictors. 
  \tiny
\begin{knitrout}\tiny
\definecolor{shadecolor}{rgb}{0.961, 0.961, 0.863}\color{fgcolor}\begin{kframe}
\begin{verbatim}
model {

#beta0 ~ dnorm(0, 0.5)  
lambda.intercept ~ dunif(0, 5)
beta0 <- log(lambda.intercept)
beta1 ~ dnorm(0, 0.5)
beta2 ~ dnorm(0, 0.5)
beta3 ~ dnorm(0, 0.5)

alpha0 ~ dnorm(0, 0.5)  
alpha1 ~ dnorm(0, 0.5)

for(i in 1:nSites) {
  elevation[i] ~ dnorm(0, 1) # Missing values drawn from prior
  utmN[i] ~ dnorm(0, 1)      # Ditto
  utmE[i] ~ dnorm(0, 1)      # Ditto
  log(lambda[i]) <- beta0 + beta1*elevation[i]*modswitch[1] +
    beta2*utmE[i]*modswitch[2] + beta3*utmN[i]*modswitch[3] 
  N[i] ~ dpois(lambda[i])    # Latent local abundance
  for(j in 1:nOccasions) {
    temp[i,j] ~ dnorm(0,1)
    logit(p[i,j]) <- alpha0 + alpha1*temp[i,j]*modswitch[4]
    y[i,j] ~ dbin(p[i,j], N[i])   # Data
    ld.y[i,j] <- logdensity.bin(y[i,j], p[i,j], N[i])
  }
  ld.y.dot[i] <- sum(ld.y[i,])
}

totalAbundance <- sum(N[1:nSites])

}
\end{verbatim}
\end{kframe}
\end{knitrout}

\end{frame}





\begin{frame}[fragile]
  \frametitle{MCMC}
  Fit Model 1, corresponding to \inr{fm1}. 
  \vspace{-6pt}
\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{library}\hldef{(jagsUI)}
\hldef{jags.data1} \hlkwb{<-} \hldef{jags.data}
\hldef{jags.data1}\hlopt{$}\hldef{modswitch} \hlkwb{<-} \hlkwd{c}\hldef{(}\hlnum{1}\hldef{,}\hlnum{1}\hldef{,}\hlnum{1}\hldef{,}\hlnum{1}\hldef{)} \hlcom{## Include all covariates}
\hldef{jm1} \hlkwb{<-} \hlkwd{jags.basic}\hldef{(}\hlkwc{data}\hldef{=jags.data1,} \hlkwc{inits}\hldef{=jags.inits,}
                  \hlkwc{parameters.to.save}\hldef{=jags.pars,}
                  \hlkwc{model.file}\hldef{=}\hlsng{"Nmix-model-grouse.jag"}\hldef{,}
                  \hlkwc{n.chains}\hldef{=}\hlnum{3}\hldef{,} \hlkwc{n.adapt}\hldef{=}\hlnum{100}\hldef{,} \hlkwc{n.burnin}\hldef{=}\hlnum{0}\hldef{,}
                  \hlkwc{n.iter}\hldef{=}\hlnum{2000}\hldef{,} \hlkwc{parallel}\hldef{=}\hlnum{TRUE}\hldef{)}
\end{alltt}
\end{kframe}
\end{knitrout}
\pause
\vfill
  Fit Model 2
  \vspace{-6pt}
\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hldef{jags.data2} \hlkwb{<-} \hldef{jags.data; jags.data2}\hlopt{$}\hldef{modswitch} \hlkwb{<-} \hlkwd{c}\hldef{(}\hlnum{1}\hldef{,}\hlnum{0}\hldef{,}\hlnum{1}\hldef{,}\hlnum{1}\hldef{)}
\hldef{jm2} \hlkwb{<-} \hlkwd{jags.basic}\hldef{(}\hlkwc{data}\hldef{=jags.data2,} \hlkwc{inits}\hldef{=jags.inits,}
                  \hlkwc{parameters.to.save}\hldef{=jags.pars,}
                  \hlkwc{model.file}\hldef{=}\hlsng{"Nmix-model-grouse.jag"}\hldef{,}
                  \hlkwc{n.chains}\hldef{=}\hlnum{3}\hldef{,} \hlkwc{n.adapt}\hldef{=}\hlnum{100}\hldef{,} \hlkwc{n.burnin}\hldef{=}\hlnum{0}\hldef{,}
                  \hlkwc{n.iter}\hldef{=}\hlnum{2000}\hldef{,} \hlkwc{parallel}\hldef{=}\hlnum{TRUE}\hldef{)}
\end{alltt}
\end{kframe}
\end{knitrout}
\end{frame}


\begin{frame}[fragile]
  \frametitle{MCMC}
  \small
  Model 3
  \vspace{-6pt}
\begin{knitrout}\tiny
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hldef{jags.data3} \hlkwb{<-} \hldef{jags.data; jags.data3}\hlopt{$}\hldef{modswitch} \hlkwb{<-} \hlkwd{c}\hldef{(}\hlnum{1}\hldef{,}\hlnum{0}\hldef{,}\hlnum{0}\hldef{,}\hlnum{1}\hldef{)}
\hldef{jm3} \hlkwb{<-} \hlkwd{jags.basic}\hldef{(}\hlkwc{data}\hldef{=jags.data3,} \hlkwc{inits}\hldef{=jags.inits,} \hlkwc{parameters.to.save}\hldef{=jags.pars,}
                  \hlkwc{model.file}\hldef{=}\hlsng{"Nmix-model-grouse.jag"}\hldef{,} \hlkwc{n.chains}\hldef{=}\hlnum{3}\hldef{,} \hlkwc{n.adapt}\hldef{=}\hlnum{100}\hldef{,} \hlkwc{n.burnin}\hldef{=}\hlnum{0}\hldef{,}
                  \hlkwc{n.iter}\hldef{=}\hlnum{2000}\hldef{,} \hlkwc{parallel}\hldef{=}\hlnum{TRUE}\hldef{)}
\end{alltt}
\end{kframe}
\end{knitrout}
  Model 4
  \vspace{-6pt}
\begin{knitrout}\tiny
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hldef{jags.data4} \hlkwb{<-} \hldef{jags.data; jags.data4}\hlopt{$}\hldef{modswitch} \hlkwb{<-} \hlkwd{c}\hldef{(}\hlnum{1}\hldef{,}\hlnum{0}\hldef{,}\hlnum{1}\hldef{,}\hlnum{0}\hldef{)}
\hldef{jm4} \hlkwb{<-} \hlkwd{jags.basic}\hldef{(}\hlkwc{data}\hldef{=jags.data4,} \hlkwc{inits}\hldef{=jags.inits,} \hlkwc{parameters.to.save}\hldef{=jags.pars,}
                  \hlkwc{model.file}\hldef{=}\hlsng{"Nmix-model-grouse.jag"}\hldef{,} \hlkwc{n.chains}\hldef{=}\hlnum{3}\hldef{,} \hlkwc{n.adapt}\hldef{=}\hlnum{100}\hldef{,} \hlkwc{n.burnin}\hldef{=}\hlnum{0}\hldef{,}
                  \hlkwc{n.iter}\hldef{=}\hlnum{2000}\hldef{,} \hlkwc{parallel}\hldef{=}\hlnum{TRUE}\hldef{)}
\end{alltt}
\end{kframe}
\end{knitrout}
  Model 5
  \vspace{-6pt}
\begin{knitrout}\tiny
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hldef{jags.data5} \hlkwb{<-} \hldef{jags.data; jags.data5}\hlopt{$}\hldef{modswitch} \hlkwb{<-} \hlkwd{c}\hldef{(}\hlnum{1}\hldef{,}\hlnum{0}\hldef{,}\hlnum{0}\hldef{,}\hlnum{0}\hldef{)}
\hldef{jm5} \hlkwb{<-} \hlkwd{jags.basic}\hldef{(}\hlkwc{data}\hldef{=jags.data5,} \hlkwc{inits}\hldef{=jags.inits,} \hlkwc{parameters.to.save}\hldef{=jags.pars,}
                  \hlkwc{model.file}\hldef{=}\hlsng{"Nmix-model-grouse.jag"}\hldef{,} \hlkwc{n.chains}\hldef{=}\hlnum{3}\hldef{,} \hlkwc{n.adapt}\hldef{=}\hlnum{100}\hldef{,} \hlkwc{n.burnin}\hldef{=}\hlnum{0}\hldef{,}
                  \hlkwc{n.iter}\hldef{=}\hlnum{2000}\hldef{,} \hlkwc{parallel}\hldef{=}\hlnum{TRUE}\hldef{)}
\end{alltt}
\end{kframe}
\end{knitrout}
  Model 6
  \vspace{-6pt}
\begin{knitrout}\tiny
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hldef{jags.data6} \hlkwb{<-} \hldef{jags.data; jags.data6}\hlopt{$}\hldef{modswitch} \hlkwb{<-} \hlkwd{c}\hldef{(}\hlnum{0}\hldef{,}\hlnum{0}\hldef{,}\hlnum{0}\hldef{,}\hlnum{0}\hldef{)}
\hldef{jm6} \hlkwb{<-} \hlkwd{jags.basic}\hldef{(}\hlkwc{data}\hldef{=jags.data6,} \hlkwc{inits}\hldef{=jags.inits,} \hlkwc{parameters.to.save}\hldef{=jags.pars,}
                  \hlkwc{model.file}\hldef{=}\hlsng{"Nmix-model-grouse.jag"}\hldef{,} \hlkwc{n.chains}\hldef{=}\hlnum{3}\hldef{,} \hlkwc{n.adapt}\hldef{=}\hlnum{100}\hldef{,} \hlkwc{n.burnin}\hldef{=}\hlnum{0}\hldef{,}
                  \hlkwc{n.iter}\hldef{=}\hlnum{2000}\hldef{,} \hlkwc{parallel}\hldef{=}\hlnum{TRUE}\hldef{)}
\end{alltt}
\end{kframe}
\end{knitrout}
\end{frame}


\bgroup
\let\oldfootnoterule\footnoterule
\def\footnoterule{\only<2->\oldfootnoterule}
\begin{frame}[fragile]
  \frametitle{WAIC}
  \[
    \mathrm{WAIC} = -2\left(\mathrm{lppd} - \sum_i \mathrm{Var}(\log p(y_i|\theta))\right)
  \]

\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hldef{waic} \hlkwb{<-} \hlkwa{function}\hldef{(}\hlkwc{x}\hldef{) \{}
    \hlcom{## Parameter names}
    \hldef{vars} \hlkwb{<-} \hldef{coda}\hlopt{::}\hlkwd{varnames}\hldef{(x)}
    \hlcom{## Extract log-density of y at each site for each post sample}
    \hldef{ld.samples} \hlkwb{<-} \hlkwd{as.matrix}\hldef{(x[,}\hlkwd{grep}\hldef{(}\hlsng{"ld.y.dot"}\hldef{, vars)])}
    \hlcom{## Compute log-pointwise-predictive-density}
    \hldef{lppd} \hlkwb{<-} \hlkwd{sum}\hldef{(}\hlkwd{log}\hldef{(}\hlkwd{colMeans}\hldef{(}\hlkwd{exp}\hldef{(ld.samples))))}
    \hlcom{## Compute penalty}
    \hldef{penalty} \hlkwb{<-} \hlkwd{sum}\hldef{(}\hlkwd{apply}\hldef{(ld.samples,} \hlnum{2}\hldef{, var))}
    \hlcom{## Return WAIC}
    \hlkwd{return}\hldef{(}\hlopt{-}\hlnum{2}\hlopt{*}\hldef{(lppd}\hlopt{-}\hldef{penalty))}
\hldef{\}}
\end{alltt}
\end{kframe}
\end{knitrout}
\let\thefootnote\relax\footnote<2->{In this case, it might be better to focus WAIC on
$p(y_i|N_i,p)p(N_i|\lambda)$ or $p(y_i|p)$, rather than just
  $p(y_i|N_i,p)$. See Gaya and Ketz (2024).} 
\end{frame}
\egroup


% \begin{frame}[fragile]
%   \frametitle{WAIC}
% <<waic1,size='scriptsize'>>=
% (waic1 <- waic(jm1, focus="yN"))
% @   
% <<waic2,size='scriptsize'>>=
% (waic2 <- waic(jm2, focus="yN"))
% @   
% <<waic6,size='scriptsize'>>=
% (waic6 <- waic(jm6, focus="yN"))
% @   
% \end{frame}



\begin{frame}[fragile]
  \frametitle{WAIC}
  WAIC for the six models
  \begin{columns}
    \begin{column}{0.5\textwidth}
\begin{knitrout}\scriptsize
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hldef{(waic1} \hlkwb{<-} \hlkwd{waic}\hldef{(jm1))}
\end{alltt}
\begin{verbatim}
## [1] 124.5963
\end{verbatim}
\end{kframe}
\end{knitrout}
\begin{knitrout}\scriptsize
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hldef{(waic2} \hlkwb{<-} \hlkwd{waic}\hldef{(jm2))}
\end{alltt}
\begin{verbatim}
## [1] 124.8125
\end{verbatim}
\end{kframe}
\end{knitrout}
\begin{knitrout}\scriptsize
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hldef{(waic3} \hlkwb{<-} \hlkwd{waic}\hldef{(jm3))}
\end{alltt}
\begin{verbatim}
## [1] 118.1807
\end{verbatim}
\end{kframe}
\end{knitrout}
    \end{column}
    \begin{column}{0.5\textwidth}
\begin{knitrout}\scriptsize
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hldef{(waic4} \hlkwb{<-} \hlkwd{waic}\hldef{(jm4))}
\end{alltt}
\begin{verbatim}
## [1] 150.4383
\end{verbatim}
\end{kframe}
\end{knitrout}
\begin{knitrout}\scriptsize
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hldef{(waic5} \hlkwb{<-} \hlkwd{waic}\hldef{(jm5))}
\end{alltt}
\begin{verbatim}
## [1] 151.1954
\end{verbatim}
\end{kframe}
\end{knitrout}
\begin{knitrout}\scriptsize
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hldef{(waic6} \hlkwb{<-} \hlkwd{waic}\hldef{(jm6))}
\end{alltt}
\begin{verbatim}
## [1] 160.7646
\end{verbatim}
\end{kframe}
\end{knitrout}
    \end{column}
  \end{columns}
  \pause
  \vfill
  In practice, you would discard burn-in and ensure convergence before
  computing WAIC.
\end{frame}





\begin{frame}[fragile]
  \frametitle{WAIC}
  Create a WAIC table:
  \vspace{-12pt}
  \begin{center}
\begin{knitrout}\scriptsize
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hldef{waic.table} \hlkwb{<-} \hlkwd{data.frame}\hldef{(}\hlkwc{WAIC}\hldef{=}\hlkwd{c}\hldef{(waic1,waic2,waic3,waic4,waic5,waic5))}
\hlkwd{rownames}\hldef{(waic.table)} \hlkwb{<-} \hlkwd{paste}\hldef{(}\hlsng{"Model"}\hldef{,} \hlnum{1}\hlopt{:}\hlnum{6}\hldef{)}
\hldef{waic.table}\hlopt{$}\hldef{delta} \hlkwb{<-} \hldef{waic.table}\hlopt{$}\hldef{WAIC}\hlopt{-}\hlkwd{min}\hldef{(waic.table}\hlopt{$}\hldef{WAIC)}
\hldef{waic.table} \hlkwb{<-} \hldef{waic.table[}\hlkwd{order}\hldef{(waic.table}\hlopt{$}\hldef{WAIC),]}
\hldef{knitr}\hlopt{::}\hlkwd{kable}\hldef{(waic.table,} \hlkwc{format}\hldef{=}\hlsng{"latex"}\hldef{,} \hlkwc{digits}\hldef{=}\hlnum{2}\hldef{,} \hlkwc{booktabs}\hldef{=}\hlnum{TRUE}\hldef{)}
\end{alltt}
\end{kframe}
\begin{tabular}{lrr}
\toprule
  & WAIC & delta\\
\midrule
Model 3 & 118.18 & 0.00\\
Model 1 & 124.60 & 6.42\\
Model 2 & 124.81 & 6.63\\
Model 4 & 150.44 & 32.26\\
Model 5 & 151.20 & 33.01\\
\addlinespace
Model 6 & 151.20 & 33.01\\
\bottomrule
\end{tabular}

\end{knitrout}
  \end{center}
\end{frame}





\section{Goodness-of-fit}



\begin{frame}[plain]
  \frametitle{Outline}
  \Large
  \tableofcontents[currentsection]
\end{frame}



\begin{frame}
  \frametitle{Goodness-of-fit}
  \small
  Distributional assumptions determine the expected values
  \alert{and the expected variance} of the random variables, including
  the data. \\  
  \pause
  \vfill
  Overdispersion occurs when there is more variance in the data than
  expected by the model. \\
  \pause
  \vfill
  Goodness-of-fit methods assess overdispersion and underdispersion. \\
  \pause
  \vfill
  If the model does not fit the data very well because of
  overdispersion, there are several remedial actions:
  \begin{itemize}
  \item<5-> Scientific approach
    \begin{itemize}
       \item Figure out why there is unexplained variation
       \item Perhaps there were unmeasured covariates or you need a
         better process model
    \end{itemize}
  \item<6-> Statistical approach
    \begin{itemize}
      \item Soak up variation with random effects
      \item Use a different distribution (we'll start here)
    \end{itemize}
  \end{itemize}
\end{frame}






\bgroup
\let\oldfootnoterule\footnoterule
\def\footnoterule{\only<3->\oldfootnoterule}
\begin{frame}
  \frametitle{Changing the distribution for $N$}
  \small
  Standard Poisson-binomial $N$-mixture model (without covariates):
  \begin{gather*}
%    \mathrm{log}(\lambda_i) = \beta_0 + \beta_1 {\color{blue} x_{i1}} +
%    \beta_2 {\color{blue} x_{i2}} + \cdots \\
    N_i \sim \mathrm{Poisson}(\lambda) \\
%    \mathrm{logit}(p_{ij}) = \alpha_0 + \alpha_1 {\color{blue} x_{i1}}
%    + \alpha_2 {\color{Purple} w_{ij}} + \cdots \\
    y_{ij} \sim \mathrm{Binomial}(N_i, p)
  \end{gather*}
  \pause
%  \vfill
  We can replace the Poisson distribution with other distributions
  that allow for greater variance in $N$. \pause Two common examples
  are the negative 
  binomial:
  \begin{equation*}
    N_i \sim \mathrm{NegBin}(\lambda_i, \kappa)
  \end{equation*}
  where $\lambda_i$ is the expected value of $N$ and $\kappa$ is the
  dispersion parameter\footnote<3->{There are several other
    parameterizations of the negative binomial}.
  \pause
%  \vfill
  Another option is the zero-inflated Poisson:
  \begin{columns}
    \begin{column}{0.45\textwidth}
      \begin{gather*}
        N_i \sim \mathrm{Poisson}(\lambda_i z_i) \\
        z_i \sim \mathrm{Bern}(\psi) \\
      \end{gather*}
    \end{column}
    \begin{column}{0.1\textwidth}
%      \centering
%      Or \\
      \rule{0.1pt}{24pt} \\
    \end{column}
    \begin{column}{0.45\textwidth}
      \begin{gather*}
        \hspace{-72pt}
        N_i \sim \mathrm{ZIPoisson}(\lambda_i,\psi) \\
      \end{gather*}
    \end{column}
  \end{columns}
  where $\psi$ is the expected proportion of sites with excess zeros. 
\end{frame}
\egroup



\begin{frame}[fragile]
  \frametitle{Simulating data from ZIP model}
  Zero-inflated Poisson model
  {\centering
    \begin{columns}
      \small
      \begin{column}{0.45\textwidth}
        \begin{gather*}
          N_i \sim \mathrm{Poisson}(\lambda_i z_i) \\
          z_i \sim \mathrm{Bern}(\psi) \\
        \end{gather*}
      \end{column}
      \begin{column}{0.1\textwidth}
        \rule{0.1pt}{24pt} \\
      \end{column}
      \begin{column}{0.45\textwidth}
        \begin{gather*}
          \hspace{-72pt}
          N_i \sim \mathrm{ZIPoisson}(\lambda_i,\psi) \\
        \end{gather*}
      \end{column}
    \end{columns}
}
\vfill
R code
\begin{knitrout}\scriptsize
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hldef{nSites} \hlkwb{<-} \hlnum{20}
\hldef{nVisits} \hlkwb{<-} \hlnum{3}
\hldef{psi} \hlkwb{<-} \hlnum{0.5}   \hlcom{# Proportion of extra-Poisson zeros}
\hldef{z} \hlkwb{<-} \hlkwd{rbinom}\hldef{(}\hlkwc{n}\hldef{=nSites,} \hlkwc{size}\hldef{=}\hlnum{1}\hldef{,} \hlkwc{prob}\hldef{=psi)} \hlcom{# Extra zeros}
\hldef{lam} \hlkwb{<-} \hlnum{5}     \hlcom{# expected count when z=1}
\hldef{N} \hlkwb{<-} \hlkwd{rpois}\hldef{(}\hlkwc{n}\hldef{=nSites,} \hlkwc{lambda}\hldef{=lam}\hlopt{*}\hldef{z)}      \hlcom{# abundance at each site}
\hldef{p} \hlkwb{<-} \hlnum{0.5}     \hlcom{# detection prob}
\hldef{y} \hlkwb{<-} \hlkwd{matrix}\hldef{(}\hlnum{NA}\hldef{, nSites, nVisits)}
\hlkwa{for}\hldef{(i} \hlkwa{in} \hlnum{1}\hlopt{:}\hldef{nSites) \{}
    \hldef{y[i,]} \hlkwb{<-} \hlkwd{rbinom}\hldef{(}\hlkwc{n}\hldef{=nVisits,} \hlkwc{size}\hldef{=N[i],} \hlkwc{prob}\hldef{=p)} \hlcom{# count data}
\hldef{\}}
\end{alltt}
\end{kframe}
\end{knitrout}
\end{frame}


\subsection{Likelihood-based methods}





\begin{frame}[fragile]
  \frametitle{Goodness-of-fit in `unmarked'}
  \small
  One of the simplest and best ways of assessing goodness-of-fit is to
  look at the residuals.
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{plot}\hldef{(fm2)}
\end{alltt}
\end{kframe}

{\centering \includegraphics[width=0.6\linewidth]{figure/resid2-1} 

}


\end{knitrout}
\pause
\vfill
No sign of obvious outliers or other problems.
\end{frame}




\begin{frame}[fragile]
  \frametitle{Goodness-of-fit in `unmarked'}
  The parametric bootstrap can be used to assess model fit:
  \begin{enumerate}
    \item Simulate a dataset from the fitted model
    \item Fit the model to the new dataset
    \item Compute a fit statistic
    \item Repeat steps 1-3 several hundred/thousand times
    \item Compare the distribution of the \alert{expected} fit
      statistic to the fit statistic associated with
      the actual data. 
  \end{enumerate}
  \pause
  \vfill
  The fit statistic associated with the actual data should not be in
  an extreme quantile of the distribution of the expected values.
  \pause
  \vfill
  Assuming a type I error rate of 0.05, the $p$-value should be
  $>0.05$ if the model fits the data well, which is the null hypothesis.
\end{frame}




\begin{frame}[fragile]
  \frametitle{Goodness-of-fit in `unmarked'}
\begin{knitrout}\scriptsize
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hldef{fitstat} \hlkwb{<-} \hlkwa{function}\hldef{(}\hlkwc{fm}\hldef{) \{} \hlcom{## Sum of squared-residuals}
    \hlkwd{return}\hldef{(}\hlkwd{c}\hldef{(}\hlkwc{SSE}\hldef{=}\hlkwd{sum}\hldef{(}\hlkwd{residuals}\hldef{(fm)}\hlopt{^}\hlnum{2}\hldef{,} \hlkwc{na.rm}\hldef{=}\hlnum{TRUE}\hldef{)))}
\hldef{\}}
\hldef{pb} \hlkwb{<-} \hlkwd{parboot}\hldef{(fm2,} \hlkwc{statistic}\hldef{=fitstat,} \hlkwc{nsim}\hldef{=}\hlnum{200}\hldef{,} \hlkwc{ncores}\hldef{=}\hlnum{3}\hldef{);} \hlkwd{plot}\hldef{(pb)}
\end{alltt}
\end{kframe}

{\centering \includegraphics[width=0.7\linewidth]{figure/parboot-1} 

}


\end{knitrout}
\end{frame}



\begin{frame}[fragile]
  \frametitle{Goodness-of-fit in `unmarked'}
\begin{knitrout}\scriptsize
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hldef{pb}
\end{alltt}
\begin{verbatim}
## 
## Call: parboot(object = fm2, statistic = fitstat, nsim = 200, ncores = 3)
## 
## Parametric Bootstrap Statistics:
##       t0 mean(t0 - t_B) StdDev(t0 - t_B) Pr(t_B > t0)
## SSE 23.2            1.9             5.79        0.353
## 
## t_B quantiles:
##       0% 2.5% 25% 50% 75% 97.5% 100%
## [1,] 9.8   12  17  20  26    33   40
## 
## t0 = Original statistic computed from data
## t_B = Vector of bootstrap samples
\end{verbatim}
\end{kframe}
\end{knitrout}
%\pause
\vfill
These results suggest that model \inr{fm2} fits the data well.
\end{frame}




\begin{frame}[fragile]
  \frametitle{Goodness-of-fit in `unmarked'}
  \small
  If the model didn't fit the data well, we could try a different
  distribution for $N_i$ such as the negative binomial:
\begin{knitrout}\tiny
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hldef{(fm.nb} \hlkwb{<-} \hlkwd{pcount}\hldef{(}\hlopt{~}\hldef{temp} \hlopt{~} \hldef{elevation.s}\hlopt{+}\hldef{utmN.s,} \hlkwc{data}\hldef{=grouse.umf,} \hlkwc{K}\hldef{=}\hlnum{50}\hldef{,} \hlkwc{mixture}\hldef{=}\hlsng{"NB"}\hldef{))}
\end{alltt}
\begin{verbatim}
## 
## Call:
## pcount(formula = ~temp ~ elevation.s + utmN.s, data = grouse.umf, 
##     K = 50, mixture = "NB")
## 
## Abundance (log-scale):
##             Estimate    SE     z P(>|z|)
## (Intercept)   -2.735 1.138 -2.40  0.0162
## elevation.s    0.659 0.283  2.33  0.0199
## utmN.s         0.876 0.445  1.97  0.0487
## 
## Detection (logit-scale):
##             Estimate    SE     z P(>|z|)
## (Intercept)   -2.415 1.234 -1.96  0.0504
## temp          -0.738 0.366 -2.01  0.0441
## 
## Dispersion (log-scale):
##  Estimate   SE     z P(>|z|)
##     -1.23 1.01 -1.22   0.222
## 
## AIC: 202.2481 
## Number of sites: 574
## ID of sites removed due to NA: 328 532 565 578 579
\end{verbatim}
\end{kframe}
\end{knitrout}
\end{frame}



\begin{frame}[fragile]
  \frametitle{Goodness-of-fit in `unmarked'}
  \small
  Or the zero-inflated Poisson:
\begin{knitrout}\tiny
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hldef{(fm.zip} \hlkwb{<-} \hlkwd{pcount}\hldef{(}\hlopt{~}\hldef{temp} \hlopt{~} \hldef{elevation.s}\hlopt{+}\hldef{utmN.s,} \hlkwc{data}\hldef{=grouse.umf,} \hlkwc{K}\hldef{=}\hlnum{50}\hldef{,} \hlkwc{mixture}\hldef{=}\hlsng{"ZIP"}\hldef{))}
\end{alltt}
\begin{verbatim}
## 
## Call:
## pcount(formula = ~temp ~ elevation.s + utmN.s, data = grouse.umf, 
##     K = 50, mixture = "ZIP")
## 
## Abundance (log-scale):
##             Estimate    SE     z P(>|z|)
## (Intercept)   -1.549 1.307 -1.19  0.2359
## elevation.s    0.633 0.275  2.30  0.0213
## utmN.s         0.875 0.433  2.02  0.0434
## 
## Detection (logit-scale):
##             Estimate    SE     z P(>|z|)
## (Intercept)   -2.363 1.172 -2.02  0.0438
## temp          -0.735 0.365 -2.01  0.0441
## 
## Zero-inflation (logit-scale):
##  Estimate   SE     z P(>|z|)
##     0.875 0.89 0.983   0.326
## 
## AIC: 202.494 
## Number of sites: 574
## ID of sites removed due to NA: 328 532 565 578 579
\end{verbatim}
\end{kframe}
\end{knitrout}
\end{frame}





% \begin{frame}[fragile]
%   \frametitle{\normalsize Empirical Bayes -- Site-level abundance}
% <<ranef,size='scriptsize',out.width='80%',fig.align='center',fig.width=9>>=
% re <- ranef(fm)
% plot(re, layout=c(4,3), subset=site%in%1:12, xlim=c(-1, 11), lwd=5)
% @   
% \end{frame}





% \begin{frame}[fragile]
%   \frametitle{Total abundance (in surveyed region)}
% <<Ntotal,size='scriptsize',out.width='60%',fig.align='center'>>=
% N.total.post <- predict(re, func=sum, nsim=1000)
% hist(N.total.post, freq=FALSE, main="", xlab="N total", ylab="Probability")
% @   
% \end{frame}







\subsection{Bayesian methods}



\begin{frame}[plain]
  \frametitle{Outline}
  \Large
  \tableofcontents[currentsection,currentsubsection]
\end{frame}




\begin{frame}[fragile]
  \frametitle{Bayesian fit assessments}
  In a Bayesian analysis, we can assess model fit using a
  \alert{posterior predictive check} (PPC). \\
  \pause
  \vfill
  The PPC compares the posterior distribution of a fit statistic, to
  the posterior distribution of a fit statistic computed from
  simulated data. \\ 
  \pause
  \vfill
  The two distributions should look similar if the model fits well. \\
\end{frame}




\begin{frame}[fragile]
  \frametitle{BUGS model with fit stats}
\begin{knitrout}\tiny
\definecolor{shadecolor}{rgb}{0.961, 0.961, 0.863}\color{fgcolor}\begin{kframe}
\begin{verbatim}
model {

lambda.intercept ~ dunif(0, 5)
beta0 <- log(lambda.intercept)
beta1 ~ dnorm(0, 0.5)
beta3 ~ dnorm(0, 0.5)

alpha0 ~ dnorm(0, 0.5)  
alpha1 ~ dnorm(0, 0.5)

for(i in 1:nSites) {
  elevation[i] ~ dnorm(0, 1)
  utmN[i] ~ dnorm(0, 1)
  utmE[i] ~ dnorm(0, 1)
  log(lambda[i]) <- beta0 + beta1*elevation[i] + beta3*utmN[i]
  N[i] ~ dpois(lambda[i])         # Latent local abundance
  N.new[i] ~ dpois(lambda[i])     # Predicted local abundance
  for(j in 1:nOccasions) {
    temp[i,j] ~ dnorm(0,1)
    logit(p[i,j]) <- alpha0 + alpha1*temp[i,j]
    y[i,j] ~ dbin(p[i,j], N[i])              # Data
    resid[i,j] <- y[i,j]-N[i]*p[i,j]         # Residual
    y.new[i,j] ~ dbin(p[i,j], N.new[i])          # Predicted data
    resid.new[i,j] <- y.new[i,j]-N.new[i]*p[i,j] # Predicted residual
  }
}
SSE <- sum(resid^2)             # Fit stat
SSE.new <- sum(resid.new^2)     # Predicted fit stat

totalAbundance <- sum(N[1:nSites])

}
\end{verbatim}
\end{kframe}
\end{knitrout}
\end{frame}





\begin{frame}[fragile]
  \frametitle{MCMC}
  Fit Model 2, corresponding to \inr{fm2}. 
  \vspace{-6pt}
\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hldef{jm} \hlkwb{<-} \hlkwd{jags.basic}\hldef{(}\hlkwc{data}\hldef{=jags.data,} \hlkwc{inits}\hldef{=jags.inits,}
                 \hlkwc{parameters.to.save}\hldef{=}\hlkwd{c}\hldef{(jags.pars,} \hlsng{"SSE"}\hldef{,} \hlsng{"SSE.new"}\hldef{),}
                 \hlkwc{model.file}\hldef{=}\hlsng{"Nmix-model-grouse2.jag"}\hldef{,}
                 \hlkwc{n.chains}\hldef{=}\hlnum{3}\hldef{,} \hlkwc{n.adapt}\hldef{=}\hlnum{100}\hldef{,} \hlkwc{n.burnin}\hldef{=}\hlnum{0}\hldef{,}
                 \hlkwc{n.iter}\hldef{=}\hlnum{2000}\hldef{,} \hlkwc{parallel}\hldef{=}\hlnum{TRUE}\hldef{)}
\end{alltt}
\end{kframe}
\end{knitrout}
\end{frame}




\begin{frame}[fragile]
  \frametitle{Bayesian goodness-of-fit}
%  Fit Model 1, corresponding to \inr{fm1}. 
%  \vspace{-6pt}
\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{plot}\hldef{(}\hlkwd{as.matrix}\hldef{(jm[,}\hlkwd{c}\hldef{(}\hlsng{"SSE"}\hldef{,} \hlsng{"SSE.new"}\hldef{)]))}
\hlkwd{abline}\hldef{(}\hlkwc{a}\hldef{=}\hlnum{0}\hldef{,} \hlkwc{b}\hldef{=}\hlnum{1}\hldef{,} \hlkwc{col}\hldef{=}\hlsng{"red"}\hldef{)}
\end{alltt}
\end{kframe}

{\centering \includegraphics[width=0.55\linewidth]{figure/bugs-mcmc-gof-plot-1} 

}


\end{knitrout}
  \vfill
  \small
  The distributions of {\tt SSE} and {\tt SSE.new} are similar,
  indicating that the model fits the data well.
\end{frame}






\section{Assignment}




\begin{frame}[fragile]
  \frametitle{Assignment}
  % \small
  \footnotesize
  Create a self-contained R script or Rmarkdown file
  to do the following:
  \vfill
  \begin{enumerate}
%    \small
    \footnotesize
    \item Simulate a dataset from the following $N$-mixture model:
      \begin{itemize}
        \footnotesize
        \item $N_i \sim \mathrm{ZIPoisson}(\lambda=5, \psi=0.5)$
        \item $y_{ij} \sim \mathrm{Binomial}(N_i, p=0.3)$
        \item nSites=200, nOccasions=4
      \end{itemize}
    \item Fit a \alert{mis-specified model} using `unmarked' and `JAGS' with
      $N_i \sim \mathrm{Pois}(\lambda)$ instead of
      $N_i \sim \mathrm{ZIPois}(\lambda, \psi)$.
    \item Assess goodness-of-fit using the parametric bootstrap and
      the Bayesian posterior predictive check.
    \item Fit the \alert{correct model} using `unmarked' and `JAGS'
      and compare the fit to the mis-specified models.
    \item Were the fit assessments methods able to identify the
      mis-specified model?
  \end{enumerate}
  \vfill
  Upload your {\tt .R} or {\tt .Rmd} file to ELC by 5:00pm on Tuesday. 
\end{frame}





\end{document}

