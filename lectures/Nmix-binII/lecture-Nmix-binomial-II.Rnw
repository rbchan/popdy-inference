\documentclass[color=usenames,dvipsnames]{beamer}
%\documentclass[color=usenames,dvipsnames,handout]{beamer}

\usepackage[roman]{../lectures}
%\usepackage[sans]{../lectures}

\usepackage{booktabs}

\hypersetup{pdfpagemode=UseNone,pdfstartview={FitV}}


\mode<handout>{
  \usetheme{default}
%  \setbeamercolor{background canvas}{bg=black!5}
% \pgfpagesuselayout{4 on 1}[letterpaper,landscape,border shrink=2.5mm]
%  \pgfpagesuselayout{2 on 1}[letterpaper,border shrink=10mm]
}


% Load function to compile and open PDF
<<build-fun,include=FALSE,purl=FALSE>>=
source("../rnw2pdf.R")
@

% Compile and open PDF
<<buildit,include=FALSE,eval=FALSE>>=
rnw2pdf("lecture-Nmix-binomial-II")
rnw2pdf("lecture-Nmix-binomial-II", tangle=TRUE)
@ 


<<knitr-theme,include=FALSE,purl=FALSE>>=
##knit_theme$set("navajo-night")
knit_theme$set("edit-kwrite")
@


%% New command for inline code that isn't to be evaluated
\definecolor{inlinecolor}{rgb}{0.878, 0.918, 0.933}
\newcommand{\inr}[1]{\colorbox{inlinecolor}{\texttt{#1}}}


% \newcommand\blfootnote[1]{%
%   \begingroup
%   \renewcommand\thefootnote{}\footnote{#1}%
%   \addtocounter{footnote}{-1}%
%   \endgroup
% }


\begin{document}




\begin{frame}[plain]
  \LARGE
%  \maketitle
  \centering
  {\LARGE Lecture 6 -- Binomial $N$-mixture models: \\
    model selection % , spatial prediction,
    and goodness-of-fit} \\  
  {\color{default} \rule{\textwidth}{0.1pt}}
  \vfill
  \large
  WILD(FISH) 8390 \\
%   Estimation of Fish and Wildlife Population Parameters \\
  Inference for Models of Fish and Wildlife Population Dynamics \\
  \vfill
  \large
  Richard Chandler \\
  University of Georgia \\
\end{frame}





\section{Model selection}



\begin{frame}[plain]
  \frametitle{Outline}
  \Large
  \only<1>{\tableofcontents}%[hideallsubsections]}
%  \only<2 | handout:0>{\tableofcontents[currentsection,currentsubsection]}
\end{frame}





\begin{frame}
  \frametitle{Model selection}
  In scientific contexts, we want models that describe natural
  processes and allow us to evaluate hypotheses. \\
  \pause
  \vfill
  Models should be predictive, but they shouldn't be crafted with the
  sole goal of prediction in mind. \\
  \pause
  \vfill
  Scientists typically don't care about prediction if the model
  doesn't help us learn about the processes that gave rise to the
  data. \\  
  \pause
  \vfill
  Nonetheless, predictive performance is often the best way
  to compare models and avoid underfitting and overfitting. \\
  \pause
  \vfill
  Make sure the models being compared were motivated by clear
  hypotheses.
\end{frame}




\begin{frame}
  \frametitle{Model selection}
  Prediction accuracy increases with model complexity up to a point,
  until overfitting kicks in. \\
  \pause
  \vfill
  The best way to determine if a model is too simplistic or too
  complex is to compare predictions to new observations. \\
  \pause
  \vfill
  However, we rarely have the resources to
  collect additional data for the sake of evaluating predictive
  performance. \\ 
  % \pause
  % \vfill
  % Trouble is, people rarely collect new observations. \\
  \pause
  \vfill
  A cheaper (albeit less desirable) alternative is to use
  cross-validation: 
  \begin{itemize}
    \item Split data into K partitions
    \item Fit model to the data in K-1 partitions
    \item Predict the holdout partition
  \end{itemize}
  \pause
  \vfill
  Information criteria like AIC and WAIC yield similar predictive
  rankings as cross-validation, but with less computation.    
\end{frame}


\begin{frame}[fragile]
  \frametitle{Overfit}
<<overfit,size='scriptsize>>=
n <- 50
set.seed(43340)
dat <- data.frame(x1=rnorm(n), x2=rnorm(n), x3=rnorm(n), x4=rnorm(n), x5=rnorm(n))
dat$y <- rnorm(n, mean = -1 + 2*dat$x2, sd = 2)
fm1 <- glm(y~1, gaussian, dat)
fm2 <- glm(y~x1, gaussian, dat)
fm3 <- glm(y~x2, gaussian, dat)  # Correct model
fm4 <- glm(y~x1+x2, gaussian, dat)
fm5 <- glm(y~x1+x2+x3, gaussian, dat)
fm6 <- glm(y~x1+x2+x3+x4, gaussian, dat)
fm7 <- glm(y~x1+x2+x3+x4+x5, gaussian, dat)
library(boot)
prediction_error <- c(
  fm1=cv.glm(dat, fm1)$delta[1],
  fm2=cv.glm(dat, fm2)$delta[1], # Correct model
  fm3=cv.glm(dat, fm3)$delta[1],
  fm4=cv.glm(dat, fm4)$delta[1],
  fm5=cv.glm(dat, fm5)$delta[1],
  fm6=cv.glm(dat, fm6)$delta[1],
  fm7=cv.glm(dat, fm7)$delta[1])

xbp <- barplot(prediction_error, xlab="Model", ylab="Predication error", cex.lab=1.3)
text(xbp[1]+1, as.character(fm1$call)[2], srt=90, pos=2, cex=1.5)
@   
\end{frame}


\subsection{Likelihood-based methods}



\begin{frame}
  \frametitle{Outline}
  \Large
  \tableofcontents[currentsection,currentsubsection]
\end{frame}





\begin{frame}
  \frametitle{Model selection with AIC}
  \small
  Most information criteria (IC) take on a form like this:
  \[
     \mathrm{IC} = \mathrm{fit} + \mathrm{penalty}
  \]
  where `fit' describes the \alert{in-sample} predictive accuracy and 
  `penalty' describes model complexity. \\
  \pause
  \vfill
  In the case of Akaike's `An Information Criterion', which
  approximates leave-one-out cross validation, `fit' is described by
  the likelihood and the `penalty' is determined by the number of parameters:
  \[
%     \mathrm{AIC} = -2\times \mathrm{logLikelihood} + 2\times \mathrm{nParameters}
     \mathrm{AIC} = -2 \log(L) + 2P 
   \]
   where $L$ is the likelihood evaluated at the MLE and $P$ is
   the number of parameters. \\
   \pause
   \vfill
   The lower the AIC, the better the \alert{out-of-sample} predictive
   performance.
\end{frame}




% \bgroup
% \let\oldfootnoterule\footnoterule
% \def\footnoterule{\only<1->\oldfootnoterule}
% \begin{frame}
%   \frametitle{Model selection with AIC}
% %  \small
%   For an $N$-mixture model, the `integrated likelihood' is computed by
%   marginalizing (summing over all possible values of) $N_i$:
%   \[
%      L = \prod_{i=1}^M \sum_{N^*_i=\max(y_i)}^{K\approx \infty}
%      \left\{\prod_{j=1}^J p(y_{ij}|N^*_i,p)\right\}p(N^*_i|\lambda)
%   \]
% %  \pause
%   where $p(y_{ij}|N_i,p)$ is the binomial probability
%   density\footnote<1->{\scriptsize For discrete random variables, 
%     ``mass'' is often used instead of ``density''.} function 
%   (pdf), and $p(N_i|\lambda)$ is the Poisson (or similar) pdf for
%   local abundance. 
% \end{frame}
% \egroup



% \bgroup
% \let\oldfootnoterule\footnoterule
% \def\footnoterule{\only<2->\oldfootnoterule}
\begin{frame}[fragile]
  \frametitle{Model selection in `unmarked'}
  \small
  Import the grouse data
  \vspace{-6pt}
<<grouse-in,size='footnotesize',cache=FALSE,results='hide',message=FALSE>>=
library(unmarked)
grouse.data <- read.csv("grouse_data_Nmix.csv", row.names=1)
grouse.umf <- unmarkedFramePCount(
    y=grouse.data[,paste0("grouse",1:3)],
    siteCovs=grouse.data[,c("utmE","utmN","elevation")],
    obsCovs=list(temp=grouse.data[,paste0("Temperature.",1:3)]))
@
\pause
\vfill
Standardize the covariates
% \footnote<2->{\inr{scale} will only work if all the covariates are continuous}:
  \vspace{-6pt}
<<grouse-stand,size='footnotesize',cache=FALSE>>=
## scale() only works if all the covariates are continuous  
site.covs.s <- scale(siteCovs(grouse.umf))
colnames(site.covs.s) <- paste0(colnames(site.covs.s), ".s")
siteCovs(grouse.umf) <- cbind(siteCovs(grouse.umf), site.covs.s)
obsCovs(grouse.umf) <- scale(obsCovs(grouse.umf))
@ 
\end{frame}
%\egroup




\begin{frame}[fragile]
  \frametitle{Model selection in `unmarked'}
  \small
  Fit some models
  \vspace{-6pt}
<<grouse-mods,size='footnotesize',warning=FALSE,cache=TRUE>>=
fm1 <- pcount(~temp ~ elevation.s+utmE.s+utmN.s, grouse.umf, K=50)
fm2 <- pcount(~temp ~ elevation.s+utmN.s, grouse.umf, K=50)
fm3 <- pcount(~temp ~ elevation.s, grouse.umf, K=50)
fm4 <- pcount(~1 ~ elevation.s+utmN.s, grouse.umf, K=50)
fm5 <- pcount(~1 ~ elevation.s, grouse.umf, K=50)
fm6 <- pcount(~1 ~ 1, grouse.umf, K=50)
@
\pause
\vfill
Put models in a special type of list
  \vspace{-6pt}
<<grouse-fitlist,size='footnotesize',warning=FALSE>>=
grouse.models <- fitList('lam(elev+utmE+utmN)p(temp)'=fm1,
                         'lam(elev+utmN)p(temp)'=fm2,
                         'lam(elev)p(ptemp)'=fm3,
                         'lam(elev+utmN)p(.)'=fm4,
                         'lam(elev)p(.)'=fm5,
                         'lam(.)p(.)'=fm6)

@
%\pause
Uh oh, missing values differ among models.
\end{frame}



\begin{frame}[fragile]
  \frametitle{Model selection in `unmarked'}
  \small
  Replace count data with \inr{NA} where associated covariates are missing:
  \vspace{-6pt}
<<addNA,size='footnotesize'>>=
na.sites <- apply(is.na(site.covs.s), 1, any)
grouse.counts <- getY(grouse.umf)
grouse.counts[na.sites,] <- NA
grouse.umf@y <- grouse.counts
@
  \pause
  \vfill
  Fit the models again
  \vspace{-6pt}
<<grouse-mods2,size='scriptsize',warning=FALSE,cache=TRUE>>=
fm1 <- pcount(~temp ~ elevation.s+utmE.s+utmN.s, grouse.umf, K=50)
fm2 <- pcount(~temp ~ elevation.s+utmN.s, grouse.umf, K=50)
fm3 <- pcount(~temp ~ elevation.s, grouse.umf, K=50)
fm4 <- pcount(~1 ~ elevation.s+utmN.s, grouse.umf, K=50)
fm5 <- pcount(~1 ~ elevation.s, grouse.umf, K=50)
fm6 <- pcount(~1 ~ 1, grouse.umf, K=50)
@
\pause
\vfill
Put models in a \inr{fitList}
  \vspace{-6pt}
<<grouse-fitlist2,size='scriptsize',warning=FALSE>>=
grouse.models <- fitList('lam(elev+utmE+utmN)p(temp)'=fm1,
                         'lam(elev+utmN)p(temp)'=fm2,
                         'lam(elev)p(ptemp)'=fm3,
                         'lam(elev+utmN)p(.)'=fm4,
                         'lam(elev)p(.)'=fm5,
                         'lam(.)p(.)'=fm6)

@
\end{frame}




\begin{frame}[fragile]
  \frametitle{Model selection in `unmarked'}
  \small
  Create AIC table
<<aic-table,size='scriptsize'>>=
modSel(grouse.models)
@
  \pause
  \vfill
  We could use the model with the lowest AIC for inference and
  prediction. \\ 
  \pause
  \vfill
  Or, we could model-average the predictions, which we'll cover later
  in the course. \\
  % \pause
  % \vfill
  % For now, let's use the top model to predict grouse abundance across
  % N Georgia.
\end{frame}


% \subsubsection{Spatial prediction}


% \begin{frame}
%   \frametitle{Spatial prediction}
%   When our covariates are available as raster layers, we can paint our
%   predictions across the landscape. \\
%   \pause
%   \vfill
%   This doesn't account for spatial autocorrelation, except through the
%   covariates, but it can be very useful nonetheless for modeling
%   species distributions. \\
%   \pause
%   \vfill
%   We will cover spatial autocorrelation later. 
% \end{frame}



% \begin{frame}[fragile]
%   \frametitle{Spatial prediction}
% <<elev-sp,fig.width=9.7,out.width='80%',fig.align='center',size='scriptsize',results='hide',message=FALSE,warning=FALSE>>=
% library(raster); library(sf)
% load("state_boundaries.gzip")
% elev <- raster("elev_utm16.tif")
% plot(elev, main="Elevation")
% plot(ga.nc.sc.tn.utm, add=TRUE)
% @ 
% \end{frame}




% \begin{frame}[fragile]
%   \frametitle{Spatial prediction}
% %  Extract UTM northing:
% <<utmN-sp,fig.width=9.7,out.width='80%',fig.align='center',size='scriptsize'>>=
% utmN <- elev
% utmN[] <- yFromCell(elev, cell=1:length(elev))
% plot(utmN, main="UTM northing")
% plot(ga.nc.sc.tn.utm, add=TRUE)
% @ 
% \end{frame}



% \begin{frame}[fragile]
%   \frametitle{Spatial prediction}
%   We have to standardize our rasters \alert{using the same mean and SD
%     as used before}.  
% \vspace{-6pt}
% <<means-sds,size='scriptsize'>>=
% attributes(site.covs.s)[3] ## Means
% attributes(site.covs.s)[4] ## SDs
% @
% \pause
% \vfill
% <<std-rast,size='scriptsize'>>=
% elev.s <- (elev-666.1)/186.6        
% utmN.s <- (utmN-3852681.2)/18030.2  
% @
% \pause
% \vfill
% Put them together in a `raster stack'
% \vspace{-6pt}
% <<stack,size='scriptsize'>>=
% elev.utm <- stack(elev.s,utmN.s)
% names(elev.utm) <- c("elevation.s", "utmN.s")
% @ 
% \end{frame}


% \begin{frame}[fragile]
%   \frametitle{Spatial prediction}
% <<lam-pred-map,size='scriptsize',results='hide',fig.width=10.5,out.width='85%',fig.align='center',cache=TRUE>>=
% grouse.pred.map <- predict(fm2, newdata=elev.utm, type="state")
% plot(grouse.pred.map)
% @
% \end{frame}




% \begin{frame}[fragile]
%   \frametitle{Spatial prediction}
% <<Elam-pred-map,size='scriptsize',results='hide',fig.width=9.7,out.width='90%',fig.align='center'>>=
% plot(grouse.pred.map$Predicted, main="Grouse distribution")
% plot(ga.nc.sc.tn.utm, add=TRUE)
% @
% \end{frame}




% \begin{frame}[fragile]
%   \frametitle{Spatial prediction}
% <<Elam-pred-map2,size='scriptsize',results='hide',fig.width=9.7,out.width='50%',fig.align='center',echo=FALSE>>=
% plot(grouse.pred.map$Predicted, main="Grouse distribution")
% plot(ga.nc.sc.tn.utm, add=TRUE)
% @
% \footnotesize
% This map depicts the expected number of grouse that would occur at a
% survey plot centered on each pixel. \\
% \pause
% \vfill
% To estimate grouse abundance in the entire region, we would need to:
% \begin{enumerate}
%   \footnotesize
%   \item Estimate density by including an \alert{offset} in the model
%     like this:
% %    \colorbox{inlinecolor}{\verb=pcount(~1~elevation.s+utmN.s+offset(log(area)))=}
%     \verb_pcount(~1~elevation.s+utmN.s+offset(log(area)))_
%   \item Predict abundance at each pixel, while accounting for pixel area
%   \item Sum pixel-specific abundance
% \end{enumerate}
% \end{frame}





\subsection{Bayesian methods}



\begin{frame}
  \frametitle{Outline}
  \Large
  \tableofcontents[currentsection,currentsubsection]
\end{frame}



\begin{frame}
  \frametitle{WAIC}
  Watanabe's widely applicable information criterion (WAIC) is a
  generalization of AIC suitable for Bayesian models. %\\
  \pause
%  \vfill
  As before, we have 
  \[
%    \mathrm{WAIC} = \sum_{i=1}^M \log(\frac{1}{S} \sum_s p(y_i|\theta_s)) +
%    \sum_{i=1}^M \mathrm{var}(\log(p(y_i|\theta_s)))
%    \mathrm{WAIC} = \sum_{i=1}^M \log\left(E_s( p(y_i|\theta_s))\right) +
%    \sum_{i=1}^M V_s(\log(p(y_i|\theta_s)))
    \mathrm{WAIC} = \mathrm{fit} + \mathrm{penalty}
  \]
  \pause
  \vfill
  The measure of `fit' in this case is the
  log-pointwise-predictive-density:
  \[
     \mathrm{lppd} = \sum_{i=1}^M \log\left(\frac{1}{S} \sum_s p(y_i|\theta_s)\right)
  \]
  \pause
  \vfill
  The penalty is proportional to the posterior variance:
  \[
     \mathrm{penalty} = \sum_{i=1}^M \mathrm{Var}(\log p(y_i|\theta_s)))
%     \mathrm{penalty} = \sum_{i=1}^M \frac{\left(\sum_s
%       \log(p(y_i|\theta_s)) - \sum_s \log(p(y_i|\theta_s))/S)\right)^2}{S-1}
  \]
\end{frame}



\begin{frame}[fragile]
  \frametitle{Data, inits, and parameters}
  Put data in a named list
  \vspace{-6pt}
<<bugs-data,size='scriptsize'>>=
jags.data <- list(
    y=grouse.counts,
    elevation=site.covs.s[,"elevation.s"],
    utmE=site.covs.s[,"utmE.s"],
    utmN=site.covs.s[,"utmN.s"],
    temp=as.matrix(grouse.data[,paste0("Temperature.",1:3)]),
    nSites=nrow(grouse.counts),
    nOccasions=ncol(grouse.counts))
jags.data$temp <- (jags.data$temp-mean(jags.data$temp, na.rm=TRUE))/
    sd(jags.data$temp, na.rm=TRUE) # standardize temperature
@
\pause
\vfill
  Initial values
  \vspace{-6pt}
<<bugs-inits,size='scriptsize'>>=
jags.inits <- function() {
    list(lambda.intercept=runif(1), alpha0=rnorm(1),
         N=rep(2, jags.data$nSites))
}
@ 
\pause
\vfill
  Parameters to monitor
  \vspace{-6pt}
<<bugs-pars,size='scriptsize'>>=
jags.pars <- c("beta0", "beta1", "beta2", "beta3",
               "alpha0", "alpha1", "totalAbundance",
               "ld.y.dot", "ld.ydot.N")
@ 
\end{frame}





\begin{frame}[fragile]
  \frametitle{The BUGS model}
  \small
  Notice \alert{\tt modswitch}, which we can use to include/exclude
  predictors. 
  \tiny
<<bugs,size='tiny',echo=FALSE,comment='',background='lightblue'>>=
writeLines(readLines("Nmix-model-grouse.jag"))
@
<<jagsUI,include=FALSE>>=
library(jagsUI)
@ 
\end{frame}





\begin{frame}[fragile]
  \frametitle{MCMC}
  Fit Model 1, corresponding to \inr{fm1}. 
  \vspace{-6pt}
<<bugs-mcmc,size='footnotesize',message=FALSE,cache=TRUE,results='hide'>>=
library(jagsUI)
jags.data1 <- jags.data
jags.data1$modswitch <- c(1,1,1,1) ## Include all covariates
jm1 <- jags.basic(data=jags.data1, inits=jags.inits,
                  parameters.to.save=jags.pars, 
                  model.file="Nmix-model-grouse.jag",
                  n.chains=3, n.adapt=100, n.burnin=0,
                  n.iter=2000, parallel=TRUE)
@
\pause
\vfill
  Fit Model 2
  \vspace{-6pt}
<<bugs-mcmc2,size='footnotesize',message=FALSE,cache=TRUE,results='hide'>>=
jags.data2 <- jags.data; jags.data2$modswitch <- c(1,0,1,1) 
jm2 <- jags.basic(data=jags.data2, inits=jags.inits,
                  parameters.to.save=jags.pars, 
                  model.file="Nmix-model-grouse.jag",
                  n.chains=3, n.adapt=100, n.burnin=0,
                  n.iter=2000, parallel=TRUE)
@ 
\end{frame}


\begin{frame}[fragile]
  \frametitle{MCMC}
  \small
  Model 3
  \vspace{-6pt}
<<bugs-mcmc3,size='tiny',message=FALSE,cache=TRUE,results='hide'>>=
jags.data3 <- jags.data; jags.data3$modswitch <- c(1,0,0,1)
jm3 <- jags.basic(data=jags.data3, inits=jags.inits, parameters.to.save=jags.pars,
                  model.file="Nmix-model-grouse.jag", n.chains=3, n.adapt=100, n.burnin=0,
                  n.iter=2000, parallel=TRUE)
@ 
  Model 4
  \vspace{-6pt}
<<bugs-mcmc4,size='tiny',message=FALSE,cache=TRUE,results='hide'>>=
jags.data4 <- jags.data; jags.data4$modswitch <- c(1,0,1,0)
jm4 <- jags.basic(data=jags.data4, inits=jags.inits, parameters.to.save=jags.pars,
                  model.file="Nmix-model-grouse.jag", n.chains=3, n.adapt=100, n.burnin=0,
                  n.iter=2000, parallel=TRUE)
@ 
  Model 5
  \vspace{-6pt}
<<bugs-mcmc5,size='tiny',message=FALSE,cache=TRUE,results='hide'>>=
jags.data5 <- jags.data; jags.data5$modswitch <- c(1,0,0,0)
jm5 <- jags.basic(data=jags.data5, inits=jags.inits, parameters.to.save=jags.pars,
                  model.file="Nmix-model-grouse.jag", n.chains=3, n.adapt=100, n.burnin=0,
                  n.iter=2000, parallel=TRUE)
@ 
  Model 6
  \vspace{-6pt}
<<bugs-mcmc6,size='tiny',message=FALSE,cache=TRUE,results='hide'>>=
jags.data6 <- jags.data; jags.data6$modswitch <- c(0,0,0,0)
jm6 <- jags.basic(data=jags.data6, inits=jags.inits, parameters.to.save=jags.pars,
                  model.file="Nmix-model-grouse.jag", n.chains=3, n.adapt=100, n.burnin=0,
                  n.iter=2000, parallel=TRUE)
@ 
\end{frame}


\bgroup
\let\oldfootnoterule\footnoterule
\def\footnoterule{\only<2->\oldfootnoterule}
\begin{frame}[fragile]
  \frametitle{WAIC}
  \[
    \mathrm{WAIC} = -2\left(\mathrm{lppd} - \sum_i \mathrm{Var}(\log p(y_i|\theta))\right)
  \]
<<waic-fn-ld-op,size='small',include=FALSE>>=
waic <- function(x, focus=c("y", "yN")) {
    vars <- coda::varnames(x)
    if(focus[1]=="y") {
        ld.samples <- as.matrix(x[,grep("ld.y.dot", vars)])
    } else if(focus[1]=="yN") {
        ld.samples <- as.matrix(x[,grep("ld.ydot.N", vars)])
    } else stop("focus should be either 'y' or 'yN'")
    lppd <- sum(log(colMeans(exp(ld.samples))))
    penalty <- sum(apply(ld.samples, 2, var))
    return(-2*(lppd-penalty))
}
@   
<<waic-fn,size='footnotesize'>>=
waic <- function(x) {
    ## Parameter names
    vars <- coda::varnames(x)
    ## Extract log-density of y at each site for each post sample
    ld.samples <- as.matrix(x[,grep("ld.y.dot", vars)])
    ## Compute log-pointwise-predictive-density
    lppd <- sum(log(colMeans(exp(ld.samples))))
    ## Compute penalty
    penalty <- sum(apply(ld.samples, 2, var))
    ## Return WAIC
    return(-2*(lppd-penalty))
}
@
\let\thefootnote\relax\footnote<2->{In this case, it might be better to focus WAIC on
$p(y_i|N_i,p)p(N_i|\lambda)$ or $p(y_i|p)$, rather than just $p(y_i|N_i,p)$.} 
\end{frame}
\egroup


% \begin{frame}[fragile]
%   \frametitle{WAIC}
% <<waic1,size='scriptsize'>>=
% (waic1 <- waic(jm1, focus="yN"))
% @   
% <<waic2,size='scriptsize'>>=
% (waic2 <- waic(jm2, focus="yN"))
% @   
% <<waic6,size='scriptsize'>>=
% (waic6 <- waic(jm6, focus="yN"))
% @   
% \end{frame}



\begin{frame}[fragile]
  \frametitle{WAIC}
  WAIC for the six models
  \begin{columns}
    \begin{column}{0.5\textwidth}
<<waic1,size='scriptsize'>>=
(waic1 <- waic(jm1))
@   
<<waic2,size='scriptsize'>>=
(waic2 <- waic(jm2))
@   
<<waic3,size='scriptsize'>>=
(waic3 <- waic(jm3))
@   
    \end{column}
    \begin{column}{0.5\textwidth}
<<waic4,size='scriptsize'>>=
(waic4 <- waic(jm4))
@   
<<waic5,size='scriptsize'>>=
(waic5 <- waic(jm5))
@   
<<waic6,size='scriptsize'>>=
(waic6 <- waic(jm6))
@
    \end{column}
  \end{columns}
  \pause
  \vfill
  In practice, you would discard burn-in and ensure convergence before
  computing WAIC.
\end{frame}





\begin{frame}[fragile]
  \frametitle{WAIC}
  Create a WAIC table:
  \vspace{-12pt}
  \begin{center}
<<waic-table,size='scriptsize'>>=
waic.table <- data.frame(WAIC=c(waic1,waic2,waic3,waic4,waic5,waic5))
rownames(waic.table) <- paste("Model", 1:6)
waic.table$delta <- waic.table$WAIC-min(waic.table$WAIC)
waic.table <- waic.table[order(waic.table$WAIC),]
knitr::kable(waic.table, format="latex", digits=2, booktabs=TRUE)
@
  \end{center}
\end{frame}





\section{Goodness-of-fit}



\begin{frame}[plain]
  \frametitle{Outline}
  \Large
  \tableofcontents[currentsection]
\end{frame}



\begin{frame}
  \frametitle{Goodness-of-fit}
  \small
  Distributional assumptions determine the expected values
  \alert{and the expected variance} of the random variables, including
  the data. \\  
  \pause
  \vfill
  Overdispersion occurs when there is more variance in the data than
  expected by the model. \\
  \pause
  \vfill
  Goodness-of-fit methods assess overdispersion and underdispersion. \\
  \pause
  \vfill
  If the model does not fit the data very well because of
  overdispersion, there are several remedial actions:
  \begin{itemize}
  \item<5-> Scientific approach
    \begin{itemize}
       \item Figure out why there is unexplained variation
       \item Perhaps there were unmeasured covariates or you need a
         better process model
    \end{itemize}
  \item<6-> Statistical approach
    \begin{itemize}
      \item Soak up variation with random effects
      \item Use a different distribution (we'll start here)
    \end{itemize}
  \end{itemize}
\end{frame}






\bgroup
\let\oldfootnoterule\footnoterule
\def\footnoterule{\only<3->\oldfootnoterule}
\begin{frame}
  \frametitle{Changing the distribution for $N$}
  \small
  Standard Poisson-binomial $N$-mixture model (without covariates):
  \begin{gather*}
%    \mathrm{log}(\lambda_i) = \beta_0 + \beta_1 {\color{blue} x_{i1}} +
%    \beta_2 {\color{blue} x_{i2}} + \cdots \\
    N_i \sim \mathrm{Poisson}(\lambda) \\
%    \mathrm{logit}(p_{ij}) = \alpha_0 + \alpha_1 {\color{blue} x_{i1}}
%    + \alpha_2 {\color{Purple} w_{ij}} + \cdots \\
    y_{ij} \sim \mathrm{Binomial}(N_i, p)
  \end{gather*}
  \pause
%  \vfill
  We can replace the Poisson distribution with other distributions
  that allow for greater variance in $N$. \pause Two common examples
  are the negative 
  binomial:
  \begin{equation*}
    N_i \sim \mathrm{NegBin}(\lambda_i, \kappa)
  \end{equation*}
  where $\lambda_i$ is the expected value of $N$ and $\kappa$ is the
  dispersion parameter\footnote<3->{There are several other
    parameterizations of the negative binomial}.
  \pause
%  \vfill
  Another option is the zero-inflated Poisson:
  \begin{columns}
    \begin{column}{0.45\textwidth}
      \begin{gather*}
        N_i \sim \mathrm{Poisson}(\lambda_i z_i) \\
        z_i \sim \mathrm{Bern}(\psi) \\
      \end{gather*}
    \end{column}
    \begin{column}{0.1\textwidth}
%      \centering
%      Or \\
      \rule{0.1pt}{24pt} \\
    \end{column}
    \begin{column}{0.45\textwidth}
      \begin{gather*}
        \hspace{-72pt}
        N_i \sim \mathrm{ZIPoisson}(\lambda_i,\psi) \\
      \end{gather*}
    \end{column}
  \end{columns}
  where $\psi$ is the expected proportion of sites with excess zeros. 
\end{frame}
\egroup



\begin{frame}[fragile]
  \frametitle{Simulating data from ZIP model}
  Zero-inflated Poisson model
  {\centering
    \begin{columns}
      \small
      \begin{column}{0.45\textwidth}
        \begin{gather*}
          N_i \sim \mathrm{Poisson}(\lambda_i z_i) \\
          z_i \sim \mathrm{Bern}(\psi) \\
        \end{gather*}
      \end{column}
      \begin{column}{0.1\textwidth}
        \rule{0.1pt}{24pt} \\
      \end{column}
      \begin{column}{0.45\textwidth}
        \begin{gather*}
          \hspace{-72pt}
          N_i \sim \mathrm{ZIPoisson}(\lambda_i,\psi) \\
        \end{gather*}
      \end{column}
    \end{columns}
}
\vfill
R code
<<zip-sim,size='scriptsize'>>=
nSites <- 20
nVisits <- 3
psi <- 0.5   # Proportion of extra-Poisson zeros
z <- rbinom(n=nSites, size=1, prob=psi) # Extra zeros
lam <- 5     # expected count when z=1
N <- rpois(n=nSites, lambda=lam*z)      # abundance at each site
p <- 0.5     # detection prob
y <- matrix(NA, nSites, nVisits)
for(i in 1:nSites) {
    y[i,] <- rbinom(n=nVisits, size=N[i], prob=p) # count data
}
@   
\end{frame}


\subsection{Likelihood-based methods}





\begin{frame}[fragile]
  \frametitle{Goodness-of-fit in `unmarked'}
  \small
  One of the simplest and best ways of assessing goodness-of-fit is to
  look at the residuals.
<<resid2,fig.width=9,out.width='60%',fig.align='center'>>=
plot(fm2)
@
\pause
\vfill
No sign of obvious outliers or other problems.
\end{frame}




\begin{frame}[fragile]
  \frametitle{Goodness-of-fit in `unmarked'}
  The parametric bootstrap can be used to assess model fit:
  \begin{enumerate}
    \item Simulate a dataset from the fitted model
    \item Fit the model to the new dataset
    \item Compute a fit statistic
    \item Repeat steps 1-3 several hundred/thousand times
    \item Compare the distribution of the \alert{expected} fit
      statistic to the fit statistic associated with
      the actual data. 
  \end{enumerate}
  \pause
  \vfill
  The fit statistic associated with the actual data should not be in
  an extreme quantile of the distribution of the expected values.
  \pause
  \vfill
  Assuming a type I error rate of 0.05, the $p$-value should be
  $>0.05$ if the model fits the data well, which is the null hypothesis.
\end{frame}




\begin{frame}[fragile]
  \frametitle{Goodness-of-fit in `unmarked'}
<<parboot,size='scriptsize',warning=FALSE,cache=TRUE,fig.width=9,out.width='70%',fig.align='center'>>=
fitstat <- function(fm) { ## Sum of squared-residuals
    return(c(SSE=sum(residuals(fm)^2, na.rm=TRUE))) 
}
pb <- parboot(fm2, statistic=fitstat, nsim=200, ncores=3); plot(pb)
@   
\end{frame}



\begin{frame}[fragile]
  \frametitle{Goodness-of-fit in `unmarked'}
<<parboot2,size='scriptsize'>>=
pb
@
%\pause
\vfill
These results suggest that model \inr{fm2} fits the data well.
\end{frame}




\begin{frame}[fragile]
  \frametitle{Goodness-of-fit in `unmarked'}
  \small
  If the model didn't fit the data well, we could try a different
  distribution for $N_i$ such as the negative binomial:
<<negbin,size='tiny',warning=FALSE,cache=TRUE>>=
(fm.nb <- pcount(~temp ~ elevation.s+utmN.s, data=grouse.umf, K=50, mixture="NB"))
@
\end{frame}



\begin{frame}[fragile]
  \frametitle{Goodness-of-fit in `unmarked'}
  \small
  Or the zero-inflated Poisson:
<<zip,size='tiny',warning=FALSE,cache=TRUE>>=
(fm.zip <- pcount(~temp ~ elevation.s+utmN.s, data=grouse.umf, K=50, mixture="ZIP"))
@
\end{frame}





% \begin{frame}[fragile]
%   \frametitle{\normalsize Empirical Bayes -- Site-level abundance}
% <<ranef,size='scriptsize',out.width='80%',fig.align='center',fig.width=9>>=
% re <- ranef(fm)
% plot(re, layout=c(4,3), subset=site%in%1:12, xlim=c(-1, 11), lwd=5)
% @   
% \end{frame}





% \begin{frame}[fragile]
%   \frametitle{Total abundance (in surveyed region)}
% <<Ntotal,size='scriptsize',out.width='60%',fig.align='center'>>=
% N.total.post <- predict(re, func=sum, nsim=1000)
% hist(N.total.post, freq=FALSE, main="", xlab="N total", ylab="Probability")
% @   
% \end{frame}







\subsection{Bayesian methods}



\begin{frame}[plain]
  \frametitle{Outline}
  \Large
  \tableofcontents[currentsection,currentsubsection]
\end{frame}




\begin{frame}[fragile]
  \frametitle{Bayesian fit assessments}
  In a Bayesian analysis, we can assess model fit using a
  \alert{posterior predictive check} (PPC). \\
  \pause
  \vfill
  The PPC compares the posterior distribution of a fit statistic, to
  the posterior distribution of a fit statistic computed from
  simulated data. \\ 
  \pause
  \vfill
  The two distributions should look similar if the model fits well. \\
\end{frame}




\begin{frame}[fragile]
  \frametitle{BUGS model with fit stats}
<<bugs2,size='tiny',echo=FALSE,comment='',background='lightblue'>>=
writeLines(readLines("Nmix-model-grouse2.jag"))
@
\end{frame}





\begin{frame}[fragile]
  \frametitle{MCMC}
  Fit Model 2, corresponding to \inr{fm2}. 
  \vspace{-6pt}
<<bugs-mcmc-gof,size='footnotesize',message=FALSE,cache=TRUE,results='hide'>>=
jm <- jags.basic(data=jags.data, inits=jags.inits,
                 parameters.to.save=c(jags.pars, "SSE", "SSE.new"), 
                 model.file="Nmix-model-grouse2.jag",
                 n.chains=3, n.adapt=100, n.burnin=0,
                 n.iter=2000, parallel=TRUE)
@
\end{frame}




\begin{frame}[fragile]
  \frametitle{Bayesian goodness-of-fit}
%  Fit Model 1, corresponding to \inr{fm1}. 
%  \vspace{-6pt}
<<bugs-mcmc-gof-plot,size='footnotesize',fig.width=8,fig.align='center',out.width='55%'>>=
plot(as.matrix(jm[,c("SSE", "SSE.new")]))
abline(a=0, b=1, col="red")
@
  \vfill
  \small
  The distributions of {\tt SSE} and {\tt SSE.new} are similar,
  indicating that the model fits the data well.
\end{frame}






\section{Assignment}




\begin{frame}[fragile]
  \frametitle{Assignment}
  % \small
  \footnotesize
  Create a self-contained R script or Rmarkdown file
  to do the following:
  \vfill
  \begin{enumerate}
%    \small
    \footnotesize
    \item Simulate a dataset from the following $N$-mixture model:
      \begin{itemize}
        \footnotesize
        \item $N_i \sim \mathrm{ZIPoisson}(\lambda=5, \psi=0.5)$
        \item $y_{ij} \sim \mathrm{Binomial}(N_i, p=0.3)$
        \item nSites=200, nOccasions=4
      \end{itemize}
    \item Fit a \alert{mis-specified model} using `unmarked' and `JAGS' with
      $N_i \sim \mathrm{Pois}(\lambda)$ instead of
      $N_i \sim \mathrm{ZIPois}(\lambda, \psi)$.
    \item Assess goodness-of-fit using the parametric bootstrap and
      the Bayesian posterior predictive check.
    \item Fit the \alert{correct model} using `unmarked' and `JAGS'
      and compare the fit to the mis-specified models.
    \item Were the fit assessments methods able to identify the
      mis-specified model?
  \end{enumerate}
  \vfill
  Upload your {\tt .R} or {\tt .Rmd} file to ELC by 8:00am on Monday. 
\end{frame}





\end{document}

