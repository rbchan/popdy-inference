\documentclass[color=usenames,dvipsnames]{beamer}\usepackage[]{graphicx}\usepackage[]{xcolor}
% maxwidth is the original width if it is less than linewidth
% otherwise use linewidth (to make sure the graphics do not exceed the margin)
\makeatletter
\def\maxwidth{ %
  \ifdim\Gin@nat@width>\linewidth
    \linewidth
  \else
    \Gin@nat@width
  \fi
}
\makeatother

\definecolor{fgcolor}{rgb}{0, 0, 0}
\newcommand{\hlnum}[1]{\textcolor[rgb]{0.69,0.494,0}{#1}}%
\newcommand{\hlstr}[1]{\textcolor[rgb]{0.749,0.012,0.012}{#1}}%
\newcommand{\hlcom}[1]{\textcolor[rgb]{0.514,0.506,0.514}{\textit{#1}}}%
\newcommand{\hlopt}[1]{\textcolor[rgb]{0,0,0}{#1}}%
\newcommand{\hlstd}[1]{\textcolor[rgb]{0,0,0}{#1}}%
\newcommand{\hlkwa}[1]{\textcolor[rgb]{0,0,0}{\textbf{#1}}}%
\newcommand{\hlkwb}[1]{\textcolor[rgb]{0,0.341,0.682}{#1}}%
\newcommand{\hlkwc}[1]{\textcolor[rgb]{0,0,0}{\textbf{#1}}}%
\newcommand{\hlkwd}[1]{\textcolor[rgb]{0.004,0.004,0.506}{#1}}%
\let\hlipl\hlkwb

\usepackage{framed}
\makeatletter
\newenvironment{kframe}{%
 \def\at@end@of@kframe{}%
 \ifinner\ifhmode%
  \def\at@end@of@kframe{\end{minipage}}%
  \begin{minipage}{\columnwidth}%
 \fi\fi%
 \def\FrameCommand##1{\hskip\@totalleftmargin \hskip-\fboxsep
 \colorbox{shadecolor}{##1}\hskip-\fboxsep
     % There is no \\@totalrightmargin, so:
     \hskip-\linewidth \hskip-\@totalleftmargin \hskip\columnwidth}%
 \MakeFramed {\advance\hsize-\width
   \@totalleftmargin\z@ \linewidth\hsize
   \@setminipage}}%
 {\par\unskip\endMakeFramed%
 \at@end@of@kframe}
\makeatother

\definecolor{shadecolor}{rgb}{.97, .97, .97}
\definecolor{messagecolor}{rgb}{0, 0, 0}
\definecolor{warningcolor}{rgb}{1, 0, 1}
\definecolor{errorcolor}{rgb}{1, 0, 0}
\newenvironment{knitrout}{}{} % an empty environment to be redefined in TeX

\usepackage{alltt}
%\documentclass[color=usenames,dvipsnames,handout]{beamer}

\usepackage[roman]{../lectures}
%\usepackage[sans]{../lectures}


\hypersetup{pdfpagemode=UseNone,pdfstartview={FitV},urlcolor=blue}

%\urlstyle{same}


% Load function to compile and open PDF


% Compile and open PDF







% R packages
% Need MARK too. Linux instructions:
% http://www.phidot.org/software/mark/rmark/linux/

% New command for inline code that isn't to be evaluated
\definecolor{inlinecolor}{rgb}{0.878, 0.918, 0.933}
\newcommand{\inr}[1]{\colorbox{inlinecolor}{\texttt{#1}}}
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\begin{document}




\begin{frame}[plain]
  \LARGE
  \centering
  {
    \LARGE %Lecture 10 --
    Non-spatial mark-recapture for \\ estimating
    population size%: \\
    %\LARGE simulation and model fitting \\
  }
  {\color{default} \rule{\textwidth}{0.1pt} }
  \vfill
  \large
  WILD(FISH) 8390 \\
  Estimation of Fish and Wildlife Population Parameters \\
  \vfill
  \large
  Richard Chandler \\
  University of Georgia \\
\end{frame}






\section{Overview}



\begin{frame}[plain]
  \frametitle{Outline}
  \Large
  \only<1>{\tableofcontents}%[hideallsubsections]}
  \only<2 | handout:0>{\tableofcontents[currentsection]}%,hideallsubsections]}
\end{frame}



\begin{frame}
  \frametitle{Mark-recapture overview}
  Until now, we've focused on models for data on aggregated quantities
  like abundance and occupancy. \\ 
  \pause
  \vfill
  Now we will talk about data on uniquely identifiable individuals. \\
  \pause
  \vfill
  This is nice because all individuals are different, and we're often
  interested in these differences\dots \\
  \pause
  \vfill
  \dots even when our primary goal is
  inference on population-level parameters like abundance
  and density. \\
\end{frame}






\begin{frame}
  \frametitle{Closed populations}
  For this lecture, we will assume population closure:
  \begin{itemize}
    \item No births or deaths during the time of sampling \\ (demographic
      closure)
    \item No permanent immigration or emigration \\ (geographic closure)
  \end{itemize}
  \pause
  \vfill
  There are several other assumptions that depend on the specific
  model being employed, such as
  \begin{itemize}
    \item No misidentification
    \item No band/tag loss
    \item etc\dots
  \end{itemize}
  \pause
  \vfill
  Later, we will relax the closure assumption so that we can study
  survival, recruitment, and movement.
\end{frame}



\begin{frame}
  \frametitle{Mark-recapture overview}
  The simplest estimator of abundance is 
  \[
    \hat{N} = \frac{n}{\hat{p}}
  \]
  where $n$ is the number of individuals detected, $p$ is detection
  probability, and $E(n)=Np$. \\
  \pause
  \vfill
  In distance sampling, we modeled detection probability as a
  function of distance, and we replaced $p$ with average detection
  probability. \\ 
  \pause
  \vfill
  For the simplest mark-recapture problems, $p$ is a constant (scalar) and we
  estimate it by trapping on multiple occasions and marking and
  recapturing as we go.  
\end{frame}





\begin{frame}
  \frametitle{Classical approaches}
  Lincoln-Peterson  \\
  \begin{itemize}
    \item $J=2$ occasions
    \item Data are:
      \begin{itemize}
        \item $n_1$ -- number of individuals captured on first occasion
        \item $n_2$ -- number of individuals captured on second occasion
        \item $m_2$ -- number of recaptures
      \end{itemize}
    \item Estimator is $\hat{N} = n_1n_2/m_2$  
  \end{itemize}
  \pause
  \vfill
  Closed population models \\
  \begin{itemize}
    \item Usually better to have $J>2$ occasions
    \item Allows for assessment of behavioral effects, individual heterogeneity, etc\dots
  \end{itemize}
\end{frame}



\begin{frame}
  \frametitle{Mark-recapture data}
  \small
  Mark-recapture data are often called ``capture histories.'' Here's
  an example with $n=6$ animals captured on $J=3$ occasions. \\
  \centering
%  \vfill  
  \begin{tabular}{lccc}
    \hline
    & \multicolumn{3}{c}{Occasion} \\
    \cline{2-4}
    Individual & 1 & 2 & 3 \\
    \hline
    1 & 0 & 0 & 1 \\
    2 & 1 & 1 & 1 \\
    3 & 0 & 1 & 0 \\
    4 & 0 & 1 & 1 \\
    5 & 1 & 0 & 0 \\
    6 & 0 & 0 & 1 \\
    \hline
  \end{tabular}
  \pause
  \vfill
  \flushleft
  How do we estimate $p$ (and $N$) from these data? %\\
  \pause
%  \vfill
  You can get a sense for $p$ (and $N$) by looking at the data.
  \begin{itemize}
    \setlength\itemsep{.1pt}
    \item If $p\approx 1$, most individuals would be captured
      on all 3 occasions, and few would go undetected
    \item If $p\approx 0$, few individuals would be captured 
      more than once, and many would go undetected
  \end{itemize}
%  \pause
%  \vfill
%  Knowing $p$ helps us determine how many individuals we missed  
\end{frame}




% \begin{frame}
%   \frametitle{In-class exercise}
%   Building off the previous example\dots
%   \begin{enumerate}
%     \item Compute $\bar{p}$ for line-transect sampling when
%       $\sigma=50, 100, \mathrm{and}\, 200$, instead of $\sigma=25$.  
%     \item Repeat, but for point-transect sampling. 
%   \end{enumerate}
% \end{frame}



\begin{frame}
  \frametitle{\large Closed population model (if we knew $N$) }
  \small
  State model \\
  \vspace{6pt}
  {\centering
    There isn't one! $N$ is often treated as a constant, although we
    sometimes put a Poisson or binomial prior on it.  \\
  }
  \pause
  \vfill
  Observation model (supposing $N$ was known)
  \begin{equation*}
    y_{ij} \sim \mathrm{Bernoulli}(p) \;\; \mathrm{for}\, i=1,\dots,N 
  \end{equation*}
  \pause
%  \vfill
  \small
  Definitions \\
  {\footnotesize
  $N$ -- Population size \\
  \hangindent=0.8cm $y_{ij}$ -- Capture histories, indicating if
  individual $i$ was captured on occasion $j$ \\  
  $p$ -- Capture probability \\
  %}
  \pause
  \vfill
  The problem with this formulation is that we don't observe the ``all
  zero'' encounter histories (and thus we don't know $N$). \pause As a
  result, the Bernoulli assumption isn't valid, and we need to develop
  a model that describes how many individuals we failed to capture.
  }
\end{frame}





\begin{frame}
  \frametitle{Closed population estimation options}
  Conditional likelihood \\
  \begin{itemize}
    \item Estimate $p$, and then estimate $N$ as a derived
      quantity. %compute $\hat{N}=n/\hat{p}$
    \item Most software is based on the work by Huggins, which allows
      for continuous covariates. 
  \end{itemize}
  \pause
  \vfill
  Joint likelihood \\
  \begin{itemize}
    \item Estimate $N$ and $p$ jointly
    % \item Joint likelihood can be written as
    %   \begin{itemize}
    %   \item $L(N,p;y,n) = p(y|n,p)p(n|N,p)$ or
    %   \item $L(N,p;y,n) = p(y,n|N,p)$
    %   \end{itemize}
  \end{itemize}
  \pause \vfill
  Data augmentation \\
  \begin{itemize}
    \item Tack on many ``all zero'' encounter histories and estimate
      how many of them actually occurred
    \item Usually, but not necessarily, used in Bayesian inference
  \end{itemize}
\end{frame}





% \begin{frame}
%   \frametitle{Joint likelihood, conditional-on-$n$}
%   \small
%   Another way of writing the observation model is to condition on the
%   number of individuals captured, and then use a
%   categorical distribution for the number of times individual $i$
%   was detected. 
%   \begin{gather*}
%     n \sim \mathrm{Binomial}\left(N, 1-\pi_0\right)                               \\
%     \tilde{y}_i \sim \mathrm{Categorical}(\pi_1, \dots, \pi_K) \;\;
%     \mathrm{for}\, i=1,\dots,n 
%   \end{gather*}
%   \pause
%   \centering
%   \vspace{6pt}
%   \begin{tabular}{ll}
%     \hline
%     Detections ($\tilde{y}_i$) & Multinomial cell probability                     \\
%     \hline
% %      0                       & $\pi_0 = (1-p)^J$                                \\
%       1                        & $\pi_1 = Jp^{1}(1-p)^{J-1}/(1-\pi_0)$            \\
%       2                        & $\pi_2 = {J\choose 2}p^{2}(1-p)^{J-2}/(1-\pi_0)$ \\
%       $\cdots$                 & $\cdots$                                         \\
%       J                        & $\pi_J = p^{J}/(1-\pi_0)$                        \\
%       \hline
%   \end{tabular}
%   \flushleft
%   \vspace{-6pt}
%   where $\pi_0=(1-p)^J$. Probs are zero-truncated binomials. \\ 
%   % \small
%   \pause
%   \vfill
%   Definitions \\
%   \scriptsize
%   $N$ -- Population size                                                          \\
%   $n$ -- Number of animals captured                                               \\
% %  $p^*$ -- probability of being captured at least once
% %  $y_{ij}$ -- encounter histories                                                \\
%   $\tilde{y}_i=\sum_{j=1}^J y_{ij}$ -- number of times individual $i$ was encounter out of $J$
%   occasions                                                                       \\
%   $\pi_j$ -- Probability of capturing an individual $k$ times \\
%   \pause
%   \vfill
%   \centering
%   This only works if $p$ doesn't change over time. \\
% \end{frame}



\begin{frame}
  \frametitle{Joint likelihood}
  % \footnotesize
  \small
  The joint likelihood is based on the multinomial distribution, with
  the ``all-zero'' encounter history being unobserved. \\  
  \begin{equation*}
    \{f_1, \dots, f_{K+1}\} \sim \mathrm{Multinomial}(N, \pi_1, \dots, \pi_{K+1}) \;\;
  \end{equation*}
  where $\{f_1, \dots, f_K\}$ are the frequencies of the observable capture
  histories. \\
  \vfill
  Here's an example with $J=3$ capture occasions.  \\
  \vfill
  \centering
    \begin{tabular}{ll}
      \hline
      Capture history       & Multinomial cell probability \\
      \hline
      100                   & $\pi_1=p_1(1-p_2)(1-p_3)$    \\
      010                   & $\pi_2=(1-p_1)p_2(1-p_3)$    \\
      001                   & $\pi_3=(1-p_1)(1-p_2)p_3$    \\
      110                   & $\pi_4=p_1p_2(1-p_3)$        \\
      101                   & $\pi_5=p_1(1-p_2)p_3$        \\
      011                   & $\pi_6=(1-p_1)p_2p_3$        \\
      111                   & $\pi_7 = p_1p_2p_3$          \\
      000                   & $\pi_0 = \prod_j 1-p_j$      \\
      \hline
    \end{tabular}
%   \pause
%   \vfill
%   \flushleft
%   Likelihood function for this formulation
%   \begin{equation*}
% %  \begin{multline*}
% %    L(N,p; y,n) =                                          \\
%     L(N,p; y,n) = \left\{\prod_{i=1}^n \prod_{j=1}^J p^{y_{ij}}(1-p)^{1-y_{ij}}\right\}
% %    \left\{\frac{N!}{(N-n)!}  \left(\prod_{j=1}^J(1-p)\right)^{N-n} \right\}
%     \frac{N!}{(N-n)!}  \left(\pi_0\right)^{N-n}
% %  \end{multline*}
%   \end{equation*}
\end{frame}




% \begin{frame}
%   \frametitle{Joint likelihood, conditional-on-$n$}
% %  \frametitle{Conditional-on-$n$, multinomial cell probs}
%   \footnotesize
%   Here's another option (that's easy to implement in JAGS) with a conditional multinomial: \\
%   \begin{gather*}
%     n \sim \mathrm{Binomial}\left(N, 1-\pi_0\right)                      \\
%     \{f_1, \dots, f_K\} \sim \mathrm{Multinomial}(n, \pi_1, \dots, \pi_K) \;\;
% %    \mathrm{for}\, i=1,\dots,n                                           %\\
% %    y_j = h_{k_i}
%   \end{gather*}
%   where $\{f_1, \dots, f_K\}$ are the observed frequencies of each
%   capture history. \\
%   \pause \vfill
%   Example with $J=3$ capture occasions.                                          \\
% %  \begin{columns}
% %    \column{0.9\paperwidth}
%   \scriptsize
%   \vspace{6pt}
%   \centering
%     \begin{tabular}{ll}
%       \hline
%       Capture history & Multinomial cell probability        \\
%       \hline
% %      000 & $\pi_0 = \prod_j 1-p_j/(1-\pi_0)$                           \\
%       100                   & $\pi_1=p_1(1-p_2)(1-p_3)/(1-\pi_0)$ \\
%       010                   & $\pi_2=(1-p_1)p_2(1-p_3)/(1-\pi_0)$ \\
%       001                   & $\pi_3=(1-p_1)(1-p_2)p_3/(1-\pi_0)$ \\
%       110                   & $\pi_4=p_1p_2(1-p_3)/(1-\pi_0)$     \\
%       101                   & $\pi_5=p_1(1-p_2)p_3/(1-\pi_0)$     \\
%       011                   & $\pi_6=(1-p_1)p_2p_3/(1-\pi_0)$     \\
%       111                   & $\pi_7 = p_1p_2p_3/(1-\pi_0)$       \\
%       \hline
%     \end{tabular}
%     % \end{columns}
%     \flushleft
%   where $\pi_0=\prod_{j=1}^J 1-p_j$.                                     \\
% \end{frame}




% \begin{frame}
%   \frametitle{Joint likelihood}
%   % \footnotesize
%   \small
%   Rather than condition on $n$, we can maximize the ``unconditional''
%   likelihood that includes the ``all zero'' encounter history,
%   weighted $n_0=N-n$ times. 
%   % \vfill
%   % \centering
%     % \begin{tabular}{ll}
%     %   \hline
%     %   Capture history ($h$) & Multinomial cell probability \\
%     %   \hline
%     %   000                   & $\pi_0 = \prod_j 1-p_j$      \\
%     %   100                   & $\pi_1=p_1(1-p_2)(1-p_3)$    \\
%     %   010                   & $\pi_2=(1-p_1)p_2(1-p_3)$    \\
%     %   001                   & $\pi_3=(1-p_1)(1-p_2)p_3$    \\
%     %   110                   & $\pi_4=p_1p_2(1-p_3)$        \\
%     %   101                   & $\pi_5=p_1(1-p_2)p_3$        \\
%     %   011                   & $\pi_6=(1-p_1)p_2p_3$        \\
%     %   111                   & $\pi_7 = p_1p_2p_3$          \\
%     %   \hline
%     % \end{tabular}
%   \pause
%   \vfill
%   \flushleft
%   Likelihood function for this formulation
%   \begin{equation*}
% %  \begin{multline*}
% %    L(N,p; y,n) =                                          \\
%     L(N,p; y,n) = \left\{\prod_{i=1}^n \prod_{j=1}^J p^{y_{ij}}(1-p)^{1-y_{ij}}\right\}
% %    \left\{\frac{N!}{(N-n)!}  \left(\prod_{j=1}^J(1-p)\right)^{N-n} \right\}
%     \frac{N!}{(N-n)!}  \left(\pi_0\right)^{N-n}
% %  \end{multline*}
%   \end{equation*}
% \end{frame}



\begin{frame}
  \frametitle{Model variations}
  \small
  More important than the estimation approach, is identification of
  the sources of variation in capture probability ($p$). \\ 
  \pause
  \vfill
  Otis et al. (1978) identified several model
  variations: 
  \begin{itemize}
    \small
    \item $M_0$ -- $p$ is constant
    \item $M_t$ -- unique $p$ for each capture occasion
    \item \hangindent=0.8cm $M_b$ -- behavioral response with $p$ different than
      recapture probability $c$
    \item $M_h$ -- individual heterogeneity in $p$
      \begin{itemize}
        \item Finite mixture models
        \item Continuous mixture models (not available in RMark)
      \end{itemize}
  \end{itemize}
  \pause \vfill
  These can be combined, but beware of identifiability issues. See
  Otis et al. (1978) for details.  \\
  \pause \vfill
  Later we'll talk about %another important class, 
  ``individual covariate'' models.  
\end{frame}




\begin{frame}
  \frametitle{Software options}
  \small
  Program MARK
  \begin{itemize}
  \footnotesize
    \item Has the most model types
    \item Written for Windows, but can be executed on other platforms  
  \end{itemize}
  R package `RMark'
  \begin{itemize}
  \footnotesize
    \item Function \inr{mark} runs MARK from R.
  \end{itemize}
  R package `marked'
  \begin{itemize}
  \footnotesize
    \item Includes CJS and JS models
  \end{itemize}
  R package `mra'
  \begin{itemize}
  \footnotesize
    \item Includes closed-population, CJS, and JS models
  \end{itemize}
  R package `Rcapture'
  \begin{itemize}
  \footnotesize
    \item Includes closed-population
  \end{itemize}
  R package `unmarked'
  \begin{itemize}
  \footnotesize
    \item Likelihood-based data augmentation with \inr{occu}
  \end{itemize}
  R package `secr'
  \begin{itemize}
  \footnotesize
    \item Designed for spatially explicit models, but see \inr{closedN}
  \end{itemize}
\end{frame}




\section{Simulation}

%\section{Model $M_0$}


%\subsection{Simulation}


\subsection{Model $M_0$}




\begin{frame}
  \frametitle{Outline}
  \Large
%  \tableofcontents[currentsection,currentsubsection]
  \tableofcontents[currentsection]
\end{frame}









\begin{frame}[fragile]
  \frametitle{Model $M_0$}
  \small
  Parameters
  \vspace{-6pt}
\begin{knitrout}\scriptsize
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{N} \hlkwb{<-} \hlnum{100}
\hlstd{p} \hlkwb{<-} \hlnum{0.2}
\end{alltt}
\end{kframe}
\end{knitrout}
  \pause
  \vfill
  All capture histories (for captured and uncaptured individuals)
  \vspace{-6pt}
\begin{knitrout}\scriptsize
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{J} \hlkwb{<-} \hlnum{4}  \hlcom{## Occasions}
\hlstd{y.all} \hlkwb{<-} \hlkwd{matrix}\hlstd{(}\hlnum{NA}\hlstd{, N, J)}
\hlkwa{for}\hlstd{(i} \hlkwa{in} \hlnum{1}\hlopt{:}\hlstd{N) \{}
    \hlstd{y.all[i,]} \hlkwb{<-} \hlkwd{rbinom}\hlstd{(J,} \hlnum{1}\hlstd{, p)}
\hlstd{\}}
\end{alltt}
\end{kframe}
\end{knitrout}
  \pause
  \vfill
  Observed capture histories (data)
  \vspace{-6pt}
\begin{knitrout}\scriptsize
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{captured} \hlkwb{<-} \hlkwd{rowSums}\hlstd{(y.all)}\hlopt{>}\hlnum{0}
\hlstd{(n} \hlkwb{<-} \hlkwd{sum}\hlstd{(captured))}
\end{alltt}
\begin{verbatim}
## [1] 54
\end{verbatim}
\begin{alltt}
\hlstd{y} \hlkwb{<-} \hlstd{y.all[captured,]}
\hlstd{y[}\hlnum{1}\hlopt{:}\hlnum{3}\hlstd{,]}
\end{alltt}
\begin{verbatim}
##      [,1] [,2] [,3] [,4]
## [1,]    0    1    0    0
## [2,]    1    0    0    0
## [3,]    0    0    1    0
\end{verbatim}
\end{kframe}
\end{knitrout}
\end{frame}



\begin{frame}[fragile]
  \frametitle{Summary stats}
  Capture history frequencies
\begin{knitrout}\scriptsize
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{histories} \hlkwb{<-} \hlkwd{apply}\hlstd{(y,} \hlnum{1}\hlstd{, paste,} \hlkwc{collapse}\hlstd{=}\hlstr{""}\hlstd{)}
\hlkwd{sort}\hlstd{(}\hlkwd{table}\hlstd{(histories))}
\end{alltt}
\begin{verbatim}
## histories
## 0011 0101 1100 1010 1101 0110 1001 0001 0010 0100 1000 
##    1    1    1    2    2    4    4    7   10   10   12
\end{verbatim}
\end{kframe}
\end{knitrout}
\pause
\vfill
  Detection frequencies
\begin{knitrout}\scriptsize
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{y.tilde} \hlkwb{<-} \hlkwd{rowSums}\hlstd{(y)}
\hlkwd{sort}\hlstd{(}\hlkwd{table}\hlstd{(y.tilde))}
\end{alltt}
\begin{verbatim}
## y.tilde
##  3  2  1 
##  2 13 39
\end{verbatim}
\end{kframe}
\end{knitrout}
\end{frame}



\subsection{Model $M_t$}


\begin{frame}[fragile]
  \frametitle{Model $M_t$ -- Temporal variation}
  Capture probability for each occasion
\begin{knitrout}\scriptsize
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{p.t} \hlkwb{<-} \hlkwd{c}\hlstd{(}\hlnum{0.3}\hlstd{,} \hlnum{0.5}\hlstd{,} \hlnum{0.2}\hlstd{,} \hlnum{0.4}\hlstd{)}
\end{alltt}
\end{kframe}
\end{knitrout}
  \pause
  \vfill
  All capture histories (for captured and uncaptured individuals)
  \vspace{-6pt}
\begin{knitrout}\scriptsize
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{y.all.Mt} \hlkwb{<-} \hlkwd{matrix}\hlstd{(}\hlnum{NA}\hlstd{, N, J)}
\hlkwa{for}\hlstd{(i} \hlkwa{in} \hlnum{1}\hlopt{:}\hlstd{N) \{}
    \hlstd{y.all.Mt[i,]} \hlkwb{<-} \hlkwd{rbinom}\hlstd{(J,} \hlnum{1}\hlstd{, p.t) \}}
\end{alltt}
\end{kframe}
\end{knitrout}
  \pause
  \vfill
  Observed capture histories (data)
  \vspace{-6pt}
\begin{knitrout}\scriptsize
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{captured.Mt} \hlkwb{<-} \hlkwd{rowSums}\hlstd{(y.all.Mt)}\hlopt{>}\hlnum{0}
\hlstd{n.Mt} \hlkwb{<-} \hlkwd{sum}\hlstd{(captured.Mt)}
\hlstd{y.Mt} \hlkwb{<-} \hlstd{y.all.Mt[captured.Mt,]}
\hlstd{y.Mt[}\hlnum{1}\hlopt{:}\hlnum{3}\hlstd{,]}
\end{alltt}
\begin{verbatim}
##      [,1] [,2] [,3] [,4]
## [1,]    1    0    1    0
## [2,]    1    1    1    0
## [3,]    1    0    0    0
\end{verbatim}
\begin{alltt}
\hlkwd{colSums}\hlstd{(y.Mt)}
\end{alltt}
\begin{verbatim}
## [1] 28 53 22 38
\end{verbatim}
\end{kframe}
\end{knitrout}
\end{frame}



\subsection{Model $M_b$}

\begin{frame}[fragile]
  \frametitle{Model $M_b$ -- Behavioral response}
  Capture probability for each occasion
\begin{knitrout}\scriptsize
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{p.b} \hlkwb{<-} \hlnum{0.3}
\hlstd{c} \hlkwb{<-} \hlnum{0.5}  \hlcom{## Trap happy}
\end{alltt}
\end{kframe}
\end{knitrout}
  \pause
  \vfill
  All capture histories (for captured and uncaptured individuals)
  \vspace{-6pt}
\begin{knitrout}\scriptsize
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{y.all.Mb} \hlkwb{<-} \hlkwd{matrix}\hlstd{(}\hlnum{NA}\hlstd{, N, J)}
\hlstd{prevcap} \hlkwb{<-} \hlkwd{matrix}\hlstd{(}\hlnum{FALSE}\hlstd{, N, J)}
\hlkwa{for}\hlstd{(i} \hlkwa{in} \hlnum{1}\hlopt{:}\hlstd{N) \{}
    \hlstd{y.all.Mb[i,}\hlnum{1}\hlstd{]} \hlkwb{<-} \hlkwd{rbinom}\hlstd{(}\hlnum{1}\hlstd{,} \hlnum{1}\hlstd{, p.b)}
    \hlkwa{for}\hlstd{(j} \hlkwa{in} \hlnum{2}\hlopt{:}\hlstd{J) \{}
        \hlstd{prevcap[i,j]} \hlkwb{<-} \hlkwd{any}\hlstd{(y.all.Mb[i,}\hlnum{1}\hlopt{:}\hlstd{(j}\hlopt{-}\hlnum{1}\hlstd{)]}\hlopt{>}\hlnum{0}\hlstd{)}
        \hlstd{prob} \hlkwb{<-} \hlkwd{ifelse}\hlstd{(prevcap[i,j], c, p.b)}
        \hlstd{y.all.Mb[i,j]} \hlkwb{<-} \hlkwd{rbinom}\hlstd{(}\hlnum{1}\hlstd{,} \hlnum{1}\hlstd{, prob)}
    \hlstd{\}}
\hlstd{\}}
\end{alltt}
\end{kframe}
\end{knitrout}
  \pause
  \vfill
  Observed capture histories (data)
  \vspace{-6pt}
\begin{knitrout}\scriptsize
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{captured.Mb} \hlkwb{<-} \hlkwd{rowSums}\hlstd{(y.all.Mb)}\hlopt{>}\hlnum{0}
\hlstd{n.Mb} \hlkwb{<-} \hlkwd{sum}\hlstd{(captured.Mb)}
\hlstd{y.Mb} \hlkwb{<-} \hlstd{y.all.Mb[captured.Mb,]}
\hlcom{## prevcap[1:3,]}
\end{alltt}
\end{kframe}
\end{knitrout}
\end{frame}



\subsection{Model $M_h$}



\begin{frame}[fragile]
  \frametitle{Model $M_h$ -- Finite mixture}
  There are many flavors of $M_h$. This one assumes there are two
  (unknown) groups of individuals with different capture probs. 
\begin{knitrout}\scriptsize
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{mixture.prob} \hlkwb{<-} \hlnum{0.6}
\hlstd{group} \hlkwb{<-} \hlkwd{rbinom}\hlstd{(N,} \hlnum{1}\hlstd{, mixture.prob)}    \hlcom{## Two groups}
\hlstd{p.Mh.mix} \hlkwb{<-} \hlkwd{ifelse}\hlstd{(group}\hlopt{==}\hlnum{0}\hlstd{,} \hlnum{0.2}\hlstd{,} \hlnum{0.7}\hlstd{)} \hlcom{## Two-point mixture}
\end{alltt}
\end{kframe}
\end{knitrout}
  \pause
  \vfill
  All capture histories (for captured and uncaptured individuals)
  \vspace{-6pt}
\begin{knitrout}\scriptsize
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{y.all.Mh.mix} \hlkwb{<-} \hlkwd{matrix}\hlstd{(}\hlnum{NA}\hlstd{, N, J)}
\hlkwa{for}\hlstd{(i} \hlkwa{in} \hlnum{1}\hlopt{:}\hlstd{N) \{}
    \hlstd{y.all.Mh.mix[i,]} \hlkwb{<-} \hlkwd{rbinom}\hlstd{(J,} \hlnum{1}\hlstd{, p.Mh.mix[i])}
\hlstd{\}}
\end{alltt}
\end{kframe}
\end{knitrout}
  \pause
  \vfill
  Observed capture histories (data)
  \vspace{-6pt}
\begin{knitrout}\scriptsize
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{captured.Mh.mix} \hlkwb{<-} \hlkwd{rowSums}\hlstd{(y.all.Mh.mix)}\hlopt{>}\hlnum{0}
\hlstd{n.Mh.mix} \hlkwb{<-} \hlkwd{sum}\hlstd{(captured.Mh.mix)}
\hlstd{y.Mh.mix} \hlkwb{<-} \hlstd{y.all.Mh.mix[captured.Mh.mix,]}
\end{alltt}
\end{kframe}
\end{knitrout}
\end{frame}



\begin{frame}[fragile]
  \frametitle{Model $M_h$ -- Individual heterogeneity}
  Here's another flavor of $M_h$: logit-normal distribution for
  $p$.  
\begin{knitrout}\scriptsize
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{logit.p.bar} \hlkwb{<-} \hlopt{-}\hlnum{1}  \hlcom{## Mean p on logit scale}
\hlstd{logit.p.var} \hlkwb{<-} \hlnum{1}   \hlcom{## SD of p on logit scale}
\hlstd{p.h} \hlkwb{<-} \hlkwd{plogis}\hlstd{(}\hlkwd{rnorm}\hlstd{(N, logit.p.bar, logit.p.var))}
\end{alltt}
\end{kframe}
\end{knitrout}
  \pause
  \vfill
  All capture histories (for captured and uncaptured individuals)
  \vspace{-6pt}
\begin{knitrout}\scriptsize
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{y.all.Mh} \hlkwb{<-} \hlkwd{matrix}\hlstd{(}\hlnum{NA}\hlstd{, N, J)}
\hlkwa{for}\hlstd{(i} \hlkwa{in} \hlnum{1}\hlopt{:}\hlstd{N) \{}
    \hlstd{y.all.Mh[i,]} \hlkwb{<-} \hlkwd{rbinom}\hlstd{(J,} \hlnum{1}\hlstd{, p.h[i])}
\hlstd{\}}
\end{alltt}
\end{kframe}
\end{knitrout}
  \pause
  \vfill
  Observed capture histories (data)
  \vspace{-6pt}
\begin{knitrout}\scriptsize
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{captured.Mh} \hlkwb{<-} \hlkwd{rowSums}\hlstd{(y.all.Mh)}\hlopt{>}\hlnum{0}
\hlstd{n.Mh} \hlkwb{<-} \hlkwd{sum}\hlstd{(captured.Mh)}
\hlstd{y.Mh} \hlkwb{<-} \hlstd{y.all.Mh[captured.Mh,]}
\hlcom{#y.Mh[1:3,]}
\end{alltt}
\end{kframe}
\end{knitrout}
\end{frame}





\section{Joint likelihood}



\begin{frame}
  \frametitle{Outline}
  \Large
  \tableofcontents[currentsection]
\end{frame}


% %% p(y,n|N,p)
% \begin{frame}[fragile]
%   \frametitle{Joint likelihood for $M_0$}
%   The joint likelihood has a multinomial form:
%   \begin{multline*}
%     L(N,p; y,n) = \\
%     \left\{\prod_{i=1}^n \prod_{j=1}^J p^{y_{ij}}(1-p)^{1-y_{ij}}\right\}
%     \left\{\frac{N!}{(N-n)!}  \left(\prod_{j=1}^J(1-p)\right)^{N-n} \right\}
%   \end{multline*}
%   \pause
%   \vfill
% % <<nll-M0,echo=TRUE,size='scriptsize'>>=
% nll.M0 <- function(pars, y) {           ## Negative log-likelihood
%     n <- nrow(y);       J <- ncol(y)
%     N <- exp(pars[1])
%     n0 <- N-n
%     if(n0<0) return(NA)
%     p <- plogis(pars[2])
%     ld.y1 <- sum(dbinom(y, 1, p, log=TRUE))
%     p0 <- (1-p)^J
%     ld.n0 <- lgamma(N+1)-lgamma(n0+1)+n0*log(p0)
%     nll <- -(ld.y1+ld.n0)
%     return(nll)
% }
% % @
% \end{frame}



% \begin{frame}[fragile]
%   \frametitle{Maximize joint likelihood for $M_0$}
% Minimized the negative log-likelihood
% % <<opt-nll-M0, size='scriptsize'>>=
% fm.M0 <- optim(c(log.N=4,logit.p=0), nll.M0, y=y, hessian=TRUE)
% fm.M0.est <- data.frame(Estimate=c(fm.M0$par[1], fm.M0$par[2]),
%                         SE=sqrt(diag(solve(fm.M0$hessian))))
% fm.M0.est

% % @
% \pause
% \vfill
% Back-transform the estimates
% % <<opt-nll-M0-back, size='scriptsize'>>=
% c(N.hat=exp(fm.M0$par[1]), p.hat=plogis(fm.M0$par[2]))
% % @
% \pause
% \vfill
% Compare to data-generating values
% % <<dg,size='scriptsize'>>=
% c(N=N, p=p)
% % @ 
% \end{frame}





% %% p(y|n,p)p(n|N,p)
% % <<eval=FALSE,include=FALSE,echo=FALSE>>=
% nll.M0.2 <- function(pars, y) {
%     n <- nrow(y);       J <- ncol(y)
%     N <- exp(pars[1])
%     n0 <- N-n
%     if(n0<0) return(NA)
%     p <- plogis(pars[2])
%     J <- ncol(y)
%     p.star <- 1-(1-p)^J

%     ydot <- rowSums(y)
%     lcd.y <- sum(dbinom(ydot, J, p, log=TRUE)-log(p.star))
%     ld.n <- lchoose(N, n)+n*log(p.star)+n0*log(1-p.star)
%     nll <- -(lcd.y+ld.n)
%     return(nll)
% }
% fm.M0.2 <- optim(c(5,0), nll.M0.2, y=y, hessian=TRUE)
% c(N=exp(fm.M0.2$par[1]), p=plogis(fm.M0.2$par[2]))
% % @ 



% %% p(y|n,p)
% % <<eval=FALSE,include=FALSE,echo=FALSE>>=

% nll.M0.cn <- function(pars, y) {
%     p <- plogis(pars[1])
%     J <- ncol(y)
%     p.star <- 1-(1-p)^J
%     ydot <- rowSums(y)
%     nll <- -sum(dbinom(ydot, J, p, log=TRUE)-log(p.star))
%     return(nll)
% }
% fm.M0.cn <- optim(0, nll.M0.cn, y=y, hessian=TRUE, method="Brent", lower=-10, upper=10)
% c(p=plogis(fm.M0.cn$par[1]))
% % @ 




% \begin{frame}[fragile]
%   \frametitle{R package `Rcapture'}
% <<Rcapture,size='scriptsize',warning=FALSE,message=FALSE>>=

% ## install.packages("Rcapture")
% library(Rcapture)
% closedp(y)
% @   
% \end{frame}




% \begin{frame}[fragile]
%   \frametitle{R package `mra'}
% <<mra,size='scriptsize',warning=FALSE,message=FALSE>>=

% ## install.packages("mra")
% library(mra)
% F.huggins.estim(~1, histories=y)
% @   
% \end{frame}



\begin{frame}
  \frametitle{R package `RMark'}
  Before you can use `RMark', you have to install MARK.  \\
  \vfill
  The main MARK page is here: \\
  {\color{blue} \url{ 
    http://www.phidot.org/software/mark/index.html
  }}  \\
  \vfill
  Instructions for Linux and Mac users: \\
  {\color{blue}
    \url{
      http://www.phidot.org/software/mark/rmark/linux/ \\
    }
    \vspace{6pt}
    \url{
      https://github.com/heathergaya/JAGS-NIMBLE-Tutorials/blob/master/Installing\%20RMark\%20on\%20Mac\%202022
    } } \\
  \vfill
  Lots of good information about closed population mark-recapture: \\
  {\color{blue} \footnotesize \url{ 
    http://www.phidot.org/software/mark/docs/book/pdf/chap14.pdf
  }}
\end{frame}



\begin{frame}[fragile]
  \frametitle{R package `RMark' -- Model $M_0$}
  \small
  Fit the model and set capture probability equal to recapture probability
  ($p=c$) using the \inr{share} argument.
\begin{knitrout}\scriptsize
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlcom{## install.packages("RMark") ## Must install MARK too!!}
\hlkwd{library}\hlstd{(RMark)}
\hlstd{y.ch} \hlkwb{<-} \hlkwd{data.frame}\hlstd{(}\hlkwc{ch}\hlstd{=}\hlkwd{apply}\hlstd{(y,} \hlnum{1}\hlstd{, paste,} \hlkwc{collapse}\hlstd{=}\hlstr{""}\hlstd{))}
\hlstd{mark.M0} \hlkwb{<-} \hlkwd{mark}\hlstd{(}\hlkwc{data}\hlstd{=y.ch,} \hlkwc{model}\hlstd{=}\hlstr{"Closed"}\hlstd{,} \hlkwc{silent}\hlstd{=}\hlnum{TRUE}\hlstd{,}
                \hlkwc{model.parameters}\hlstd{=}\hlkwd{list}\hlstd{(}\hlkwc{p}\hlstd{=}\hlkwd{list}\hlstd{(}\hlkwc{formula}\hlstd{=}\hlopt{~}\hlnum{1}\hlstd{,}\hlkwc{share}\hlstd{=}\hlnum{TRUE}\hlstd{)))}
\end{alltt}
\end{kframe}
\end{knitrout}
\pause
\vfill
Estimates of $p$ and $n_0$ (called $f_0$ in MARK)
\begin{knitrout}\scriptsize
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{mark.M0}\hlopt{$}\hlstd{results}\hlopt{$}\hlstd{real}
\end{alltt}
\begin{verbatim}
##               estimate         se        lcl        ucl fixed note
## p g1 t1      0.1837077  0.0374009  0.1212906  0.2684329           
## f0 g1 a0 t1 42.6208670 16.7216970 20.3020000 89.4758290
\end{verbatim}
\end{kframe}
\end{knitrout}
\pause
\vfill
Estimate of $N$ 
\begin{knitrout}\scriptsize
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{mark.M0}\hlopt{$}\hlstd{results}\hlopt{$}\hlstd{derived}
\end{alltt}
\begin{verbatim}
## $`N Population Size`
##   estimate      se    lcl      ucl
## 1 96.62087 16.7217 74.302 143.4758
\end{verbatim}
\end{kframe}
\end{knitrout}
\end{frame}





\begin{frame}[fragile]
  \frametitle{R package `RMark' -- Model $M_t$}
\begin{knitrout}\scriptsize
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{yt.ch} \hlkwb{<-} \hlkwd{data.frame}\hlstd{(}\hlkwc{ch}\hlstd{=}\hlkwd{apply}\hlstd{(y.Mt,} \hlnum{1}\hlstd{, paste,} \hlkwc{collapse}\hlstd{=}\hlstr{""}\hlstd{))}
\hlstd{mark.Mt} \hlkwb{<-} \hlkwd{mark}\hlstd{(}\hlkwc{data}\hlstd{=yt.ch,} \hlkwc{model}\hlstd{=}\hlstr{"Closed"}\hlstd{,} \hlkwc{silent}\hlstd{=}\hlnum{TRUE}\hlstd{,}
                \hlkwc{model.parameters}\hlstd{=}\hlkwd{list}\hlstd{(}\hlkwc{p}\hlstd{=}\hlkwd{list}\hlstd{(}\hlkwc{formula}\hlstd{=}\hlopt{~}\hlstd{time,}\hlkwc{share}\hlstd{=}\hlnum{TRUE}\hlstd{)))}
\end{alltt}
\end{kframe}
\end{knitrout}
\pause
\vfill
Estimates of $p_j$ and $n_0$ (called $f_0$ in MARK)
\begin{knitrout}\scriptsize
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{mark.Mt}\hlopt{$}\hlstd{results}\hlopt{$}\hlstd{real}
\end{alltt}
\begin{verbatim}
##               estimate        se       lcl        ucl fixed note
## p g1 t1      0.2740198 0.0473865 0.1913594  0.3757930           
## p g1 t2      0.5186804 0.0592722 0.4035760  0.6318356           
## p g1 t3      0.2153013 0.0428690 0.1429996  0.3108977           
## p g1 t4      0.3718840 0.0532543 0.2746824  0.4806868           
## f0 g1 a0 t1 17.1823890 6.4441806 8.4388339 34.9852260
\end{verbatim}
\end{kframe}
\end{knitrout}
\pause
\vfill
Estimate of $N$ 
\begin{knitrout}\scriptsize
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{mark.Mt}\hlopt{$}\hlstd{results}\hlopt{$}\hlstd{derived}
\end{alltt}
\begin{verbatim}
## $`N Population Size`
##   estimate       se      lcl      ucl
## 1 102.1824 6.444181 93.43883 119.9852
\end{verbatim}
\end{kframe}
\end{knitrout}
\end{frame}





\begin{frame}[fragile]
  \frametitle{R package `RMark' -- Model $M_b$}
\begin{knitrout}\scriptsize
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{yb.ch} \hlkwb{<-} \hlkwd{data.frame}\hlstd{(}\hlkwc{ch}\hlstd{=}\hlkwd{apply}\hlstd{(y.Mb,} \hlnum{1}\hlstd{, paste,} \hlkwc{collapse}\hlstd{=}\hlstr{""}\hlstd{))}
\hlstd{mark.Mb} \hlkwb{<-} \hlkwd{mark}\hlstd{(}\hlkwc{data}\hlstd{=yb.ch,} \hlkwc{model}\hlstd{=}\hlstr{"Closed"}\hlstd{,} \hlkwc{silent}\hlstd{=}\hlnum{TRUE}\hlstd{)} \hlcom{## Default model}
\end{alltt}
\end{kframe}
\end{knitrout}
\pause
\vfill
Estimates of $p$, $c$, and $n_0$ (called $f_0$ in MARK)
\begin{knitrout}\scriptsize
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{mark.Mb}\hlopt{$}\hlstd{results}\hlopt{$}\hlstd{real}
\end{alltt}
\begin{verbatim}
##               estimate         se       lcl         ucl fixed note
## p g1 t1      0.2459652  0.0827673 0.1197363   0.4389148           
## c g1 t2      0.4031008  0.0431879 0.3220497   0.4898126           
## f0 g1 a0 t1 33.4146890 23.1166000 9.8085778 113.8331600
\end{verbatim}
\end{kframe}
\end{knitrout}
\pause
\vfill
Estimate of $N$ 
\begin{knitrout}\scriptsize
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{mark.Mb}\hlopt{$}\hlstd{results}\hlopt{$}\hlstd{derived}
\end{alltt}
\begin{verbatim}
## $`N Population Size`
##   estimate      se      lcl      ucl
## 1 104.4147 23.1166 80.80858 184.8332
\end{verbatim}
\end{kframe}
\end{knitrout}
\end{frame}





\begin{frame}[fragile]
  \frametitle{`RMark' -- Model $M_h$}
  This is a two-point mixture model. % using the conditional likelihood
%  approach of Huggins. 
\begin{knitrout}\scriptsize
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{yh.ch} \hlkwb{<-} \hlkwd{data.frame}\hlstd{(}\hlkwc{ch}\hlstd{=}\hlkwd{apply}\hlstd{(y.Mh.mix,} \hlnum{1}\hlstd{, paste,} \hlkwc{collapse}\hlstd{=}\hlstr{""}\hlstd{))}
\hlstd{mark.Mh} \hlkwb{<-} \hlkwd{mark}\hlstd{(}\hlkwc{data}\hlstd{=yh.ch,} \hlkwc{silent}\hlstd{=}\hlnum{TRUE}\hlstd{,} \hlkwc{model}\hlstd{=}\hlstr{"HetClosed"}\hlstd{,} \hlcom{# "HugHet", }
                \hlkwc{model.parameters}\hlstd{=}\hlkwd{list}\hlstd{(}\hlkwc{p}\hlstd{=}\hlkwd{list}\hlstd{(}\hlkwc{formula}\hlstd{=}\hlopt{~}\hlstd{mixture,}\hlkwc{share}\hlstd{=}\hlnum{TRUE}\hlstd{)))}
\end{alltt}
\end{kframe}
\end{knitrout}
\pause
\vfill
Estimates of $p$ and $\pi$, the proportion of individuals in group 2.
\begin{knitrout}\scriptsize
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{mark.Mh}\hlopt{$}\hlstd{results}\hlopt{$}\hlstd{real}
\end{alltt}
\begin{verbatim}
##              estimate        se       lcl        ucl fixed note
## pi g1 m1    0.6554419 0.1938702 0.2612441  0.9109756           
## p g1 t1 m1  0.3985716 0.1171102 0.2027866  0.6332367           
## p g1 t1 m2  0.8435083 0.1105443 0.5107926  0.9653086           
## f0 g1 a0 t1 7.6766952 5.7418200 2.0786092 28.3514810
\end{verbatim}
\end{kframe}
\end{knitrout}
\pause
\vfill
Estimate of $N$ 
\begin{knitrout}\scriptsize
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{mark.Mh}\hlopt{$}\hlstd{results}\hlopt{$}\hlstd{derived}
\end{alltt}
\begin{verbatim}
## $`N Population Size`
##   estimate      se      lcl      ucl
## 1  94.6767 5.74182 89.07861 115.3515
\end{verbatim}
\end{kframe}
\end{knitrout}
\end{frame}





\section{Data augmentation}


%\section{Prediction}
%\subsection{Likelihood-based inference}


\begin{frame}
  \frametitle{Outline}
  \Large
  \tableofcontents[currentsection]
\end{frame}



\begin{frame}
  \frametitle{Data augmentation}
  Data augmentation is strange. \\
  \pause
  \vfill
  We add ``all zero'' capture histories to our data, then we try to
  estimate how many of them are real. \\ 
  \pause
  \vfill
  The total number of observed and augmented encounter histories is
  $M$. \\
  \pause
  \vfill
  We define the model in terms of a binary indicator variable $z_i$,
  such that $N=\sum_{i=1}^M z_i$. \\
  \pause
  \vfill
  We know $z_i=1$ for the $n$ captured individuals. \\
\end{frame}



\begin{frame}
  \frametitle{Data augmentation}
  \footnotesize
  We can think about the problem like this: \\
  \centering
  \vfill
  \begin{tabular}{lcccc}
    \hline
               & \multicolumn{3}{c}{Occasion} \\
    \cline{2-4}
    Individual & 1     & 2     & 3     & z    \\
    \hline
    1          & 0     & 0     & 1     & 1    \\
    2          & 1     & 1     & 1     & 1            \\
    3          & 0     & 1     & 0     & 1            \\
    4          & 0     & 1     & 1     & 1            \\
    5          & 1     & 0     & 0     & 1            \\
    \dots      & \dots & \dots & \dots      & 1        \\
    $n$        & 0     & 0     & 1     & 1            \\
    \hline
    $n+1$      & 0     & 0     & 0     & ?            \\
    $n+2$      & 0     & 0     & 0     & ?            \\
    \dots      & \dots & \dots & \dots     & ?        \\
    $N$        & 0     & 0     & 0     & ?            \\
    \hline
    $N+1$      & 0     & 0     & 0     & ?            \\
    $N+2$      & 0     & 0     & 0     & ?            \\
    \dots      & \dots & \dots & \dots     & ?        \\
    $M$      & 0     & 0     & 0     & ?            \\
    \hline
  \end{tabular}
\end{frame}



\begin{frame}
  \frametitle{Data augmentation}
  The model:
  \begin{gather*}
    z_i \sim \mathrm{Bern}(\psi) \\
    y_{ij} \sim \mathrm{Bern}(z_i \times p_{ij}) \\
    N=\sum_{i=1}^M z_i
  \end{gather*}
  \pause \vfill
  % A uniform prior on $\psi$ results in a discrete uniform prior on
  % $N$. We can change the prior for $N$ by changing the prior on
  % $\psi$, recognizing that $E(N)=M\psi$.
  Note that this looks exactly like an occupancy model. \\
  \pause \vfill
  But why bother with augmentation?
  \begin{itemize}
    \item DA works for \alert{all} varieties of mark-recapture models
    \item Makes it easy to incorporate individual-covariates\dots \pause
      including distance and location.
  \end{itemize}
\end{frame}




% \subsection{Likelihood-based data augmentation}


\begin{frame}[fragile]
  \frametitle{Data augmentation}
  % \small
  % Normally, DA is used with Bayesian inference, but since it's exactly
  % the same model as a single-season occupancy model, we can also fit
  % it in `unmarked'.
  % \pause
  % \vfill
  First, let's augment the data simulated under model $M_b$, with
  $M=200$. \\
%\vspace{-6pt}
\begin{knitrout}\scriptsize
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{M} \hlkwb{<-} \hlnum{200}
\hlstd{y.aug} \hlkwb{<-} \hlkwd{matrix}\hlstd{(}\hlnum{0}\hlstd{, M, J)}
\hlstd{y.aug[}\hlnum{1}\hlopt{:}\hlkwd{nrow}\hlstd{(y.Mb),]} \hlkwb{<-} \hlstd{y.Mb}
\end{alltt}
\end{kframe}
\end{knitrout}
\pause
\vfill
We also need to augment the \inr{prevcap} object. \\
%\vspace{-6pt}
\begin{knitrout}\scriptsize
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{prevcap.aug} \hlkwb{<-} \hlkwd{matrix}\hlstd{(}\hlnum{FALSE}\hlstd{, M, J)}
\hlstd{prevcap.aug[}\hlnum{1}\hlopt{:}\hlkwd{nrow}\hlstd{(y.Mb),]} \hlkwb{<-} \hlstd{prevcap[captured.Mb,]}
\hlstd{prevcap.aug} \hlkwb{<-} \hlkwd{ifelse}\hlstd{(prevcap.aug,} \hlstr{"Yes"}\hlstd{,} \hlstr{"No"}\hlstd{)}
\end{alltt}
\end{kframe}
\end{knitrout}
\pause
\vfill
And we need a covariate indicating time (occasion). \\
%\vspace{-6pt}
\begin{knitrout}\scriptsize
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{occasion.aug} \hlkwb{<-} \hlkwd{matrix}\hlstd{(}\hlkwd{as.character}\hlstd{(}\hlnum{1}\hlopt{:}\hlstd{J), M, J,} \hlkwc{byrow}\hlstd{=}\hlnum{TRUE}\hlstd{)}
\end{alltt}
\end{kframe}
\end{knitrout}
\end{frame}


% \begin{frame}[fragile]
%   \frametitle{Model $M_0$ with `unmarked'}
%   \small
%   Create the unmarked frame
% <<un-umf,results='hide',size='scriptsize',warning=FALSE,message=FALSE>>=
% library(unmarked)
% umf <- unmarkedFrameOccu(y=y.aug,
%                          obsCovs=list(prevcap=prevcap.aug,
%                                       occasion=occasion.aug))
% @   
%   Fit the model  
% <<un-M0,size='scriptsize'>>=
% fm.M0 <- occu(~1~1, umf)
% fm.M0
% @   
% \end{frame}



% \begin{frame}[fragile]
%   \frametitle{Model $M_t$ with `unmarked'}
% <<un-Mt,size='scriptsize'>>=
% fm.Mt <- occu(~occasion~1, umf)
% fm.Mt
% @   
% \end{frame}



% \begin{frame}[fragile]
%   \frametitle{Model $M_b$ with `unmarked'}
% <<un-Mb,size='scriptsize'>>=
% fm.Mb <- occu(~prevcap~1, umf)
% fm.Mb
% @   
% \end{frame}


% \begin{frame}[fragile]
%   \frametitle{But how do we estimate $N$?}
%   First compute Empirical Bayes posterior probability that each
%   individual was ``real''. 
% <<un-re,size='footnotesize'>>=
% re.M0 <- ranef(fm.M0)
% re.Mt <- ranef(fm.Mt)
% re.Mb <- ranef(fm.Mb)
% @
% \pause
% \vfill
% Then we predict $N$, which can be thought of as the number of real
% individuals in the set of $M$ pseudo-individuals.
% <<un-N,size='footnotesize'>>=
% N.post.M0 <- predict(re.M0, func=sum, nsim=1000)
% N.post.Mt <- predict(re.Mt, func=sum, nsim=1000)
% N.post.Mb <- predict(re.Mb, func=sum, nsim=1000)
% @ 
% \end{frame}



% \begin{frame}[fragile]
%   \frametitle{Empirical Bayes posteriors of $N$}
% <<un-N-post, size='tiny',fig.height=3,out.width="100%",fig.show='hide', echo=-1>>=
% par(mfrow=c(1,3), mai=c(0.6,0.6,0.5,0.1))
% plot(table(N.post.M0), xlab="N", ylab="Posterior probability", main="M0",
%      xlim=c(75, 130), ylim=c(0,150)); abline(v=N, col="red")
% plot(table(N.post.Mt), xlab="N", ylab="Posterior probability", main="Mt",
%      xlim=c(75, 130), ylim=c(0,150)); abline(v=N, col="red")
% plot(table(N.post.Mb), xlab="N", ylab="Posterior probability", main="Mb",
%      xlim=c(75, 130), ylim=c(0,150)); abline(v=N, col="red")
% @
%   \begin{columns}
%     \begin{column}{0.95\paperwidth}
%       \includegraphics[width=\textwidth]{figure/un-N-post-1}
%     \end{column}
%   \end{columns}
%   \vfill
%   \pause
%   \footnotesize
%   We see that $M$ is sufficiently high because: $\Pr(N=M|y) \approx
%   0$. Otherwise, we would have to rerun it with a larger value of $M$.
% \end{frame}





% \subsection{Bayesian data augmentation}

% %\subsection{Bayesian inference}


% \begin{frame}
%   \frametitle{Outline}
%   \Large
%   \tableofcontents[currentsection,currentsubsection]
% \end{frame}



\begin{frame}
  \frametitle{Bayesian data augmentation}
  For Bayesian inference, we need priors on $\psi$ and $p$. 
  \begin{gather*}
    z_i \sim \mathrm{Bern}(\psi) \\
    y_{ij} \sim \mathrm{Bern}(z_i \times p) \\
    N = \sum_{i=1}^M z_i
  \end{gather*}
  \vfill
  A uniform prior on $\psi$ results in a discrete uniform prior on
  $N$. We can change the prior for $N$ by changing the prior on  
  $\psi$, recognizing:
  \[
    E(N)=M\psi
  \]
\end{frame}



\begin{frame}[fragile]
  \frametitle{Model $M_0$ -- data augmentation}
\vspace{-3pt}
\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.678, 0.847, 0.902}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{writeLines}\hlstd{(}\hlkwd{readLines}\hlstd{(}\hlstr{"M0-aug.jag"}\hlstd{))}
\end{alltt}
\begin{verbatim}
model {

p ~ dunif(0,1)       ## Capture probability
psi ~ dunif(0,1)     ## Data augmentation parameter

for(i in 1:M) {
  z[i] ~ dbern(psi)  ## DA indicator
  for(j in 1:J) {
    y[i,j] ~ dbern(z[i]*p) ## Model for the capture histories
  }
}

N <- sum(z)          ## Abundance

}
\end{verbatim}
\end{kframe}
\end{knitrout}
\end{frame}



\begin{frame}[fragile]
  \frametitle{Model $M_0$ -- data augmentation}
  Data
\begin{knitrout}\scriptsize
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{y.aug} \hlkwb{<-} \hlkwd{matrix}\hlstd{(}\hlnum{0}\hlstd{, M, J)}
\hlstd{y.aug[}\hlnum{1}\hlopt{:}\hlstd{n,]} \hlkwb{<-} \hlstd{y}
\hlstd{jags.data.M0} \hlkwb{<-} \hlkwd{list}\hlstd{(}\hlkwc{y}\hlstd{=y.aug,} \hlkwc{M}\hlstd{=M,} \hlkwc{J}\hlstd{=J)}
\end{alltt}
\end{kframe}
\end{knitrout}
\pause
\vfill
  Inits and parameters
\begin{knitrout}\scriptsize
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{ji.M0} \hlkwb{<-} \hlkwa{function}\hlstd{()} \hlkwd{list}\hlstd{(}\hlkwc{z}\hlstd{=}\hlkwd{rep}\hlstd{(}\hlnum{1}\hlstd{,M),} \hlkwc{psi}\hlstd{=}\hlkwd{runif}\hlstd{(}\hlnum{1}\hlstd{),} \hlkwc{p}\hlstd{=}\hlkwd{runif}\hlstd{(}\hlnum{1}\hlstd{))}
\hlstd{jp.M0} \hlkwb{<-} \hlkwd{c}\hlstd{(}\hlstr{"p"}\hlstd{,} \hlstr{"psi"}\hlstd{,} \hlstr{"N"}\hlstd{)}
\end{alltt}
\end{kframe}
\end{knitrout}
\pause
\vfill
MCMC
\begin{knitrout}\scriptsize
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{library}\hlstd{(jagsUI)}
\hlstd{jags.post.M0} \hlkwb{<-} \hlkwd{jags.basic}\hlstd{(}\hlkwc{data}\hlstd{=jags.data.M0,} \hlkwc{inits}\hlstd{=ji.M0,}
                           \hlkwc{parameters.to.save}\hlstd{=jp.M0,}
                           \hlkwc{model.file}\hlstd{=}\hlstr{"M0-aug.jag"}\hlstd{,}
                           \hlkwc{n.chains}\hlstd{=}\hlnum{3}\hlstd{,} \hlkwc{n.adapt}\hlstd{=}\hlnum{100}\hlstd{,} \hlkwc{n.burnin}\hlstd{=}\hlnum{0}\hlstd{,}
                           \hlkwc{n.iter}\hlstd{=}\hlnum{2000}\hlstd{,} \hlkwc{parallel}\hlstd{=}\hlnum{TRUE}\hlstd{)}
\end{alltt}
\end{kframe}
\end{knitrout}
\end{frame}




\begin{frame}[fragile]
  \frametitle{Traceplots and density plots}
\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{plot}\hlstd{(jags.post.M0[,jp.M0])}
\end{alltt}
\end{kframe}

{\centering \includegraphics[width=0.7\textwidth]{figure/plot-mcmc-M0-1} 

}


\end{knitrout}
\end{frame}




% \begin{frame}[fragile]
%   \frametitle{Model $M_0$ -- without data augmentation}
%   Here's why practitioners like data augmentation 
% \vspace{-3pt}
% <<bugs-M0,size='footnotesize',comment='',background='lightblue'>>=
% writeLines(readLines("M0.jag"))
% @
% \end{frame}





% \begin{frame}[fragile]
%   \frametitle{Model $M_0$ -- without data augmentation}
%   Data
% <<jd-M0-noaug,size='scriptsize'>>=
% n0max <- 1000  ## Upper limit of prior on n0
% jags.data.M0.noaug <- list(y=y.aug, n=n, J=J,
%                            ## Prior probs for n0
%                            n0probs=rep(1/n0max, n0max), zero=0)
% @
% \pause
% \vfill
%   Inits and parameters
% <<ji-M0-noaug,size='scriptsize'>>=
% ji.M0.noaug <- function() list(n0=rpois(1, 5), p=runif(1, 0, 0.1))
% jp.M0.noaug <- c("p", "N")
% @
% \pause
% \vfill
% MCMC
% <<mcmc-M0-noaug,size='scriptsize',results='hide'>>=
% jags.post.M0.noaug <- jags.basic(data=jags.data.M0.noaug,
%                                  inits=ji.M0.noaug,
%                                  parameters.to.save=jp.M0.noaug,
%                                  model.file="M0.jag",
%                                  n.chains=3, n.adapt=100, n.burnin=0,
%                                  n.iter=2000, parallel=TRUE)
% @ 
% \end{frame}




% \begin{frame}[fragile]
%   \frametitle{Traceplots and density plots}
% <<plot-mcmc-M0-noaug,size='footnotesize',out.width="0.7\\textwidth",fig.align='center',cache=TRUE>>=
% plot(jags.post.M0.noaug[,jp.M0.noaug])
% @ 
% \end{frame}








% \begin{frame}[fragile]
%   \frametitle{Model $M_t$ -- data augmentation}
% \vspace{-3pt}
% <<bugs-Mt-aug,size='small',comment='',background='lightblue'>>=
% writeLines(readLines("Mt-aug.jag"))
% @
% \end{frame}






% \begin{frame}[fragile]
%   \frametitle{Model $M_t$ -- data augmentation}
%   Data, inits, parameters to monitor
% <<ji-Mt-aug,size='scriptsize'>>=
% jags.data.Mt <- jags.data.M0
% ji.Mt <- function() list(z=rep(1,M), psi=runif(1), p=runif(4))
% jp.Mt <- c("p", "psi", "N")
% @
% \pause
% \vfill
% MCMC
% <<mcmc-Mt-aug,size='scriptsize',results='hide'>>=
% jags.post.Mt <- jags.basic(data=jags.data.Mt, inits=ji.Mt,
%                            parameters.to.save=jp.Mt,
%                            model.file="Mt-aug.jag",
%                            n.chains=3, n.adapt=100, n.burnin=0,
%                            n.iter=2000, parallel=TRUE)
% @ 
% \end{frame}



% \begin{frame}[fragile]
%   \frametitle{Traceplots and density plots}
% <<plot-mcmc-Mt1,size='footnotesize',out.width="0.7\\textwidth",fig.align='center',cache=TRUE>>=
% plot(jags.post.Mt[,paste0("p[", 1:4, "]")])
% @ 
% \end{frame}


% \begin{frame}[fragile]
%   \frametitle{Model $M_t$ -- data augmentation}
% \vspace{-3pt}
% <<bugs-Mt-aug,size='small',comment='',background='lightblue'>>=
% writeLines(readLines("Mt-aug.jag"))
% @
% \end{frame}




\begin{frame}
  \frametitle{In-class exercise}
  \centering
  \large
  Write the BUGS model for $M_t$. \\
\end{frame}






\begin{frame}[fragile]
  \frametitle{Model $M_b$ -- data augmentation}
\vspace{-3pt}
\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.678, 0.847, 0.902}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{writeLines}\hlstd{(}\hlkwd{readLines}\hlstd{(}\hlstr{"Mb-aug.jag"}\hlstd{))}
\end{alltt}
\begin{verbatim}
model {

p ~ dunif(0, 1)     ## Capture prob
c ~ dunif(0, 1)     ## Recapture prob

psi ~ dunif(0,1)    ## Data augmentation parameter

for(i in 1:M) {     
  z[i] ~ dbern(psi) ## DA indicator
  for(j in 1:J) {
    pc[i,j] <- ifelse(prevcap[i,j]==0, p, c) ## First cap or recap?
    y[i,j] ~ dbern(z[i]*pc[i,j])
  }
}

N <- sum(z)

}
\end{verbatim}
\end{kframe}
\end{knitrout}
\end{frame}




\begin{frame}[fragile]
  \frametitle{Model $M_b$ -- data augmentation}
  Data, inits, parameters to monitor
\begin{knitrout}\scriptsize
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{jags.data.Mb} \hlkwb{<-} \hlstd{jags.data.M0}
\hlstd{jags.data.Mb}\hlopt{$}\hlstd{y[}\hlnum{1}\hlopt{:}\hlkwd{nrow}\hlstd{(y.Mb),]} \hlkwb{<-} \hlstd{y.Mb}
\hlstd{jags.data.Mb}\hlopt{$}\hlstd{prevcap} \hlkwb{<-} \hlkwd{ifelse}\hlstd{(prevcap.aug}\hlopt{==}\hlstr{"Yes"}\hlstd{,} \hlnum{1}\hlstd{,} \hlnum{0}\hlstd{)}
\hlstd{ji.Mb} \hlkwb{<-} \hlkwa{function}\hlstd{()} \hlkwd{list}\hlstd{(}\hlkwc{z}\hlstd{=}\hlkwd{rep}\hlstd{(}\hlnum{1}\hlstd{,M),} \hlkwc{psi}\hlstd{=}\hlkwd{runif}\hlstd{(}\hlnum{1}\hlstd{),} \hlkwc{p}\hlstd{=}\hlkwd{runif}\hlstd{(}\hlnum{1}\hlstd{),} \hlkwc{c}\hlstd{=}\hlkwd{runif}\hlstd{(}\hlnum{1}\hlstd{))}
\hlstd{jp.Mb} \hlkwb{<-} \hlkwd{c}\hlstd{(}\hlstr{"p"}\hlstd{,} \hlstr{"c"}\hlstd{,} \hlstr{"psi"}\hlstd{,} \hlstr{"N"}\hlstd{)}
\end{alltt}
\end{kframe}
\end{knitrout}
\pause
\vfill
MCMC
\begin{knitrout}\scriptsize
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{jags.post.Mb} \hlkwb{<-} \hlkwd{jags.basic}\hlstd{(}\hlkwc{data}\hlstd{=jags.data.Mb,} \hlkwc{inits}\hlstd{=ji.Mb,}
                           \hlkwc{parameters.to.save}\hlstd{=jp.Mb,}
                           \hlkwc{model.file}\hlstd{=}\hlstr{"Mb-aug.jag"}\hlstd{,}
                           \hlkwc{n.chains}\hlstd{=}\hlnum{3}\hlstd{,} \hlkwc{n.adapt}\hlstd{=}\hlnum{100}\hlstd{,} \hlkwc{n.burnin}\hlstd{=}\hlnum{0}\hlstd{,}
                           \hlkwc{n.iter}\hlstd{=}\hlnum{2000}\hlstd{,} \hlkwc{parallel}\hlstd{=}\hlnum{TRUE}\hlstd{)}
\end{alltt}
\end{kframe}
\end{knitrout}
\end{frame}





\begin{frame}[fragile]
  \frametitle{Traceplots and density plots}
\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.878, 0.918, 0.933}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{plot}\hlstd{(jags.post.Mb[,jp.Mb])}
\end{alltt}
\end{kframe}

{\centering \includegraphics[width=0.7\textwidth]{figure/plot-mcmc-Mb-1} 

}


\end{knitrout}
\end{frame}



\begin{frame}[fragile]
  \frametitle{Model $M_h$ -- finite mixture}
\vspace{-3pt}
\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.678, 0.847, 0.902}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{writeLines}\hlstd{(}\hlkwd{readLines}\hlstd{(}\hlstr{"Mhm-aug.jag"}\hlstd{))}
\end{alltt}
\begin{verbatim}
model {

p1 ~ dunif(0, 1)     ## Capture prob, group 1
p2 ~ dunif(0, 1)     ## Capture prob, group 2
mixprob ~ dunif(0,1) ## Finite mixture prob
psi ~ dunif(0,1)     ## Data augmentation parameter

for(i in 1:M) {     
  z[i] ~ dbern(psi)  ## DA indicator
  group[i] ~ dbern(mixprob)           ## Group 1 or 2?
  p[i] <- ifelse(group[i]==0, p1, p2) ## p depends on group
  for(j in 1:J) {
    y[i,j] ~ dbern(z[i]*p[i])
  }
}

N <- sum(z)

}
\end{verbatim}
\end{kframe}
\end{knitrout}
\end{frame}



\begin{frame}[fragile]
  \frametitle{Model $M_h$ -- logit normal}
\vspace{-3pt}
\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.678, 0.847, 0.902}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{writeLines}\hlstd{(}\hlkwd{readLines}\hlstd{(}\hlstr{"Mh-aug.jag"}\hlstd{))}
\end{alltt}
\begin{verbatim}
model {

lp.mean ~ dnorm(0,0.1)   ## Mean of logit(p)
lp.var ~ dexp(1)         ## Variance of logit(p)
psi ~ dunif(0,1)         ## Data augmentation parameter

for(i in 1:M) {     
  z[i] ~ dbern(psi)      ## DA indicator
  lp[i] ~ dnorm(lp.mean, 1/lp.var) ## Random effect (p on logit scale)
  p[i] <- ilogit(lp[i])  ## Capture prob for individual i
  for(j in 1:J) {
    y[i,j] ~ dbern(z[i]*p[i])
  }
}

N <- sum(z)

}
\end{verbatim}
\end{kframe}
\end{knitrout}
\end{frame}




%\section{Summary}


\begin{frame}
  \frametitle{Mark-recapture summary}
  We assume that variation in $p$ arises from changes over time,
  behavioral effects, or random individual heterogeneity. \\
  \pause \vfill
  Individual heterogeneity models pose estimation problems. \\
  \pause \vfill
  A solution is to use individual covariates to explain the variation,
  rather than random effects. \pause But what covariates are
  important? And how do we know the covariates values for uncaptured
  individuals? \\
  \pause \vfill
  With spatial capture-recapture (SCR) models we will use
  \alert{the unobserved distance between animals and traps} as a
  covariate, and we'll use a spatial point process model for
  animal locations.  
\end{frame}




\section{Assignment}




\begin{frame}[fragile]
  \frametitle{Assignment}
  \small
  % \footnotesize
  Create a self-contained R script or Rmarkdown file to do the
  following: 
  \vfill
  \begin{enumerate}
    \small
%    \footnotesize
%  \item Fit model $M_h$ in JAGS to the data simulated above
    \item Import the Canada warbler mark-recapture data ({\tt
        CAWAcaps\_2018.csv}) and fit the following models in RMark and
      JAGS\footnote{For JAGS, use $M=800$ but note if the posterior of
      $N$ pushes up against $M$.}:
      \begin{itemize}
        % \footnotesize
        \item Model $M_0$
        \item Model $M_t$ 
%        \item Model $M_b$
        \item Model $M_h$ -- Finite mixture
        \item Model $M_h$ -- Logit-normal (JAGS only)
      \end{itemize}
    \item Create a table reporting point estimates and 95\% CIs for
      $N$ for each model fit in RMark and JAGS. Which model has the
      lowest AICc? 
  \end{enumerate}
  \vfill
  Upload your {\tt .R} or {\tt .Rmd} file to ELC by noon on Wednesday.
\end{frame}





\end{document}

