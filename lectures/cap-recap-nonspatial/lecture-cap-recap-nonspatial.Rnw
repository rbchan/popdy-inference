\documentclass[color=usenames,dvipsnames]{beamer}
%\documentclass[color=usenames,dvipsnames,handout]{beamer}

\usepackage[roman]{../lectures}
%\usepackage[sans]{../lectures}


\hypersetup{pdfpagemode=UseNone,pdfstartview={FitV}}



% Load function to compile and open PDF
<<build-fun,include=FALSE,purl=FALSE>>=
source("../rnw2pdf.R")
@
% Compile and open PDF
<<buildit,include=FALSE,eval=FALSE>>=
rnw2pdf("lecture-cap-recap-nonspatial")
rnw2pdf("lecture-cap-recap-nonspatial", tangle=TRUE)
@ 


<<knitr-theme,include=FALSE,purl=FALSE>>=
knit_theme$set("edit-kwrite")
@


% New command for inline code that isn't to be evaluated
\definecolor{inlinecolor}{rgb}{0.878, 0.918, 0.933}
\newcommand{\inr}[1]{\colorbox{inlinecolor}{\texttt{#1}}}




\begin{document}




\begin{frame}[plain]
  \LARGE
  \centering
  {
    \LARGE Lecture 10 -- Non-spatial mark-recapture \\ for estimating
    population size: \\
    \Large simulation, fitting, and prediction \\
  }
  {\color{default} \rule{\textwidth}{0.1pt} }
  \vfill
  \large
  WILD(FISH) 8390 \\
  Estimation of Fish and Wildlife Population Parameters \\
  \vfill
  \large
  Richard Chandler \\
  University of Georgia \\
\end{frame}






\section{Overview}



\begin{frame}[plain]
  \frametitle{Outline}
  \Large
  \only<1>{\tableofcontents}%[hideallsubsections]}
  \only<2 | handout:0>{\tableofcontents[currentsection]}%,hideallsubsections]}
\end{frame}



\begin{frame}
  \frametitle{Mark-recapture overview}
  Until now, we've focused on models for data on aggregated quantities
  like abundance and occupancy. \\ 
  \pause
  \vfill
  Now we will talk about data on uniquely identifable individuals. \\
  \pause
  \vfill
  This is nice because all individuals are different, and we're often
  interested in these differences\dots \\
  \pause
  \vfill
  \dots even when our primary goal is
  inference on population-level parameters like abundance
  and density. \\
\end{frame}



\begin{frame}
  \frametitle{Mark-recapture overview}
  The simplest estimator of abundance is 
  \[
    \hat{N} = \frac{n}{\hat{p}}
  \]
  where $n$ is the number of individuals detected, $p$ is detection
  probability, and $E(n)=Np$. \\
  \pause
  \vfill
  In distance sampling, we modeled detection probability as a
  function of distance, and, we replaced $p$ with average detection
  probability. \\ 
  \pause
  \vfill
  For the simplest mark-recapture problems, $p$ is a constant and we
  estimate it by trapping on multiple occasions and marking and
  recapturing as we go.  
\end{frame}





\begin{frame}
  \frametitle{Mark-recapture data}
  \small
  Mark-recapture data are often called ``capture histories.'' Here's
  an example with $n=6$ animals captured on $J=3$ occasions. \\
  \centering
%  \vfill  
  \begin{tabular}{lccc}
    \hline
    & \multicolumn{3}{c}{Occasion} \\
    \cline{2-4}
    Individual & 1 & 2 & 3 \\
    \hline
    1 & 0 & 0 & 1 \\
    2 & 1 & 1 & 1 \\
    3 & 0 & 1 & 0 \\
    4 & 0 & 1 & 1 \\
    5 & 1 & 0 & 0 \\
    6 & 0 & 0 & 1 \\
    \hline
  \end{tabular}
  \pause
  \vfill
  \flushleft
  How do we estimate $p$ (and $N$) from these data? %\\
  \pause
%  \vfill
  You can get a sense for $p$ (and $N$) by looking at the data.
  \begin{itemize}
    \setlength\itemsep{.1pt}
    \item If $p\approx 1$, most individuals would be captured
      on all 3 occasions
    \item If $p\approx 0$, few individuals would be captured on
      more than once
  \end{itemize}
  \pause
  \vfill
  Knowing $p$ helps us determine how many individuals we missed  
\end{frame}




% \begin{frame}
%   \frametitle{In-class exercise}
%   Building off the previous example\dots
%   \begin{enumerate}
%     \item Compute $\bar{p}$ for line-transect sampling when
%       $\sigma=50, 100, \mathrm{and}\, 200$, instead of $\sigma=25$.  
%     \item Repeat, but for point-transect sampling. 
%   \end{enumerate}
% \end{frame}





\begin{frame}
  \frametitle{Classical approaches}
  Lincoln-Peterson  \\
  \begin{itemize}
    \item Just $J=2$ occasions
    \item Data are:
      \begin{itemize}
        \item $n_1$ -- number of individuals captured on first occasion
        \item $n_2$ -- number of individuals captured on second occasion
        \item $m_2$ -- number of recaptures
      \end{itemize}
    \item Estimator is $\hat{N} = n_1n_2/m_2$  
  \end{itemize}
  \pause
  \vfill
  Closed population models \\
  \begin{itemize}
    \item Usually better to have $J>2$ occasions
    \item Allows for assessment of behavioral effect, individual heterogeneity, etc\dots
  \end{itemize}
\end{frame}






\begin{frame}
  \frametitle{\large Closed population model ($N$ known hypothetically) }
  \small
  State model \\
  \vspace{6pt}
  {\centering
    There isn't one! $N$ is often treated as a constant, although we
    sometimes put a Poisson or binomial prior on it.  \\
  }
  \pause
  \vfill
  Observation model (supposing $N$ was known)
  \begin{equation*}
    y_{ij} \sim \mathrm{Bernoulli}(p) \;\; \mathrm{for}\, i=1,\dots,N 
  \end{equation*}
  \pause
%  \vfill
  \small
  Definitions \\
  $N$ -- Population size \\
  \hangindent=0.8cm $y_{ij}$ -- encounter histories, indicating if
  individual $i$ was captured on occasion $j$ \\  
  $p$ -- Capture probability
  \pause
  \vfill
  The problem with this formulation is that we don't observe the ``all
  zero'' encounter histories (and thus we don't know $N$). 
\end{frame}





\begin{frame}
  \frametitle{Closed population estimation options}
  Condional likelihood \\
  \begin{itemize}
    \item Estimate $p$, and then compute $\hat{N}=n/\hat{p}$
  \end{itemize}
  \pause
  \vfill
  Joint likelihood \\
  \begin{itemize}
    \item Estimate $N$ and $p$ jointly
    \item Joint likelihood can be written as
      \begin{itemize}
      \item $L(N,p;y,n) = p(y|n,p)p(n|N,p)$ or
      \item $L(N,p;y,n) = p(y,n|N,p)$
      \end{itemize}
  \end{itemize}
  \pause \vfill
  Data augmentation \\
  \begin{itemize}
    \item Tack on many ``all zero'' encounter histories and estimate
      how many of them actually occurred
    \item Likelihood-based
    \item Bayesian
  \end{itemize}
\end{frame}





\begin{frame}
  \frametitle{Joint likelihood, conditional-on-$n$}
  \small
  % State model                                                                   \\
  % \vspace{6pt}
  % {\centering
  %   There isn't one! $N$ is often treated as a constant, although we
  %   sometimes put a Poisson or binomial prior on it.                            \\
  % }
  % \pause
  % \vfill
  Another way of writing the observation model is to condition on the
  number of individuals captured, and then use a
  categorical distribution for the number of times individual $i$
  was detected. 
  \begin{gather*}
    n \sim \mathrm{Binomial}\left(N, 1-\pi_0\right)                               \\
    \tilde{y}_i \sim \mathrm{Categorical}(\pi_1, \dots, \pi_K) \;\;
    \mathrm{for}\, i=1,\dots,n 
  \end{gather*}
  \pause
%  \vfill
%  \scriptsize
  \centering
  \vspace{6pt}
  \begin{tabular}{ll}
    \hline
    Detections ($\tilde{y}_i$) & Multinomial cell probability                     \\
    \hline
%      0                       & $\pi_0 = (1-p)^J$                                \\
      1                        & $\pi_1 = Jp^{1}(1-p)^{J-1}/(1-\pi_0)$            \\
      2                        & $\pi_2 = {J\choose 2}p^{2}(1-p)^{J-2}/(1-\pi_0)$ \\
      $\cdots$                 & $\cdots$                                         \\
      J                        & $\pi_J = p^{J}/(1-\pi_0)$                        \\
      \hline
  \end{tabular}
  \flushleft
  \vspace{-6pt}
  where $\pi_0=(1-p)^J$ \\ 
  % \small
  \pause
  \vfill
  Definitions \\
  \scriptsize
  $N$ -- Population size                                                          \\
  $n$ -- Number of animals captured                                               \\
%  $p^*$ -- probability of being captured at least once
%  $y_{ij}$ -- encounter histories                                                \\
  $\tilde{y}_i=\sum_{j=1}^J y_{ij}$ -- number of times individual $i$ was encounter out of $J$
  occasions                                                                       \\
  $\pi_j$ -- Probability of capturing an individual $k$ times \\
  \pause
  \vfill
  This only works if $p$ doesn't change over time. 
\end{frame}



\begin{frame}
  \frametitle{Joint likelihood, conditional-on-$n$}
%  \frametitle{Conditional-on-$n$, multinomial cell probs}
  \footnotesize
  The more general formulation is in terms of the encounter histories,
  but there are many ($2^J-1$) of them.                                  \\
  \begin{gather*}
    n \sim \mathrm{Binomial}\left(N, 1-\pi_0\right)                      \\
    k_i \sim \mathrm{Categorical}(\pi_1, \dots, \pi_K) \;\;
    \mathrm{for}\, i=1,\dots,n                                           \\
    y_i = h_{k_i}
  \end{gather*}
  \pause \vfill
  Here's an example with $J=3$.                                          \\
%  \begin{columns}
%    \column{0.9\paperwidth}
  \scriptsize
  \vspace{6pt}
  \centering
    \begin{tabular}{lll}
      \hline
      $k$  & Capture history ($h$) & Multinomial cell probability        \\
      \hline
%      000 & $\pi_0 = \prod_j 1-p_j/(1-\pi_0)$                           \\
      1    & 100                   & $\pi_1=p_1(1-p_2)(1-p_3)/(1-\pi_0)$ \\
      2    & 010                   & $\pi_2=(1-p_1)p_2(1-p_3)/(1-\pi_0)$ \\
      3    & 001                   & $\pi_3=(1-p_1)(1-p_2)p_3/(1-\pi_0)$ \\
      4    & 110                   & $\pi_4=p_1p_2(1-p_3)/(1-\pi_0)$     \\
      5    & 101                   & $\pi_5=p_1(1-p_2)p_3/(1-\pi_0)$     \\
      6    & 011                   & $\pi_6=(1-p_1)p_2p_3/(1-\pi_0)$     \\
      7    & 111                   & $\pi_7 = p_1p_2p_3/(1-\pi_0)$       \\
      \hline
    \end{tabular}
    % \end{columns}
    \flushleft
  where $\pi_0=\prod_{j=1}^J 1-p_j$.                                     \\
\end{frame}




\begin{frame}
  \frametitle{Joint likelihood}
  % \footnotesize
  \small
  Rather than condition on $n$, we can maximize the ``unconditional''
  likelihood that includes the ``all zero'' encounter history,
  weighted $n_0=N-n$ times. 
  % \vfill
  % \centering
    % \begin{tabular}{ll}
    %   \hline
    %   Capture history ($h$) & Multinomial cell probability \\
    %   \hline
    %   000                   & $\pi_0 = \prod_j 1-p_j$      \\
    %   100                   & $\pi_1=p_1(1-p_2)(1-p_3)$    \\
    %   010                   & $\pi_2=(1-p_1)p_2(1-p_3)$    \\
    %   001                   & $\pi_3=(1-p_1)(1-p_2)p_3$    \\
    %   110                   & $\pi_4=p_1p_2(1-p_3)$        \\
    %   101                   & $\pi_5=p_1(1-p_2)p_3$        \\
    %   011                   & $\pi_6=(1-p_1)p_2p_3$        \\
    %   111                   & $\pi_7 = p_1p_2p_3$          \\
    %   \hline
    % \end{tabular}
  \pause
  \vfill
  \flushleft
  Likelihood function for this formulation
  \begin{equation*}
%  \begin{multline*}
%    L(N,p; y,n) =                                          \\
    L(N,p; y,n) = \left\{\prod_{i=1}^n \prod_{j=1}^J p^{y_{ij}}(1-p)^{1-y_{ij}}\right\}
%    \left\{\frac{N!}{(N-n)!}  \left(\prod_{j=1}^J(1-p)\right)^{N-n} \right\}
    \frac{N!}{(N-n)!}  \left(\pi_0\right)^{N-n}
%  \end{multline*}
  \end{equation*}
\end{frame}



\begin{frame}
  \frametitle{Model variations}
  Aside from of the approach to estimation, the key consideration
  concerns the sources of variation in capture probability ($p$). \\
  \pause
  \vfill
  Otis et al. (1978, Wildlife Monographs) identified several model variations
  \begin{itemize}
    \small
    \item $M_0$ -- $p$ is constant
    \item $M_t$ -- unique $p$ for each capture occasion
    \item $M_b$ -- behavioral response with $p$ different than
      recapture probability $c$
    \item $M_h$ -- individual heterogeneity in $p$
  \end{itemize}
  \pause \vfill
  These can be combined, but beware of identifiability issues. See
  Otis et al. (1978) for details. 
\end{frame}




\begin{frame}
  \frametitle{Software options}
  \small
  Program MARK
  \begin{itemize}
  \footnotesize
    \item Has the most model types
    \item Written for Windows, but can be executed on other platforms  
  \end{itemize}
  R package `RMark'
  \begin{itemize}
  \footnotesize
    \item Function \inr{mark} runs MARK from R.
  \end{itemize}
  R package `marked'
  \begin{itemize}
  \footnotesize
    \item Includes CJS and JS models
  \end{itemize}
  R package `mra'
  \begin{itemize}
  \footnotesize
    \item Includes closed-population, CJS, and JS models
  \end{itemize}
  R package Rcapture
  \begin{itemize}
  \footnotesize
    \item Includes closed-population
  \end{itemize}
  R package `unmarked'
  \begin{itemize}
  \footnotesize
    \item Likelihood-based data augmentation with \inr{occu}
  \end{itemize}
  R package `secr'
  \begin{itemize}
  \footnotesize
    \item Designed for spatially explicit models, but see \inr{closedN}
  \end{itemize}
\end{frame}




\section{Simulation}

%\section{Model $M_0$}


%\subsection{Simulation}


\subsection{Model $M_0$}




\begin{frame}
  \frametitle{Outline}
  \Large
%  \tableofcontents[currentsection,currentsubsection]
  \tableofcontents[currentsection]
\end{frame}







<<include=FALSE,echo=FALSE>>=
set.seed(34889243)
@ 

\begin{frame}[fragile]
  \frametitle{Model $M_0$}
  \small
  Parameters
  \vspace{-6pt}
<<sim-M0-pars,size='scriptsize'>>=
N <- 100
p <- 0.2
@
  \pause
  \vfill
  All capture histories (for captured and uncaptured individuals)
  \vspace{-6pt}
<<sim-M0-ch,size='scriptsize'>>=
J <- 4  ## Occasions
y.all <- matrix(NA, N, J)
for(i in 1:N) {
    y.all[i,] <- rbinom(J, 1, p)
}
@
  \pause
  \vfill
  Observed capture histories (data)
  \vspace{-6pt}
<<sim-M0-y1,size='scriptsize'>>=
captured <- rowSums(y.all)>0
(n <- sum(captured))
y <- y.all[captured,]
y[1:3,]
@ 
\end{frame}



\begin{frame}[fragile]
  \frametitle{Summary stats}
  Capture history frequencies
<<M0-hist,size='scriptsize'>>=
histories <- apply(y, 1, paste, collapse="")
sort(table(histories))
@
\pause
\vfill
  Detection frequencies
<<M0-freq,size='scriptsize'>>=
y.tilde <- rowSums(y)
frequencies <- table(y.tilde)
frequencies
@   
\end{frame}



\subsection{Model $M_t$}


\begin{frame}[fragile]
  \frametitle{Model $M_t$ -- Temporal variation}
  Capture probability for each occasion
<<sim-Mt-pars,size='scriptsize'>>=
p.t <- c(0.3, 0.5, 0.2, 0.4)
@
  \pause
  \vfill
  All capture histories (for captured and uncaptured individuals)
  \vspace{-6pt}
<<sim-Mt-ch,size='scriptsize'>>=
y.all.Mt <- matrix(NA, N, J)
for(i in 1:N) {
    y.all.Mt[i,] <- rbinom(J, 1, p.t) }
@
  \pause
  \vfill
  Observed capture histories (data)
  \vspace{-6pt}
<<sim-Mt-y1,size='scriptsize'>>=
captured.Mt <- rowSums(y.all.Mt)>0
n.Mt <- sum(captured.Mt)
y.Mt <- y.all.Mt[captured.Mt,]
y.Mt[1:3,]
colSums(y.Mt)
@ 
\end{frame}



\subsection{Model $M_b$}

\begin{frame}[fragile]
  \frametitle{Model $M_b$ -- Behavioral response}
  Capture probability for each occasion
<<sim-Mb-pars,size='scriptsize'>>=
p.b <- 0.3
c <- 0.5  ## Trap happy
@
  \pause
  \vfill
  All capture histories (for captured and uncaptured individuals)
  \vspace{-6pt}
<<sim-Mb-ch,size='scriptsize'>>=
y.all.Mb <- matrix(NA, N, J)
prevcap <- matrix(FALSE, N, J)
for(i in 1:N) {
    y.all.Mb[i,1] <- rbinom(1, 1, p.b)
    for(j in 2:J) {
        prevcap[i,j] <- any(y.all.Mb[i,1:(j-1)]>0)
        prob <- ifelse(prevcap[i,j], c, p.b)
        y.all.Mb[i,j] <- rbinom(1, 1, prob)
    }
}
@
  \pause
  \vfill
  Observed capture histories (data)
  \vspace{-6pt}
<<sim-Mb-y1,size='scriptsize'>>=
captured.Mb <- rowSums(y.all.Mb)>0
n.Mb <- sum(captured.Mb)
y.Mb <- y.all.Mb[captured.Mb,]
## prevcap[1:3,]
@ 
\end{frame}



\subsection{Model $M_h$}


\begin{frame}[fragile]
  \frametitle{Model $M_h$ -- Individual heterogeneity}
  There are many flavors of $M_h$. Some use finite mixture
  models. Here we have logit-normal distribution for $p$. 
<<sim-Mh-pars,size='scriptsize'>>=
logit.p.bar <- -1  ## Mean p on logit scale
logit.p.var <- 1   ## SD of p on logit scale
p.h <- plogis(rnorm(N, logit.p.bar, logit.p.var))
@
  \pause
  \vfill
  All capture histories (for captured and uncaptured individuals)
  \vspace{-6pt}
<<sim-Mh-ch,size='scriptsize'>>=
y.all.Mh <- matrix(NA, N, J)
for(i in 1:N) {
    y.all.Mh[i,] <- rbinom(J, 1, p.h[i])
}
@
  \pause
  \vfill
  Observed capture histories (data)
  \vspace{-6pt}
<<sim-Mh-y1,size='scriptsize'>>=
captured.Mh <- rowSums(y.all.Mh)>0
n.Mh <- sum(captured.Mh)
y.Mh <- y.all.Mh[captured.Mh,]
#y.Mh[1:3,]
@ 
\end{frame}





\section{Joint likelihood}



\begin{frame}
  \frametitle{Outline}
  \Large
  \tableofcontents[currentsection]
\end{frame}


%% p(y,n|N,p)
\begin{frame}[fragile]
  \frametitle{Joint likelihood for $M_0$}
  The joint likelihood is
  \begin{multline*}
    L(N,p; y,n) = \\
    \left\{\prod_{i=1}^n \prod_{j=1}^J p^{y_{ij}}(1-p)^{1-y_{ij}}\right\}
    \left\{\frac{N!}{(N-n)!}  \left(\prod_{j=1}^J(1-p)\right)^{N-n} \right\}
  \end{multline*}
  \pause
  \vfill
<<nll-M0,echo=TRUE,size='scriptsize'>>=
nll.M0 <- function(pars, y) {
    n <- nrow(y);       J <- ncol(y)
    N <- exp(pars[1])
    n0 <- N-n
    if(n0<0) return(NA)
    p <- plogis(pars[2])
    ld.y1 <- sum(dbinom(y, 1, p, log=TRUE))
    p0 <- (1-p)^J
    ld.n0 <- lgamma(N+1)-lgamma(n0+1)+n0*log(p0)
    nll <- -(ld.y1+ld.n0)
    return(nll)
}
@
\end{frame}



\begin{frame}[fragile]
  \frametitle{Maximize joint likelihood for $M_0$}
Minimized the negative log-likelihood
<<opt-nll-M0, size='scriptsize'>>=
fm.M0 <- optim(c(log.N=4,logit.p=0), nll.M0, y=y, hessian=TRUE)
fm.M0.est <- data.frame(Estimate=c(fm.M0$par[1], fm.M0$par[2]),
                        SE=sqrt(diag(solve(fm.M0$hessian))))
fm.M0.est
@
\pause
\vfill
Back-transform the estimates
<<opt-nll-M0-back, size='scriptsize'>>=
c(N.hat=exp(fm.M0$par[1]), p.hat=plogis(fm.M0$par[2]))
@
\pause
\vfill
Compare to data-generating values
<<dg,size='scriptsize'>>=
c(N=N, p=p)
@ 
\end{frame}





%% p(y|n,p)p(n|N,p)
<<eval=FALSE,include=FALSE,echo=FALSE>>=
nll.M0.2 <- function(pars, y) {
    n <- nrow(y);       J <- ncol(y)
    N <- exp(pars[1])
    n0 <- N-n
    if(n0<0) return(NA)
    p <- plogis(pars[2])
    J <- ncol(y)
    p.star <- 1-(1-p)^J
    ydot <- rowSums(y)
    lcd.y <- sum(dbinom(ydot, J, p, log=TRUE)-log(p.star))
    ld.n <- lchoose(N, n)+n*log(p.star)+n0*log(1-p.star)
    nll <- -(lcd.y+ld.n)
    return(nll)
}

fm.M0.2 <- optim(c(5,0), nll.M0.2, y=y, hessian=TRUE)
c(N=exp(fm.M0.2$par[1]), p=plogis(fm.M0.2$par[2]))
@ 



%% p(y|n,p)
<<eval=FALSE,include=FALSE,echo=FALSE>>=
nll.M0.cn <- function(pars, y) {
    p <- plogis(pars[1])
    J <- ncol(y)
    p.star <- 1-(1-p)^J
    ydot <- rowSums(y)
    nll <- -sum(dbinom(ydot, J, p, log=TRUE)-log(p.star))
    return(nll)
}

fm.M0.cn <- optim(0, nll.M0.cn, y=y, hessian=TRUE, method="Brent", lower=-10, upper=10)
c(p=plogis(fm.M0.cn$par[1]))
@ 




\begin{frame}[fragile]
  \frametitle{R package `Rcapture'}
<<Rcapture,size='scriptsize'>>=
## install.packages("Rcapture")
library(Rcapture)
closedp(y)
@   
\end{frame}




\begin{frame}[fragile]
  \frametitle{R package `mra'}
<<mra,size='scriptsize'>>=
## install.packages("mra")
library(mra)
F.huggins.estim(~1, histories=y)
@   
\end{frame}



\begin{frame}
  \frametitle{R package `RMark'}
  Before you can use `RMark', you have to install MARK.  \\
  \vfill
  The main MARK page is here: \\
  \url{http://www.phidot.org/software/mark/index.html}  \\
  \vfill
  Instructions for Linux and Mac users: \\
  \url{http://www.phidot.org/software/mark/rmark/linux/}
\end{frame}



\begin{frame}[fragile]
  \frametitle{R package `RMark' -- Model $M_0$}
  \small
  Fit model and set capture probability equal to recapture probability
  ($p=c$) using the \inr{share=TRUE} argument.
<<RMark,size='scriptsize',warning=FALSE,results='hide',cache=TRUE>>=
## install.packages("RMark") ## Must install MARK TOO!!
library(RMark)
y.ch <- data.frame(ch=apply(y, 1, paste, collapse=""))
mark.M0 <- mark(data=y.ch, model="Closed", silent=TRUE,
                model.parameters=list(p=list(formula=~1,share=TRUE)))
@
\pause
\vfill
Estimates of $p$ and $n_0$ (called $f_0$ in MARK)
<<RMark-pn0,size='scriptsize'>>=
mark.M0$results$real      
@   
\pause
\vfill
Estimate of $N$ 
<<RMark-N,size='scriptsize'>>=
mark.M0$results$derived   
@   
\end{frame}





\begin{frame}[fragile]
  \frametitle{R package `RMark' -- Model $M_t$}
<<RMark-Mt,size='scriptsize',warning=FALSE,results='hide',cache=TRUE>>=
yt.ch <- data.frame(ch=apply(y.Mt, 1, paste, collapse=""))
mark.Mt <- mark(data=yt.ch, model="Closed", silent=TRUE,
                model.parameters=list(p=list(formula=~time,share=TRUE)))
@
\pause
\vfill
Estimates of $p_j$ and $n_0$ (called $f_0$ in MARK)
<<RMark-pn0-Mt,size='scriptsize'>>=
mark.Mt$results$real      
@   
\pause
\vfill
Estimate of $N$ 
<<RMark-N-Mt,size='scriptsize'>>=
mark.Mt$results$derived   
@   
\end{frame}





\begin{frame}[fragile]
  \frametitle{R package `RMark' -- Model $M_b$}
<<RMark-Mb,size='scriptsize',warning=FALSE,results='hide',cache=TRUE>>=
yb.ch <- data.frame(ch=apply(y.Mb, 1, paste, collapse=""))
mark.Mb <- mark(data=yb.ch, model="Closed", silent=TRUE) ## Default model
@
\pause
\vfill
Estimates of $p$, $c$, and $n_0$ (called $f_0$ in MARK)
<<RMark-pn0-Mb,size='scriptsize'>>=
mark.Mb$results$real      
@   
\pause
\vfill
Estimate of $N$ 
<<RMark-N-Mb,size='scriptsize'>>=
mark.Mb$results$derived   
@   
\end{frame}















\section{Data augmentation}


%\section{Prediction}
%\subsection{Likelihood-based inference}


\begin{frame}
  \frametitle{Outline}
  \Large
  \tableofcontents[currentsection]
\end{frame}



\begin{frame}
  \frametitle{Data augmentation}
  Data augmentation is strange \\
  \pause
  \vfill
  We add ``all zero'' capture histories to our data, then we try to
  estimate how many of them are real. \\ 
  \pause
  \vfill
  The total number of observed and agumented encounter histories is
  $M$. \\
  \pause
  \vfill
  We define the model in terms of a binary indicator variable $z_i$,
  such that $N=\sum_{i=1}^M z_i$. \\
  \pause
  \vfill
  We know $z_i=1$ for the $n$ captured individuals. \\
\end{frame}




\begin{frame}
  \frametitle{Data augmentation model}
  The model is:
  \begin{gather*}
    z_i \sim \mathrm{Bern}(\psi) \\
    y_{ij} \sim \mathrm{Bern}(z_i p_{ij}) \\
    N=\sum_{i=1}^M z_i
  \end{gather*}
  \pause \vfill
  % A uniform prior on $\psi$ results in a discrete uniform prior on
  % $N$. We can change the prior for $N$ by changing the prior on
  % $\psi$, recognizing that $E(N)=M\psi$.
  Note that this looks exactly like an occupancy model. \\
  \pause \vfill
  But why do this?
  \begin{itemize}
    \item DA works for \alert{all} varieties of mark-recapture model
    \item It make it easy to incorporate
      individual-covariates\dots\pause including distance and
      location!   
  \end{itemize}
\end{frame}




\subsection{Likelihood-based data augmentation}


\begin{frame}[fragile]
  \frametitle{Likelihood-based data augmentation}
  \small
  Normally, DA is used with Bayesian inference, but since it's exactly
  the same model as a single-season occupancy model, we can also fit
  it in `unmarked'.
  \pause
  \vfill
  First, let's augment the data simulated under model $M_b$, with
  $M=200$. 
<<aug-y,size='scriptsize'>>=
M <- 200
y.aug <- matrix(0, M, J)
y.aug[1:nrow(y.Mb),] <- y.Mb
@
\pause
\vfill
We also need to augment the \inr{prevcap} object.
<<un-prevcap,size='scriptsize'>>=
prevcap.aug <- matrix(FALSE, M, J)
prevcap.aug[1:nrow(y.Mb),] <- prevcap[captured.Mb,]
prevcap.aug <- ifelse(prevcap.aug, "Yes", "No")
@
And we need a covariate indicating time (occasion)
<<un-occ,size='scriptsize'>>=
occasion.aug <- matrix(as.character(1:J), M, J, byrow=TRUE)
@ 
\end{frame}


\begin{frame}[fragile]
  \frametitle{Model $M_0$ with `unmarked'}
  \small
  Create the unmarked frame
<<un-umf,results='hide',size='scriptsize',warning=FALSE>>=
library(unmarked)
umf <- unmarkedFrameOccu(y=y.aug,
                         obsCovs=list(prevcap=prevcap.aug,
                                      occasion=occasion.aug))
@   
  Fit the model  
<<un-M0,size='scriptsize'>>=
fm.M0 <- occu(~1~1, umf)
fm.M0
@   
\end{frame}



\begin{frame}[fragile]
  \frametitle{Model $M_t$ with `unmarked'}
<<un-Mt,size='scriptsize'>>=
fm.Mt <- occu(~occasion~1, umf)
fm.Mt
@   
\end{frame}



\begin{frame}[fragile]
  \frametitle{Model $M_b$ with `unmarked'}
<<un-Mb,size='scriptsize'>>=
fm.Mb <- occu(~prevcap~1, umf)
fm.Mb
@   
\end{frame}


\begin{frame}[fragile]
  \frametitle{But how do we compute $N$?}
  First we compute Empirical Bayes posterior probability that each
  individual was ``real''. 
<<un-re,size='small'>>=
re.M0 <- ranef(fm.M0)
re.Mt <- ranef(fm.Mt)
re.Mb <- ranef(fm.Mb)
@
\pause
\vfill
Then we predict $N$, which can be thought of as the number of real
individuals in the set of $M$ guys.
<<un-N,size='small'>>=
N.post.M0 <- predict(re.M0, func=sum, nsim=1000)
N.post.Mt <- predict(re.Mt, func=sum, nsim=1000)
N.post.Mb <- predict(re.Mb, func=sum, nsim=1000)
@ 
\end{frame}



\begin{frame}[fragile]
  \frametitle{Empirical Bayes posteriors of $N$}
<<un-N-post, size='tiny',fig.height=3,out.width="100%",fig.show='hide', echo=-1>>=
par(mfrow=c(1,3), mai=c(0.7,0.7,0.6,0.1))
plot(table(N.post.M0), xlab="N", ylab="Posterior probability", main="M0",
     xlim=c(75, 130), ylim=c(0,150)); abline(v=N, col="red")
plot(table(N.post.Mt), xlab="N", ylab="Posterior probability", main="Mt",
     xlim=c(75, 130), ylim=c(0,150)); abline(v=N, col="red")
plot(table(N.post.Mb), xlab="N", ylab="Posterior probability", main="Mb",
     xlim=c(75, 130), ylim=c(0,150)); abline(v=N, col="red")
@
  \begin{columns}
    \begin{column}{\paperwidth}
      \includegraphics[width=\paperwidth]{figure/un-N-post-1}
    \end{column}
  \end{columns}
\end{frame}





\subsection{Bayesian data augmentation}





% \begin{frame}[fragile]
%   \frametitle{Prepare data in `unmarked'}
%   \small
%   Note the new arguments.
%   \vspace{-6pt}
% <<un-umf,size='tiny'>>=
% umf <- unmarkedFrameDS(y=y2, siteCovs=data.frame(elevation,noise), dist.breaks=b,
%                        tlength=rep(L, nSites), survey="line", unitsIn="m")
% @
% \pause
% <<wfac,size='tiny'>>=
% summary(umf)
% @ 
% \end{frame}



% \begin{frame}[fragile]
%   \frametitle{Fit the model}
%   \footnotesize
% <<un-fit,size='tiny'>>=
% ## fm <- distsamp(~noise ~elevation, umf, keyfun="exp")     # negative exp
% ## fm <- distsamp(~noise ~elevation, umf, keyfun="hazard")  # hazard rate
% fm <- distsamp(~noise ~elevation, umf, keyfun="halfnorm")   # half-normal
% fm
% @
% \pause
% \vfill
% Compare to actual parameter values:
% \vspace{-6pt}
% <<un-compare,size='tiny'>>=
% c(beta0=beta0, beta1=beta1); c(alpha0=alpha0, alpha1=alpha1)
% @ 
% \end{frame}







%\subsection{Bayesian inference}


\begin{frame}
  \frametitle{Outline}
  \Large
  \tableofcontents[currentsection,currentsubsection]
\end{frame}





% \begin{frame}[fragile]
%   \frametitle{\normalsize Conditional-on-$N$ and $n_i=\sum_{j=1}^{J} y_{i,j}$}
% \vspace{-3pt}
% <<bugs-line,size='tiny',echo=FALSE>>=
% writeLines(readLines("distsamp-line-mod.jag"))
% @
% \end{frame}





% \begin{frame}[fragile]
%   \frametitle{Data, inits, and parameters}
%   Put data in a named list
%   \vspace{-12pt}
% <<bugs-data2,size='footnotesize'>>=
% jags.data.line <- list(y=y2, n=rowSums(y2),
%                        b=b,           # Distance break points
%                        psi=diff(b)/B, # Pr(occuring in bin j)
%                        elevation=elevation, noise=noise,
%                        nSites=nSites, nBins=J)
% @
% \pause
% \vfill
%   Initial values
%   \vspace{-12pt}
% <<bugs-inits,size='footnotesize'>>=
% jags.inits.line <- function() {
%     list(lambda.intercept=runif(1), alpha0=rnorm(1, 5),
%          N=rowSums(y2)+rpois(nrow(y2), 2))
% }
% @ 
% \pause
% \vfill
%   Parameters to monitor
%   \vspace{-12pt}
% <<bugs-pars,size='small'>>=
% jags.pars.line <- c("beta0", "beta1",
%                     "alpha0", "alpha1", "totalAbundance")
% @ 
% \end{frame}





% \begin{frame}[fragile]
%   \frametitle{MCMC}
%   \small
% <<bugs-mcmc-line,size='scriptsize',message=FALSE,cache=TRUE,results='hide'>>=
% library(jagsUI)
% jags.post.line <- jags.basic(data=jags.data.line, inits=jags.inits.line,
%                              parameters.to.save=jags.pars.line,
%                              model.file="distsamp-line-mod.jag",
%                              n.chains=3, n.adapt=100, n.burnin=0,
%                              n.iter=2000, parallel=TRUE)
% @ 
% \vfill
% <<jags-sum-line,size='scriptsize',cache=TRUE>>=
% round(summary(jags.post.line)$quantile, digits=3)
% @ 
% \end{frame}


% \begin{frame}[fragile]
%   \frametitle{Traceplots and density plots}
% <<bugs-plot1-rem2,size='footnotesize',out.width="0.7\\textwidth",fig.align='center',cache=TRUE>>=
% plot(jags.post.line[,jags.pars.line[1:3]])
% @ 
% \end{frame}



% \begin{frame}[fragile]
%   \frametitle{Traceplots and density plots}
% <<bugs-plot2-rem2,size='footnotesize',out.width="0.7\\textwidth",fig.align='center',cache=TRUE>>=
% plot(jags.post.line[,jags.pars.line[4:5]])
% @ 
% \end{frame}






% \section{Models $M_t$, $M_b$, $M_h$}


% \subsection{Simulation}


% \subsection{Joint Likelihood}

% \subsection{Likelihood-based data augmentation}


% \subsection{Bayesian data augmentation}





%\section{Summary}


\begin{frame}
  \frametitle{Mark-recapture summary}
  Assumptions
  \begin{itemize}
    \small
    \item Animals don't move during the survey
    \item Animals are uniformly distributed with respect to the
      transects
    \item Detection is certain on the transect, i.e. $p=1$ when $x=0$. 
    \item Detections are independent
  \end{itemize}
  \pause
  \vfill
  \small
  If these assumptions can be met, distance sampling is a powerful
  method allowing for inference about abundance and density using data
  from a single visit. \\
\end{frame}




\section{Assignment}




\begin{frame}[fragile]
  \frametitle{Assignment}
  % \small
  \footnotesize
  Create a self-contained R script or Rmarkdown file to do the following:
  \vfill
  \begin{enumerate}
%    \small
    \footnotesize
    \item Fit a distance sampling model with a half-normal detection
      function and the following covariates to the black-throated blue
      warbler data ({\tt btbw\_data\_distsamp.csv}) in `unmarked' and
      `JAGS':   
      \begin{itemize}
        \footnotesize
        \item Density covariates: {\tt Elevation, UTM.N, UTM.W}
        \item Detection covariates: {\tt Wind, Noise}
        \item Response: {\scriptsize \tt btbw0\_20, btbw20\_40, btbw40\_60, btbw60\_80, btbw80\_100}
      \end{itemize}
    \item Using the model fitted in `unmarked', create two graphs of
      the predictions, one for density and the other for the scale
      parameter ($\sigma$).
    \item Compare the half-normal model to two other models with the
      same covariates, but with negative exponential and hazard
      rate detection functions. Which has the lowest AIC? 
  \end{enumerate}
  \pause
  \vfill
  Suggestions:
  \begin{itemize}
    \item Convert response variables to matrix with \inr{as.matrix}
    \item Standardize covariates
  \end{itemize}
  \pause
  \vfill
  Upload your {\tt .R} or {\tt .Rmd} file to ELC before Tuesday. 
\end{frame}





\end{document}

