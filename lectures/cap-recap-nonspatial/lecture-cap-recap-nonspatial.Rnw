\documentclass[color=usenames,dvipsnames]{beamer}
%\documentclass[color=usenames,dvipsnames,handout]{beamer}

\usepackage[roman]{../lectures}
%\usepackage[sans]{../lectures}


\hypersetup{pdfpagemode=UseNone,pdfstartview={FitV}}



% Load function to compile and open PDF
<<build-fun,include=FALSE,purl=FALSE>>=
source("../rnw2pdf.R")
@

% Compile and open PDF
<<buildit,include=FALSE,eval=FALSE>>=
rnw2pdf("lecture-cap-recap-nonspatial")
rnw2pdf("lecture-cap-recap-nonspatial", tangle=TRUE)
@ 


<<knitr-theme,include=FALSE,purl=FALSE>>=
knit_theme$set("edit-kwrite")
@


% New command for inline code that isn't to be evaluated
\definecolor{inlinecolor}{rgb}{0.878, 0.918, 0.933}
\newcommand{\inr}[1]{\colorbox{inlinecolor}{\texttt{#1}}}




\begin{document}




\begin{frame}[plain]
  \LARGE
  \centering
  {
    \LARGE Lecture 10 -- Non-spatial mark-recapture \\ for estimating
    population size: \\
    \Large simulation, fitting, and prediction \\
  }
  {\color{default} \rule{\textwidth}{0.1pt} }
  \vfill
  \large
  WILD(FISH) 8390 \\
  Estimation of Fish and Wildlife Population Parameters \\
  \vfill
  \large
  Richard Chandler \\
  University of Georgia \\
\end{frame}






\section{Overview}



\begin{frame}[plain]
  \frametitle{Outline}
  \Large
  \only<1>{\tableofcontents}%[hideallsubsections]}
  \only<2 | handout:0>{\tableofcontents[currentsection]}%,hideallsubsections]}
\end{frame}



\begin{frame}
  \frametitle{Mark-recapture overview}
  Until now, we've focused on models for data on aggregated quantities
  like abundance and occupancy. \\ 
  \pause
  \vfill
  Now we will talk about data on uniquely identifable individuals. \\
  \pause
  \vfill
  This is nice because all individuals are different, and we're often
  interested in these differences\dots \\
  \pause
  \vfill
  \dots even when our primary goal is
  inference on population-level parameters like abundance
  and density. \\
\end{frame}



\begin{frame}
  \frametitle{Mark-recapture overview}
  The simplest estimator of abundance is 
  \[
    \hat{N} = \frac{n}{\hat{p}}
  \]
  where $n$ is the number of individuals detected, $p$ is detection
  probability, and $E(n)=Np$. \\
  \pause
  \vfill
  In distance sampling, we modeled detection probability as a
  function of distance, and, we replaced $p$ with average detection
  probability. \\ 
  \pause
  \vfill
  For the simplest mark-recapture problems, $p$ is a constant and we
  estimate it by trapping on multiple occasions and marking and
  recapturing as we go.  
\end{frame}





\begin{frame}
  \frametitle{Mark-recapture data}
  \small
  Mark-recapture data are often called ``capture histories.'' Here's
  an example with $n=6$ animals captured on $J=3$ occasions. \\
  \centering
%  \vfill  
  \begin{tabular}{lccc}
    \hline
    & \multicolumn{3}{c}{Occasion} \\
    \cline{2-4}
    Individual & 1 & 2 & 3 \\
    \hline
    1 & 0 & 0 & 1 \\
    2 & 1 & 1 & 1 \\
    3 & 0 & 1 & 0 \\
    4 & 0 & 1 & 1 \\
    5 & 1 & 0 & 0 \\
    6 & 0 & 0 & 1 \\
    \hline
  \end{tabular}
  \pause
  \vfill
  \flushleft
  How do we estimate $p$ (and $N$) from these data? %\\
  \pause
%  \vfill
  You can get a sense for $p$ (and $N$) by looking at the data.
  \begin{itemize}
    \setlength\itemsep{.1pt}
    \item If $p$ was close to 1, most individuals would be captured
      on all 3 occasions
    \item If $p$ was close to 0, few individuals would be captured on
      more than one occasion
  \end{itemize}
\end{frame}




% \begin{frame}
%   \frametitle{In-class exercise}
%   Building off the previous example\dots
%   \begin{enumerate}
%     \item Compute $\bar{p}$ for line-transect sampling when
%       $\sigma=50, 100, \mathrm{and}\, 200$, instead of $\sigma=25$.  
%     \item Repeat, but for point-transect sampling. 
%   \end{enumerate}
% \end{frame}





\begin{frame}
  \frametitle{Classical approaches}
  Lincoln-Peterson  \\
  \pause
  \vfill
  Closed population models \\
\end{frame}






\begin{frame}
  \frametitle{Basic model}
  \small
  State model \\
  {\centering
    There isn't one! $N$ is often treated as a constant. \\
  }
  \pause
  \vfill
  Observation model
  \begin{gather*}
    n \sim \mathrm{Bin}(N, p^*) \\
    y \sim \mathrm{Multinomial}()
  \end{gather*}
  \pause
  \small
  Definitions \\
  $N$ -- Population size \\
  $n$ -- Number of animals captured \\
  $y_{ij}$ -- count for distance bin $j$ (final count is unobserved) \\
\end{frame}



\begin{frame}
  \frametitle{Estimation options}
  
\end{frame}


\begin{frame}
  \frametitle{Software options}
  
\end{frame}




%\section{Simulation}

\section{Model $M_0$}


\subsection{Simulation}




\begin{frame}
  \frametitle{Outline}
  \Large
%  \tableofcontents[currentsection,currentsubsection]
  \tableofcontents[currentsection]
\end{frame}



\begin{frame}
  \frametitle{Multinomial cell probs}
  \small
  Definitions needed for computing \alert{bin-specific} $\bar{p}$ and
  multinomial cell probabilities. 
  \begin{itemize}
  \small
    \setlength\itemsep{1pt}
    \item $y_{ij}$ -- number of individuals detected at site $i$ in bin $j$
  \end{itemize}
  \pause \vfill
  \footnotesize
  \begin{columns}
    \column{0.9\paperwidth}
    \begin{tabular}{lc}
      \hline
      \centering
      Capture history                 & Multinomial cell probability \\
      \hline
      100  & $p_1(1-p)(1-p)$   \\
        & $\pi_2 = \psi_2\bar{p}_2$   \\
      111  & $\pi_J = \psi_J\bar{p}_J$   \\
      000                  & $\pi_{K} = 1-\sum_{j=1}^J \pi_j$          \\
      \hline
    \end{tabular}
  \end{columns}
\end{frame}






<<include=FALSE,echo=FALSE>>=
set.seed(34889243)
@ 

\begin{frame}[fragile]
  \frametitle{Model $M_0$}
  \small
  Parameters
  \vspace{-6pt}
<<sim-M0-pars,size='scriptsize'>>=
N <- 100
p <- 0.2
@
  \pause
  \vfill
  All capture histories (for captured and uncaptured individuals)
  \vspace{-6pt}
<<sim-N0-ch,size='scriptsize'>>=
J <- 4  ## Occasions
y.all <- matrix(NA, N, J)
for(i in 1:N) {
    y.all[i,] <- rbinom(J, 1, p)
}
@
  \pause
  \vfill
  Observed capture histories (data)
  \vspace{-6pt}
<<sim-hds-y1,size='scriptsize'>>=
captured <- rowSums(y.all)>0
(n <- sum(captured))
y <- y.all[captured,]
y[1:3,]
@ 
\end{frame}



\begin{frame}[fragile]
  \frametitle{Capture history frequencies}
  \centering
<<M0-hist,size='scriptsize'>>=
histories <- apply(y, 1, paste, collapse="")
sort(table(histories))
@   
<<M0-freq,size='scriptsize'>>=
frequencies <- table(rowSums(y))
frequencies
@   
\end{frame}



\section{Joint likelihood}


\begin{frame}[fragile]
  \frametitle{Joint likelihood}
  The joint likelihood is
  \begin{multline*}
    L(N,p; y,n) = \\
    \prod_{i=1}^n \prod_{j=1}^J p^{y_{ij}}(1-p)^{1-y_{ij}}
    \left\{\frac{N!}{(N-n)!}  \left(\prod_{j=1}^J(1-p)\right)^{N-n} \right\}
  \end{multline*}
  \pause
  \vfill
<<nll-M0,echo=TRUE,size='scriptsize'>>=
nll.M0 <- function(pars, y) {
    n <- nrow(y);       J <- ncol(y)
    N <- exp(pars[1])
    n0 <- N-n
    if(n0<0) return(NA)
    p <- plogis(pars[2])
    ld.y1 <- sum(dbinom(y, 1, p, log=TRUE))
    p0 <- (1-p)^J
    ld.n0 <- lgamma(N+1)-lgamma(n0+1)+n0*sum(log(p0))
    nll <- -(ld.y1+ld.n0)
    return(nll)
}
@
\end{frame}



\begin{frame}[fragile]
  \frametitle{Joint likelihood}
Minimized the negative log-likelihood
\pause
\vfill
<<opt-nll-M0, size='scriptsize'>>=
fm.M0 <- optim(c(log.N=4,logit.p=0), nll.M0, y=y, hessian=TRUE)
fm.M0.est <- data.frame(Estimate=c(fm.M0$par[1], fm.M0$par[2]),
                        SE=sqrt(diag(solve(fm.M0$hessian))))
fm.M0.est
@
\pause
\vfill
Back-transform the estimates
<<opt-nll-M0-back, size='scriptsize'>>=
c(N.hat=exp(fm.M0$par[1]), p.hat=plogis(fm.M0$par[2]))
@ 

\end{frame}



<<eval=FALSE,include=FALSE,echo=FALSE>>=
nll.M0.cn <- function(pars, y) {
    p <- plogis(pars[1])
    J <- ncol(y)
    p.star <- 1-(1-p)^J
    ydot <- rowSums(y)
    nll <- -sum(dbinom(ydot, J, p, log=TRUE)-log(p.star))
    return(nll)
}

fm.M0.cn <- optim(0, nll.M0.cn, y=y, hessian=TRUE, method="Brent", lower=-10, upper=10)
c(p=plogis(fm.M0.cn$par[1]))
@ 




\section{Data augmentation}


%\section{Prediction}
%\subsection{Likelihood-based inference}


\begin{frame}
  \frametitle{Outline}
  \Large
  \tableofcontents[currentsection]
\end{frame}


\subsection{Likelihood-based data augmentation}


\subsection{Bayesian data augmentation}





% \begin{frame}[fragile]
%   \frametitle{Prepare data in `unmarked'}
%   \small
%   Note the new arguments.
%   \vspace{-6pt}
% <<un-umf,size='tiny'>>=
% umf <- unmarkedFrameDS(y=y2, siteCovs=data.frame(elevation,noise), dist.breaks=b,
%                        tlength=rep(L, nSites), survey="line", unitsIn="m")
% @
% \pause
% <<wfac,size='tiny'>>=
% summary(umf)
% @ 
% \end{frame}



% \begin{frame}[fragile]
%   \frametitle{Fit the model}
%   \footnotesize
% <<un-fit,size='tiny'>>=
% ## fm <- distsamp(~noise ~elevation, umf, keyfun="exp")     # negative exp
% ## fm <- distsamp(~noise ~elevation, umf, keyfun="hazard")  # hazard rate
% fm <- distsamp(~noise ~elevation, umf, keyfun="halfnorm")   # half-normal
% fm
% @
% \pause
% \vfill
% Compare to actual parameter values:
% \vspace{-6pt}
% <<un-compare,size='tiny'>>=
% c(beta0=beta0, beta1=beta1); c(alpha0=alpha0, alpha1=alpha1)
% @ 
% \end{frame}







%\subsection{Bayesian inference}


\begin{frame}
  \frametitle{Outline}
  \Large
  \tableofcontents[currentsection,currentsubsection]
\end{frame}





% \begin{frame}[fragile]
%   \frametitle{\normalsize Conditional-on-$N$ and $n_i=\sum_{j=1}^{J} y_{i,j}$}
% \vspace{-3pt}
% <<bugs-line,size='tiny',echo=FALSE>>=
% writeLines(readLines("distsamp-line-mod.jag"))
% @
% \end{frame}





% \begin{frame}[fragile]
%   \frametitle{Data, inits, and parameters}
%   Put data in a named list
%   \vspace{-12pt}
% <<bugs-data2,size='footnotesize'>>=
% jags.data.line <- list(y=y2, n=rowSums(y2),
%                        b=b,           # Distance break points
%                        psi=diff(b)/B, # Pr(occuring in bin j)
%                        elevation=elevation, noise=noise,
%                        nSites=nSites, nBins=J)
% @
% \pause
% \vfill
%   Initial values
%   \vspace{-12pt}
% <<bugs-inits,size='footnotesize'>>=
% jags.inits.line <- function() {
%     list(lambda.intercept=runif(1), alpha0=rnorm(1, 5),
%          N=rowSums(y2)+rpois(nrow(y2), 2))
% }
% @ 
% \pause
% \vfill
%   Parameters to monitor
%   \vspace{-12pt}
% <<bugs-pars,size='small'>>=
% jags.pars.line <- c("beta0", "beta1",
%                     "alpha0", "alpha1", "totalAbundance")
% @ 
% \end{frame}





% \begin{frame}[fragile]
%   \frametitle{MCMC}
%   \small
% <<bugs-mcmc-line,size='scriptsize',message=FALSE,cache=TRUE,results='hide'>>=
% library(jagsUI)
% jags.post.line <- jags.basic(data=jags.data.line, inits=jags.inits.line,
%                              parameters.to.save=jags.pars.line,
%                              model.file="distsamp-line-mod.jag",
%                              n.chains=3, n.adapt=100, n.burnin=0,
%                              n.iter=2000, parallel=TRUE)
% @ 
% \vfill
% <<jags-sum-line,size='scriptsize',cache=TRUE>>=
% round(summary(jags.post.line)$quantile, digits=3)
% @ 
% \end{frame}


% \begin{frame}[fragile]
%   \frametitle{Traceplots and density plots}
% <<bugs-plot1-rem2,size='footnotesize',out.width="0.7\\textwidth",fig.align='center',cache=TRUE>>=
% plot(jags.post.line[,jags.pars.line[1:3]])
% @ 
% \end{frame}



% \begin{frame}[fragile]
%   \frametitle{Traceplots and density plots}
% <<bugs-plot2-rem2,size='footnotesize',out.width="0.7\\textwidth",fig.align='center',cache=TRUE>>=
% plot(jags.post.line[,jags.pars.line[4:5]])
% @ 
% \end{frame}






\section{Models $M_t$, $M_b$, $M_h$}


\subsection{Simulation}


\subsection{Joint Likelihood}

\subsection{Likelihood-based data augmentation}


\subsection{Bayesian data augmentation}





%\section{Summary}


\begin{frame}
  \frametitle{Mark-recapture summary}
  Assumptions
  \begin{itemize}
    \small
    \item Animals don't move during the survey
    \item Animals are uniformly distributed with respect to the
      transects
    \item Detection is certain on the transect, i.e. $p=1$ when $x=0$. 
    \item Detections are independent
  \end{itemize}
  \pause
  \vfill
  \small
  If these assumptions can be met, distance sampling is a powerful
  method allowing for inference about abundance and density using data
  from a single visit. \\
\end{frame}




\section{Assignment}




\begin{frame}[fragile]
  \frametitle{Assignment}
  % \small
  \footnotesize
  Create a self-contained R script or Rmarkdown file to do the following:
  \vfill
  \begin{enumerate}
%    \small
    \footnotesize
    \item Fit a distance sampling model with a half-normal detection
      function and the following covariates to the black-throated blue
      warbler data ({\tt btbw\_data\_distsamp.csv}) in `unmarked' and
      `JAGS':   
      \begin{itemize}
        \footnotesize
        \item Density covariates: {\tt Elevation, UTM.N, UTM.W}
        \item Detection covariates: {\tt Wind, Noise}
        \item Response: {\scriptsize \tt btbw0\_20, btbw20\_40, btbw40\_60, btbw60\_80, btbw80\_100}
      \end{itemize}
    \item Using the model fitted in `unmarked', create two graphs of
      the predictions, one for density and the other for the scale
      parameter ($\sigma$).
    \item Compare the half-normal model to two other models with the
      same covariates, but with negative exponential and hazard
      rate detection functions. Which has the lowest AIC? 
  \end{enumerate}
  \pause
  \vfill
  Suggestions:
  \begin{itemize}
    \item Convert response variables to matrix with \inr{as.matrix}
    \item Standardize covariates
  \end{itemize}
  \pause
  \vfill
  Upload your {\tt .R} or {\tt .Rmd} file to ELC before Tuesday. 
\end{frame}





\end{document}

